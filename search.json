[{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://jbdorey.github.io/BeeBDC/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"working-directory","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.1 Working directory","title":"BeeBDC vignette","text":"Choose path root folder folders can found first time run BeeBDC, want use renv package manage packages, can install renv… initialise renv project. already initialised project, can instead just activate .","code":"RootPath <- \"/Users/jamesdorey/Desktop/Uni/My_papers/Bee_SDM_paper\"   # Create the working directory in the RootPath if it doesn't exist already if (!dir.exists(paste0(RootPath, \"/Data_acquisition_workflow\"))) {     dir.create(paste0(RootPath, \"/Data_acquisition_workflow\"), recursive = TRUE) }   # Set the working directory setwd(paste0(RootPath,\"/Data_acquisition_workflow\")) ## Error in setwd(paste0(RootPath, \"/Data_acquisition_workflow\")): cannot change working directory install.packages(\"renv\") renv::init(project = paste0(RootPath,\"/Data_acquisition_workflow\")) renv::activate(project = paste0(RootPath,\"/Data_acquisition_workflow\")) ## Error: failed to create directory at path '/Users/jamesdorey/Desktop/Uni/My_papers/Bee_SDM_paper/Data_acquisition_workflow'"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"install-packages-if-needed","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.2 Install packages (if needed)","title":"BeeBDC vignette","text":"may need install gdal computer. can done mac using Homebrew terminal command “brew install gdal”. start , need install BiocManager, devtools, ComplexHeatmap, rnaturalearthhires install adn fully use BeeBDC. Now install BeeBDC. Snapshot renv environment. Set directories used BeeBDC. directories include data, figures, reports, etc. saved. RDoc needs path RELATIVE RootPath; .e., file path two diverge.","code":"if (!require(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\") if (!require(\"devtools\", quietly = TRUE))     install.packages(\"devtools\") ##  ## Attaching package: 'devtools' ## The following object is masked from 'package:BiocManager': ##  ##     install devtools::install_github(\"ropensci/rnaturalearthhires\") ## Using github PAT from envvar GITHUB_PAT ## Skipping install of 'rnaturalearthhires' from a github remote, the SHA1 (c3785a8c) has not changed since last install. ##   Use `force = TRUE` to force installation BiocManager::install(\"ComplexHeatmap\") ## 'getOption(\"repos\")' replaces Bioconductor standard repositories, see ## 'help(\"repositories\", package = \"BiocManager\")' for details. ## Replacement repositories: ##     CRAN: https://cloud.r-project.org ## Bioconductor version 3.17 (BiocManager 1.30.22), R 4.3.1 (2023-06-16) ## Installation paths not writeable, unable to update packages ##   path: /opt/R/4.3.1/lib/R/library ##   packages: ##     KernSmooth, Matrix, mgcv, nlme, spatial, survival ## Old packages: 'DT', 'labeling', 'pak' devtools::install_github(\"https://github.com/jbdorey/BeeBDC.git\", ref = \"main\",                          force = FALSE,                         auth_token = \"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\") renv::snapshot(project = paste0(RootPath,\"/Data_acquisition_workflow\"),                  prompt = FALSE) ## Error in normalizePath(path, winslash, mustWork): path[1]=\"/Users/jamesdorey/Desktop/Uni/My_papers/Bee_SDM_paper/Data_acquisition_workflow\": No such file or directory BeeBDC::dirMaker(     RootPath = RootPath,     RDoc = \"BeeBDC_website.Rmd\") %>%       # Add paths created by this function to the .GlobalEnv     list2env(envir = .GlobalEnv) ## here() starts at /home/runner/work/BeeBDC/BeeBDC ## Error in setwd(RootPath): cannot change working directory"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"load-packages","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.3 Load packages","title":"BeeBDC vignette","text":"Load packages list specified , addition “rnaturalearthhires”.","code":"lapply(c(\"ComplexHeatmap\", \"BeeBDC\", \"magrittr\"),         library, character.only = TRUE) ## Loading required package: grid ## ======================================== ## ComplexHeatmap version 2.16.0 ## Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/ ## Github page: https://github.com/jokergoo/ComplexHeatmap ## Documentation: http://jokergoo.github.io/ComplexHeatmap-reference ##  ## If you use it in published research, please cite either one: ## - Gu, Z. Complex Heatmap Visualization. iMeta 2022. ## - Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional  ##     genomic data. Bioinformatics 2016. ##  ##  ## The new InteractiveComplexHeatmap package can directly export static  ## complex heatmaps into an interactive Shiny app with zero effort. Have a try! ##  ## This message can be suppressed by: ##   suppressPackageStartupMessages(library(ComplexHeatmap)) ## ========================================"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-merge","dir":"Articles","previous_headings":"","what":"1.0 Data merge","title":"BeeBDC vignette","text":"Attention:  Although line code validated, order save time knitting RMarkdown document next section display . data merging (section 1.0) preparing data (section 2.0), feel free skip Section 3.0 Initial flags.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"download-ala-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.1 Download ALA data","title":"BeeBDC vignette","text":"Download ALA data create new file DataPath put data . also first make account ALA order download data — https://auth.ala.org.au/userdetails/registration/createAccount","code":"BeeBDC::atlasDownloader(path = DataPath,            userEmail = \"your@email.edu.au\",            atlas = \"ALA\",            ALA_taxon = \"Apiformes\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-and-merge-ala-scan-idigbio-and-gbif-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.2 Import and merge ALA, SCAN, iDigBio and GBIF data","title":"BeeBDC vignette","text":"Supply path data , save_type either “csv_files” “R_file”. error finding file run repoFinder() troubleshoot. example: Load -recent version data needed.return list : occurrence dataset attributes (.$Data_WebDL) appended eml file (.$eml_files)","code":"DataImp <- BeeBDC::repoMerge(path = DataPath,                    occ_paths = BeeBDC::repoFinder(path = DataPath),                   save_type = \"R_file\") #BeeBDC::repoFinder(path = DataPath)             #OUTPUT:             #$ALA_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/ALA_galah_path/galah_download_2022-09-15/data.csv\"                #$GBIF_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0000165-220831081235567/occurrence.txt\"             #[2] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436695-210914110416597/occurrence.txt\"             #[3] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436697-210914110416597/occurrence.txt\"             #[4] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436704-210914110416597/occurrence.txt\"             #[5] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436732-210914110416597/occurrence.txt\"             #[6] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436733-210914110416597/occurrence.txt\"             #[7] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436734-210914110416597/occurrence.txt\"                                  #$iDigBio_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/iDigBio_webDL_30Aug2022/5aa5abe1-62e0-4d8c-bebf-4ac13bd9e56f/occurrence_raw.csv\"                #$SCAN_data             #character(0)             #Failing because SCAN_data seems to be missing. Downloaded separatly from the one drive DataImp <- BeeBDC::importOccurrences(path = DataPath,                        fileName = \"BeeData_\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-usgs-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.3 Import USGS Data","title":"BeeBDC vignette","text":"USGS_formatter() find, import, format create metadata USGS dataset. pubDate must day-month-year format.","code":"USGS_data <- BeeBDC::USGS_formatter(path = DataPath, pubDate = \"19-11-2022\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"formatted-source-importer","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.4 Formatted Source Importer","title":"BeeBDC vignette","text":"Formatted source importer. Use importer find files formatted need added larger data file. attributes file must contain “attribute” name, occurrence file must . catalogNumber, remove “.*specimennumber:” comes USGS number match duplicates.","code":"Complete_data <- BeeBDC::formattedCombiner(path = DataPath,                                  strings = c(\"USGS_[a-zA-Z_]+[0-9]{4}-[0-9]{2}-[0-9]{2}\"),                                    # This should be the list-format with eml attached                                 existingOccurrences = DataImp$Data_WebDL,                                 existingEMLs = DataImp$eml_files) Complete_data$Data_WebDL <- Complete_data$Data_WebDL %>%     dplyr::mutate(catalogNumber = stringr::str_replace(catalogNumber,                                                        pattern = \".*\\\\| specimennumber:\",                                                        replacement = \"\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.5 Save data","title":"BeeBDC vignette","text":"Choose type data format want.","code":"BeeBDC::dataSaver(path = DataPath,# The main path to look for data in        save_type = \"CSV_file\", # \"R_file\" OR \"CSV_file\"        occurrences = Complete_data$Data_WebDL, # The existing datasheet        eml_files = Complete_data$eml_files, # The existing EML files        file_prefix = \"Fin_\") # The prefix for the fileNames rm(Complete_data, DataImp)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-preperation","dir":"Articles","previous_headings":"","what":"2.0 Data preperation","title":"BeeBDC vignette","text":"data preparatin section script relates mostly integrating bee occurrence datasets corrections may skipped many general taxon users.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"standardise-datasets","dir":"Articles","previous_headings":"2.0 Data preperation","what":"2.1 standardise datasets","title":"BeeBDC vignette","text":"may either use: bdc import method (works well general datasets) jbd import method (works well data merge)","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--bdc-import","dir":"Articles","previous_headings":"2.0 Data preperation > 2.1 standardise datasets","what":"a. bdc import","title":"BeeBDC vignette","text":"bdc import truly supported , provided example. Please go section 2.1b . Read bdc metadata standardise dataset bdc.","code":"bdc_metadata <- readr::read_csv(paste(DataPath, \"out_file\", \"bdc_integration.csv\", sep = \"/\"))         # ?issue — datasetName is a darwinCore field already!         # Standardise the dataset to bdc         db_standardized <- bdc::bdc_standardize_datasets(           metadata = bdc_metadata,           format = \"csv\",           overwrite = TRUE,           save_database = TRUE)         # read in configuration description file of the column header info         config_description <- readr::read_csv(paste(DataPath, \"Output\", \"bdc_configDesc.csv\",                                                     sep = \"/\"),                                                show_col_types = FALSE, trim_ws = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--jbd-import","dir":"Articles","previous_headings":"2.0 Data preperation > 2.1 standardise datasets","what":"b. jbd import","title":"BeeBDC vignette","text":"Find path, read file, add database_id column.","code":"occPath <- BeeBDC::fileFinder(path = DataPath, fileName = \"Fin_BeeData_combined_\")     db_standardized <- readr::read_csv(occPath,                                         # Use the basic ColTypeR function to determine types                                      col_types = BeeBDC::ColTypeR(), trim_ws = TRUE) %>%                                      dplyr::mutate(database_id = paste(\"Dorey_data_\",                                       1:nrow(.), sep = \"\"),                                      .before = family)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--optional-thin","dir":"Articles","previous_headings":"2.0 Data preperation > 2.1 standardise datasets","what":"c. optional thin","title":"BeeBDC vignette","text":"can thin dataset TESTING !","code":"check_pf <- check_pf %>%            # take every 100th record            filter(row_number() %% 100 == 1)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"paige-dataset","dir":"Articles","previous_headings":"2.0 Data preperation","what":"2.2 Paige dataset","title":"BeeBDC vignette","text":"Paige Chesshire’s cleaned American dataset — https://doi.org/10.1111/ecog.06584","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-data","dir":"Articles","previous_headings":"2.0 Data preperation > 2.2 Paige dataset","what":"Import data","title":"BeeBDC vignette","text":"haven’t figured now, don’t worry column name warning — columns occur . Attention:  recommended run code full bee dataset 16GB RAM. Robert ran laptop 16GB RAM Intel(R) Core(TM) i7-8550U processor (4 cores 8 threads) — struggled.","code":"PaigeNAm <- readr::read_csv(paste(DataPath, \"Paige_data\", \"NorAmer_highQual_only_ALLfamilies.csv\",                                     sep = \"/\"), col_types = BeeBDC::ColTypeR()) %>%      # Change the column name from Source to dataSource to match the rest of the data.     dplyr::rename(dataSource = Source) %>%      # EXTRACT WAS HERE       # add a NEW database_id column     dplyr::mutate(       database_id = paste0(\"Paige_data_\", 1:nrow(.)),       .before = scientificName)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"merge-paiges-data-with-downloaded-data","dir":"Articles","previous_headings":"2.0 Data preperation > 2.2 Paige dataset","what":"Merge Paige’s data with downloaded data","title":"BeeBDC vignette","text":"Remove spent data.","code":"db_standardized <- BeeBDC::PaigeIntegrater(       db_standardized = db_standardized,       PaigeNAm = PaigeNAm,         # This is a list of columns by which to match Paige's data to the most-recent download with.          # Each vector will be matched individually       columnStrings = list(         c(\"decimalLatitude\", \"decimalLongitude\",            \"recordNumber\", \"recordedBy\", \"individualCount\", \"samplingProtocol\",           \"associatedTaxa\", \"sex\", \"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",           \"recordId\", \"occurrenceID\", \"collectionID\"),         # Iteration 1         c(\"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",           \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 2         c(\"decimalLatitude\", \"decimalLongitude\",            \"recordedBy\", \"genus\", \"specificEpithet\"),# Iteration 3         c(\"id\", \"decimalLatitude\", \"decimalLongitude\"),# Iteration 4         c(\"recordedBy\", \"genus\", \"specificEpithet\", \"locality\"), # Iteration 5         c(\"recordedBy\", \"institutionCode\", \"genus\",            \"specificEpithet\",\"locality\"),# Iteration 6         c(\"occurrenceID\",\"decimalLatitude\", \"decimalLongitude\"),# Iteration 7         c(\"catalogNumber\",\"decimalLatitude\", \"decimalLongitude\"),# Iteration 8         c(\"catalogNumber\", \"locality\") # Iteration 9       ) ) rm(PaigeNAm)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"usgs","dir":"Articles","previous_headings":"2.0 Data preperation","what":"2.3 USGS","title":"BeeBDC vignette","text":"USGS dataset also partially occurs GBIF BISON. However, occurrence codes silly place… correct help identify duplicates later.","code":"db_standardized <- db_standardized %>%           # Remove the discoverlife html if it is from USGS       dplyr::mutate(occurrenceID = dplyr::if_else(         stringr::str_detect(occurrenceID, \"USGS_DRO\"),         str_remove(occurrenceID, \"http://www\\\\.discoverlife\\\\.org/mp/20l\\\\?id=\"),         occurrenceID)) %>%           # Use otherCatalogNumbers when occurrenceID is empty AND when USGS_DRO is detected there       dplyr::mutate(         occurrenceID = dplyr::if_else(           stringr::str_detect(otherCatalogNumbers, \"USGS_DRO\") & is.na(occurrenceID),           otherCatalogNumbers, occurrenceID)) %>%            # Make sure that no eventIDs have snuck into the occurrenceID columns             # For USGS_DRO, codes with <6 digits are event ids       dplyr::mutate(         occurrenceID = dplyr::if_else(stringr::str_detect(occurrenceID, \"USGS_DRO\", negate = TRUE),              # Keep occurrenceID if it's NOT USGS_DRO            occurrenceID,               # If it IS USGS_DRO and it has => 6 numbers, keep it, else, NA           dplyr::if_else(stringr::str_detect(occurrenceID, \"USGS_DRO[0-9]{6,10}\"),                          occurrenceID, NA_character_)),         catalogNumber = dplyr::if_else(stringr::str_detect(catalogNumber, \"USGS_DRO\", negate = TRUE),              # Keep catalogNumber if it's NOT USGS_DRO           catalogNumber,               # If it IS USGS_DRO and it has => 6 numbers, keep it, else, NA           dplyr::if_else(stringr::str_detect(catalogNumber, \"USGS_DRO[0-9]{6,10}\"),                          catalogNumber, NA_character_)))"},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-additional-and-potentially-private-datasets-","dir":"Articles","previous_headings":"2.0 Data preperation > 2.4 Additional datasets","what":"Import additional and potentially private datasets.","title":"BeeBDC vignette","text":"Note: Private dataset functions provided data integrated datasets become freely available. warnings rows may formatted correctly dates fail parse. normal.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--epel","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Guzman, L. M., Kelly, T. & Elle, E. data set pollinator diversity interactions plants Pacific Northwest. Ecology n/, e3927 (2022). https://doi.org/10.1002/ecy.3927","code":"EPEL_Data <- BeeBDC::readr_BeeBDC(dataset = \"EPEL\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/bee_data_canada.csv\",                       outFile = \"jbd_EPEL_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--allan-smith-pardo","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data Allan Smith-Pardo","code":"ASP_Data <- BeeBDC::readr_BeeBDC(dataset = \"ASP\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Allan_Smith-Pardo_Dorey_ready2.csv\",                       outFile = \"jbd_ASP_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--minckley","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data Robert Minckley","code":"BMin_Data <- BeeBDC::readr_BeeBDC(dataset = \"BMin\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Bob_Minckley_6_1_22_ScanRecent-mod_Dorey.csv\",                         outFile = \"jbd_BMin_data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"d--bmont","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Delphia, C. M. Bumble bees Montana. https://www.mtent.org/projects/Bumble_Bees/bombus_species.html. (2022)","code":"BMont_Data <- BeeBDC::readr_BeeBDC(dataset = \"BMont\",                                  path = paste0(DataPath, \"/Additional_Datasets\"),                           inFile = \"/InputDatasets/Bombus_Montana_dorey.csv\",                           outFile = \"jbd_BMont_data.csv\",                           dataLicense = \"https://creativecommons.org/licenses/by-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"e--ecd","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Ecdysis. Ecdysis: portal live-data arthropod collections, https://serv.biokic.asu.edu/ecdysis/index.php (2022).","code":"Ecd_Data <- BeeBDC::readr_BeeBDC(dataset = \"Ecd\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Ecdysis_occs.csv\",                       outFile = \"jbd_Ecd_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"f--gai","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Gaiarsa, M. P., Kremen, C. & Ponisio, L. C. Pollinator interaction flexibility across scales affects patch colonization occupancy. Nature Ecology & Evolution 5, 787-793 (2021). https://doi.org/10.1038/s41559-021-01434-y","code":"Gai_Data <- BeeBDC::readr_BeeBDC(dataset = \"Gai\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/upload_to_scan_Gaiarsa et al_Dorey.csv\",                       outFile = \"jbd_Gai_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"g--caes","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Connecticut Agricultural Experiment Station","code":"CAES_Data <- BeeBDC::readr_BeeBDC(dataset = \"CAES\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/CT_BEE_DATA_FROM_PBI.xlsx\",                         outFile = \"jbd_CT_Data.csv\",                         sheet = \"Sheet1\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"h--geol","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"","code":"GeoL_Data <- BeeBDC::readr_BeeBDC(dataset = \"GeoL\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Geolocate and BELS_certain and accurate.xlsx\",                         outFile = \"jbd_GeoL_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"i--eaco","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"","code":"EaCO_Data <- BeeBDC::readr_BeeBDC(dataset = \"EaCO\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Eastern Colorado bee 2017 sampling.xlsx\",                         outFile = \"jbd_EaCo_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"j--fsca","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Florida State Collection Arthropods","code":"FSCA_Data <- BeeBDC::readr_BeeBDC(dataset = \"FSCA\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"InputDatasets/fsca_9_15_22_occurrences.csv\",                         outFile = \"jbd_FSCA_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"k--texas-smc","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Published unpublished data Texas literature online database, usually copied spreadsheet document format, otherwise copied differently-formatted spreadsheet. Unpublished partially published data obtained express permission lead author.","code":"SMC_Data <- BeeBDC::readr_BeeBDC(dataset = \"SMC\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/TXbeeLitOccs_31Oct22.csv\",                        outFile = \"jbd_SMC_Data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"l--texas-bal","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data GPS coordinates Ballare, K. M., Neff, J. L., Ruppel, R. & Jha, S. Multi-scalar drivers biodiversity: local management mediates wild bee community response regional urbanization. Ecol. Appl. 29, e01869 (2019), https://doi.org/10.1002/eap.1869. version Dryad missing site GPS coordinates (accident). Kim okay data made public long paper referenced. - Elinor Lichtenberg","code":"Bal_Data <- BeeBDC::readr_BeeBDC(dataset = \"Bal\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Beedata_ballare.xlsx\",                        outFile = \"jbd_Bal_Data.csv\",                       sheet = \"animal_data\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"m--palouse-lic","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"*Attached: canola data. tried get DarwinCore format. data go manuscript currently review. ’s bioRxiv version: Lichtenberg, E. M., Milosavljević, ., Campbell, . J. & Crowder, D. W. Differential effects soil conservation practices arthropods crop yield. bioRxiv, https://doi.org/10.1101/2021.1112.1106.471474 (2022) https://www.biorxiv.org/content/10.1101/2021.12.06.471474v2. data putting SCAN. - Elinor Lichtenberg","code":"Lic_Data <- BeeBDC::readr_BeeBDC(dataset = \"Lic\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Lichtenberg_canola_records.csv\",                        outFile = \"jbd_Lic_Data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"n--arm","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"","code":"Arm_Data <- BeeBDC::readr_BeeBDC(dataset = \"Arm\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Bee database Armando_Final.xlsx\",                       outFile = \"jbd_Arm_Data.csv\",                       sheet = \"Sheet1\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"o--dor","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"several papers: https://doi.org/10.3897/jhr.79.57308, https://doi.org/10.3897/jhr.81.59365, https://doi.org/10.11646/zootaxa.4674.1.1.","code":"Dor_Data <- BeeBDC::readr_BeeBDC(dataset = \"Dor\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/DoreyData.csv\",                       outFile = \"jbd_Dor_Data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"merge-all","dir":"Articles","previous_headings":"2.0 Data preperation > 2.4 Additional datasets","what":"2.5 Merge all","title":"BeeBDC vignette","text":"Remove spent datasets. Read merge . readr_BeeBDC() supported currently implemented represent datasets publicly released future. See ‘?readr_BeeBDC()’ details.","code":"rm(EPEL_Data, ASP_Data, BMin_Data, BMont_Data, Ecd_Data, Gai_Data, CAES_Data,    GeoL_Data, EaCO_Data, FSCA_Data, SMC_Data, Bal_Data, Lic_Data, Arm_Data, Dor_Data) db_standardized <- db_standardized %>%   dplyr::bind_rows(     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_ASP_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_EPEL_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_BMin_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_BMont_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Ecd_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Gai_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_CT_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_GeoL_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_EaCo_Data.csv\"), col_types = BeeBDC::ColTypeR()),      readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_SMC_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Bal_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Lic_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Arm_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Dor_Data.csv\"), col_types = BeeBDC::ColTypeR())) %>%      # END bind_rows   suppressWarnings(classes = \"warning\") # End suppressWarnings — due to col_types"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"match-database_id","dir":"Articles","previous_headings":"2.0 Data preperation > 2.4 Additional datasets","what":"2.6 Match database_id","title":"BeeBDC vignette","text":"prior runs ’d like match database_ids current run. may use script try match database IDs prior runs. Read prior run choice. function attempt find database_ids prior runs. Save dataset.","code":"priorRun <- BeeBDC::fileFinder(path = DataPath,                           file = \"01_prefilter_database_9Aug22.csv\") %>%     readr::read_csv(file = ., col_types = BeeBDC::ColTypeR()) db_standardized <- BeeBDC::idMatchR(   currentData = db_standardized,   priorData = priorRun,     # First matches will be given preference over later ones   matchBy = tibble::lst(c(\"gbifID\", \"dataSource\"),                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\", \"decimalLatitude\",                           \"decimalLongitude\"),                         c(\"occurrenceID\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         c(\"recordId\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         c(\"id\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         # Because INHS was entered as it's own dataset but is now included in the GBIF    download...                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\",                           \"decimalLatitude\",\"decimalLongitude\")),     # You can exclude datasets from prior by matching their prefixs — before first underscore:   excludeDataset = c(\"ASP\", \"BMin\", \"BMont\", \"CAES\", \"EaCO\", \"Ecd\", \"EcoS\",                      \"Gai\", \"KP\", \"EPEL\", \"CAES\", \"EaCO\", \"FSCA\", \"SMC\", \"Lic\", \"Arm\"))   # Remove redundant files rm(priorRun) db_standardized %>%     readr::write_excel_csv(.,                      paste(OutPath_Intermediate, \"00_prefilter_database.csv\",                            sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"initial-flags","dir":"Articles","previous_headings":"","what":"3.0 Initial flags","title":"BeeBDC vignette","text":"Read data back needed. OutPath_Intermediate (directories) created saved global environment dirMaker(). Attention:  purposes website, use combination two test datasets, provided BeeBDC. datasets () 105 occurrence records across three species (bees3sp) (ii) 100 records across 85 names (beesRaw). details bdc package, please see tutorial.","code":"if(!exists(\"db_standardized\")){   db_standardized <- readr::read_csv(paste(OutPath_Intermediate, \"00_prefilter_database.csv\",                                     sep = \"/\"), col_types = BeeBDC::ColTypeR())} data(\"bees3sp\", package = \"BeeBDC\") data(\"beesRaw\", package = \"BeeBDC\") db_standardized <- dplyr::bind_rows(beesRaw,                                        # Only keep a subset of columns from bees3sp                              bees3sp %>% dplyr::select(tidyselect::all_of(colnames(beesRaw)), countryCode))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"sciname","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.1 SciName","title":"BeeBDC vignette","text":"Flag occurrences without scientificName provided.","code":"check_pf <- bdc::bdc_scientificName_empty(   data = db_standardized,   sci_name = \"scientificName\") ##  ## bdc_scientificName_empty: ## Flagged 0 records. ## One column was added to the database. # now that this is saved, remove it to save space in memory rm(db_standardized)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"misscoords","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.2 MissCoords","title":"BeeBDC vignette","text":"Flag occurrences missing decimalLatitude decimalLongitude.","code":"check_pf <- bdc::bdc_coordinates_empty(   data = check_pf,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\") ##  ## bdc_coordinates_empty: ## Flagged 42 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"outofrange","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.3 OutOfRange","title":"BeeBDC vignette","text":"Flag occurrences earth (outside -180 180 -90 90 degrees).","code":"check_pf <- bdc::bdc_coordinates_outOfRange(   data = check_pf,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\") ##  ## bdc_coordinates_outOfRange: ## Flagged 0 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"source","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.4 Source","title":"BeeBDC vignette","text":"Flag occurrences don’t match basisOfRecord types .","code":"check_pf <- bdc::bdc_basisOfRecords_notStandard(   data = check_pf,   basisOfRecord = \"basisOfRecord\",   names_to_keep = c(     # Keep all plus some at the bottom.     \"Event\",     \"HUMAN_OBSERVATION\",     \"HumanObservation\",     \"LIVING_SPECIMEN\",     \"LivingSpecimen\",     \"MACHINE_OBSERVATION\",     \"MachineObservation\",     \"MATERIAL_SAMPLE\",     \"O\",     \"Occurrence\",     \"MaterialSample\",     \"OBSERVATION\",     \"Preserved Specimen\",     \"PRESERVED_SPECIMEN\",     \"preservedspecimen Specimen\",     \"Preservedspecimen\",     \"PreservedSpecimen\",     \"preservedspecimen\",     \"S\",     \"Specimen\",     \"Taxon\",     \"UNKNOWN\",     \"\",     NA,     \"NA\",     \"LITERATURE\",      \"None\", \"Pinned Specimen\", \"Voucher reared\", \"Emerged specimen\"   )) ##  ## bdc_basisOfRecords_notStandard: ## Flagged 1 of the following specific nature: ##  MATERIAL_CITATION  ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"countryname","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.5 CountryName","title":"BeeBDC vignette","text":"Try harmonise country names.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--prepare-dataset","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"a. prepare dataset","title":"BeeBDC vignette","text":"Fix country names based common problems extract ISO2 codes occurrences.","code":"check_pf_noNa <- BeeBDC::countryNameCleanR(   data = check_pf,     # Create a Tibble of common issues in country names and their replacements   commonProblems = dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',                                               'United States','U.S.A','MX','CA','Bras.','Braz.',                                               'Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                                   fix = c('United States of America','United States of America',                                           'United States of America','United States of America',                                           'United States of America','United States of America',                                           'United States of America','Mexico','Canada','Brazil',                                           'Brazil','Brazil','Northern Mariana Islands','PUERTO.RICO'))   ) ##  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--run-function","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"b. run function","title":"BeeBDC vignette","text":"Get country name coordinates using wrapper around jbd_country_from_coordinates() function. dataset much larger used design bdc, made can analyse data smaller pieces. Additionally, like functions BeeBDC, implemented parallel operations (using mc.cores = #cores stepSize = #rowsPerOperation); see ‘?jbd_CfC_chunker()’ details.","code":"suppressWarnings(   countryOutput <- BeeBDC::jbd_CfC_chunker(data = check_pf_noNa,                                    lat = \"decimalLatitude\",                                    lon = \"decimalLongitude\",                                    country = \"country\",                                     # How many rows to process at a time                                    stepSize = 1000000,                                     # Start row                                    chunkStart = 1,                                    path = OutPath_Intermediate,                                    append = FALSE,                                    mc.cores = 1),   classes = \"warning\") ##  - Starting chunk 1... ## From 1 to 1,000,000 ##  - Cleaning RAM. ##  - Finished chunk 1 of 1 chunks. Records examined: 1,000,000 ## Error in eval(expr, envir, enclos): object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--re-merge","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"c. re-merge","title":"BeeBDC vignette","text":"Join datasets. Save dataset. Read needed. remove interim datasets.","code":"check_pf <- dplyr::left_join(check_pf,                               countryOutput,                               by = \"database_id\",                              suffix = c(\"\", \"CO\"))  %>%      # Take the new country name if the original is NA   dplyr::mutate(country = dplyr::if_else(is.na(country),                                          countryCO,                                          country)) %>%     # Remove duplicates if they arose from left_join!   dplyr::distinct() ## Error in eval(expr, envir, enclos): object 'countryOutput' not found check_pf %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"01_prefilter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found if(!exists(\"check_pf\")){ check_pf <- readr::read_csv(paste(DataPath,               \"Output\", \"Intermediate\", \"01_prefilter_database.csv\", sep = \"/\"),              col_types = BeeBDC::ColTypeR())} rm(check_pf_noNa, countryOutput)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"standardconames","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.6 StandardCoNames","title":"BeeBDC vignette","text":"Run function (standardises country names adds ISO2 codes needed).","code":"# Standardise country names and add ISO2 codes if needed check_pf <- bdc::bdc_country_standardized(   # Remove the countryCode and country_suggested columns to avoid an error with      # where two \"countryCode\" and \"country_suggested\" columns exist (i.e. if the dataset has been       # run before)   data = check_pf %>% dplyr::select(!tidyselect::any_of(c(\"countryCode\", \"country_suggested\"))),   country = \"country\" ) ## Loading auxiliary data: country names ## Standardizing country names ## country found: Argentina ## country found: Australia ## country found: Belgium ## country found: Brazil ## country found: Canada ## country found: Colombia ## country found: Costa Rica ## country found: Ecuador ## country found: Estonia ## country found: Finland ## country found: France ## country found: Germany ## country found: Mexico ## country found: Norway ## country found: South Africa ## country found: Sweden ## country found: Switzerland ##  ## bdc_country_standardized: ## The country names of 5 records were standardized. ## Two columns ('country_suggested' and 'countryCode') were added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"transpcoords","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.7 TranspCoords","title":"BeeBDC vignette","text":"Flag correct records decimalLatitude decimalLongitude appear transposed. created chunked version bdc::bdc_coordinates_transposed() RAM-heavy using large bee dataset. However, like many ‘jbd_…’ functions improvements - e.g., parallel running. Get quick summary number transposed records. Save dataset Read data needed","code":"check_pf <- BeeBDC::jbd_Ctrans_chunker(   # bdc_coordinates_transposed inputs   data = check_pf,   id = \"database_id\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   countryCode = \"countryCode\",   border_buffer = 0.2, # in decimal degrees (~22 km at the equator)   save_outputs = TRUE,   sci_names = \"scientificName\",   # chunker inputs   stepSize = 1000000,  # How many rows to process at a time   chunkStart = 1,  # Start row   append = FALSE,  # If FALSE it may overwrite existing dataset   path = OutPath_Check,   mc.cores = 1 ) ##  - Running chunker with: ## stepSize = 1,000,000 ## chunkStart = 1 ## chunkEnd = 1,000,000 ## append = FALSE ##  - Starting chunk 1... ## From 1 to 1,000,000 ##  - Cleaning RAM. ##  - Finished chunk 1 with 1 remaining. Records examined: 205 ## Error in eval(expr, envir, enclos): object 'OutPath_Check' not found table(check_pf$coordinates_transposed, useNA = \"always\") ##  ## <NA>  ##    0 check_pf %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"01_prefilter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found gc() ##            used  (Mb) gc trigger  (Mb)  max used  (Mb) ## Ncells  5886676 314.4    9883022 527.9   9883022 527.9 ## Vcells 13763686 105.1   62906164 480.0 122843431 937.3 if(!exists(\"check_pf\")){   check_pf <- readr::read_csv(paste(OutPath_Intermediate, \"01_prefilter_database.csv\",                                     sep = \"/\"))}"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"coord-country","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.8 Coord-country","title":"BeeBDC vignette","text":"Collect country names country_suggested column. rebuilt bdc function flag occurrences coordinates inconsistent provided country name. Save dataset.","code":"check_pf <- BeeBDC::jbd_coordCountryInconsistent(   data = check_pf,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   mapResolution = 50,   pointBuffer = 0.01) ## Loading required namespace: mgsub ##  - Downloading naturalearth map... ## Spherical geometry (s2) switched off ##  - Extracting initial country names without buffer... ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ##  - Buffering naturalearth map by pointBuffer... ## dist is assumed to be in decimal degrees (arc_degrees). ##  - Extracting FAILED country names WITH buffer... ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ##  ## jbd_coordinates_country_inconsistent: ## Flagged 2 records. ## The column, '.coordinates_country_inconsistent', was added to the database. ##  - Completed in 0.02 secs check_pf %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"01_prefilter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"georefissue","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.9 GeoRefIssue","title":"BeeBDC vignette","text":"function Identifies records whose coordinates can potentially extracted locality information (must manually checked later). Remove spent data.","code":"xyFromLocality <- bdc::bdc_coordinates_from_locality(   data = check_pf,   locality = \"locality\",   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   save_outputs = TRUE ) %>% # Save data    readr::write_excel_csv(paste(OutPath_Check, \"01_coordinates_from_locality.csv\",                          sep = \"/\")) ##  ## bdc_coordinates_from_locality  ## Found 38 records missing or with invalid coordinates but with potentially useful information on locality. ##   ## Check database in: Output/Check/01_coordinates_from_locality.csv ##  ## bdc_coordinates_from_locality  ## Found 38 records missing or with invalid coordinates but with potentially useful information on locality. ## Error: object 'OutPath_Check' not found rm(xyFromLocality)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-absent","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.10 Flag Absent","title":"BeeBDC vignette","text":"Flag records marked “absent”.","code":"check_pf <- BeeBDC::flagAbsent(data = check_pf,                    PresAbs = \"occurrenceStatus\") ## \\.occurrenceAbsent: ##  Flagged 8 absent records: ##  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-license","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.11 flag License","title":"BeeBDC vignette","text":"Flag records may used according license information.","code":"check_pf <- BeeBDC::flagLicense(data = check_pf,                     strings_to_restrict = \"all\",                     # DON'T flag if in the following dataSource(s)                     excludeDataSource = NULL) ## \\.unLicensed: ##  Flagged 0 records that may NOT be used. ##  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"gbif-issue","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.12 GBIF issue","title":"BeeBDC vignette","text":"Flag select issues flagged GBIF.","code":"check_pf <- BeeBDC::GBIFissues(data = check_pf,                     issueColumn = \"issue\",                     GBIFflags = c(\"COORDINATE_INVALID\", \"ZERO_COORDINATE\")) ##  - jbd_GBIFissues: ## Flagged 0  ##   The .GBIFflags column was added to the database."},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--save-flags","dir":"Articles","previous_headings":"3.0 Initial flags > 3.13 Flag Reports","what":"a. Save flags","title":"BeeBDC vignette","text":"Save flags far. function make sure keep copy everything flagged now. updated throughout script can accessed end, wary moving files around manually. However, data also still maintained main running file optional fail-safe.. Update .summary column","code":"flagFile <- BeeBDC::flagRecorder(   data = check_pf,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),     # These are the columns that will be kept along with the flags   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),     # TRUE if you want to find a file from a previous part of the script to append to   append = FALSE) ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found check_pf <- BeeBDC::summaryFun(   data = check_pf,     # Don't filter these columns (or NULL)   dontFilterThese = NULL,     # Remove the filtering columns?   removeFilterColumns = FALSE,     # Filter to ONLY cleaned data?   filterClean = FALSE) ##  - We will flag all columns starting with '.' ##  - summaryFun: ## Flagged 52  ##   The .summary column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--reporting","dir":"Articles","previous_headings":"3.0 Initial flags > 3.13 Flag Reports","what":"c. Reporting","title":"BeeBDC vignette","text":"Use bdc generate reports.","code":"(report <- bdc::bdc_create_report(data = check_pf,                                   database_id = \"database_id\",                                   workflow_step = \"prefilter\",                                   save_report = TRUE) ) ## Loading required package: DT ##  ## bdc_create_report: ## Check the report summarizing the results of the prefilter in: ##  /home/runner/work/BeeBDC/BeeBDC/Output/Report"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.14 Save","title":"BeeBDC vignette","text":"Save intermediate dataset.","code":"check_pf %>%   readr::write_excel_csv(., paste(OutPath_Intermediate, \"01_prefilter_output.csv\",                             sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"taxonomy","dir":"Articles","previous_headings":"","what":"4.0 Taxonomy","title":"BeeBDC vignette","text":"information corresponding bdc functions used section, see tutorial. Read filtered dataset rename 3.x dataset 4.0. Remove names_clean already exists (.e. run following functions dataset ).","code":"if(!exists(\"check_pf\")){ database <-   readr::read_csv( paste(OutPath_Intermediate, \"01_prefilter_output.csv\",                          sep = \"/\"), col_types = BeeBDC::ColTypeR()) }else{     # OR rename and remove   database <- check_pf   # Remove spent dataset   rm(check_pf)} database <- database %>%               dplyr::select(!tidyselect::any_of(\"names_clean\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"prep-data-names","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.1 Prep data names","title":"BeeBDC vignette","text":"step cleans database’s scientificName column. ***! MAC: might need install gnparser terminal — brew brew tap gnames/gn brew install gnparser Attention:  can difficult Windows install. Ensure recent version R, Rstudio, R packages. Also check package ‘rgnparser’ installed correctly. still can get code work, may download latest version ‘gnparser’ . may need manually install edit systems environmental variable PATH locate ‘gnparser.exe’. See . Keep .uncer_terms names_clean columns. Merge names complete dataset.","code":"parse_names <-   bdc::bdc_clean_names(sci_names = database$scientificName, save_outputs = TRUE) ## The latest gnparser version is v1.7.4 ## gnparser has been installed to /home/runner/bin ##  ## >> Family names prepended to scientific names were flagged and removed from 0 records. ## >> Terms denoting taxonomic uncertainty were flagged and removed from 0 records. ## >> Other issues, capitalizing the first letter of the generic name, replacing empty names by NA, and removing extra spaces, were flagged and corrected or removed from 1 records. ## >> Infraspecific terms were flagged and removed from 0 records. ## >> Scientific names were cleaned and parsed. Check the results in 'Output/Check/02_clean_names.csv'. parse_names <-   parse_names %>%   dplyr::select(.uncer_terms, names_clean) database <- dplyr::bind_cols(database, parse_names) rm(parse_names)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"taxo-harmonization","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.2 Taxo harmonization","title":"BeeBDC vignette","text":"Read custom taxonomy file BeeBDC package Discover Life website. Harmonise names occurrence tibble. flags occurrences without matched name matches names correct name according Discover Life. can also use multiple cores achieve . See ‘?harmoniseR()’ details. don’t need file … Save harmonised file.","code":"data(\"beesTaxonomy\", package = \"BeeBDC\") database <- BeeBDC::harmoniseR(path = DataPath, #The path to a folder that the output can be saved                        taxonomy = beesTaxonomy, # The formatted taxonomy file                        data = database,                        mc.cores = 4) ## Error in eval(expr, envir, enclos): object 'DataPath' not found rm(beesTaxonomy) database %>%   readr::write_excel_csv(.,                    paste(DataPath, \"Output\", \"Intermediate\", \"02_taxonomy_database.csv\",                          sep = \"/\")) ## Error: object 'DataPath' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.3 Save flags","title":"BeeBDC vignette","text":"SAVE flags far. find -recent flag file append new data . can double-check data number columns ’d like thorough sure data intact. <3","code":"flagFile <- BeeBDC::flagRecorder(   data = database,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = TRUE,   printSummary = TRUE) ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space","dir":"Articles","previous_headings":"","what":"5.0 Space","title":"BeeBDC vignette","text":"Read last database.","code":"if(!exists(\"database\")){ database <-   readr::read_csv(paste(OutPath_Intermediate, \"02_taxonomy_database.csv\", sep = \"/\"),                   col_types = BeeBDC::ColTypeR())}"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"coord-precision","dir":"Articles","previous_headings":"5.0 Space","what":"5.1 Coord precision","title":"BeeBDC vignette","text":"function identifies records coordinate precision specified number decimal places. example, precision coordinate 1 decimal place 11.132 km equator, .e., scale large city. major difference bdc BeeBDC functions jbd_coordinates_precision() flag occurrences lat lon rounded (opposed one ). “Coordinates one, two, three decimal places present precision ~11.1 km, ~1.1 km, ~111 m equator, respectively.” Remove spent dataset. Save harmonised file.","code":"check_space <-   BeeBDC::jbd_coordinates_precision(     data = database,     lon = \"decimalLongitude\",     lat = \"decimalLatitude\",     ndec = 2 # number of decimals to be tested   ) ## jbd_coordinates_precision: ## Flagged 61 records ## The '.rou' column was added to the database. rm(database) check_space %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"03_space_inter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"common-spatial-issues","dir":"Articles","previous_headings":"5.0 Space","what":"5.2 Common spatial issues","title":"BeeBDC vignette","text":"run occurrences clean_coordinates spatially ‘valid’. Next, flag common spatial issues using functions package CoordinateCleaner. addresses common issues biodiversity datasets. Re-merge datasets. Remove temporary dataset. Save intermediate dataset.","code":"tempSpace <- check_space %>%    dplyr::filter(!.coordinates_empty == FALSE) %>%   dplyr::filter(!.coordinates_outOfRange == FALSE) tempSpace <-   CoordinateCleaner::clean_coordinates(     x =  tempSpace,     lon = \"decimalLongitude\",     lat = \"decimalLatitude\",     species = \"scientificName\",     countries = NULL, # Tests if coords are from x country. This is not needed.     tests = c(       \"capitals\",     # records within 0.5 km of capitals centroids       \"centroids\",    # records within 1 km around country and province centroids       \"equal\",      # records with equal coordinates       \"gbif\",         # records within 1 km of GBIF headquarters. (says 1 degree in package, but code says 1000 m)       \"institutions\", # records within 100m of zoo and herbaria       \"zeros\"       # records with coordinates 0,0       # \"seas\"        # Not flagged as this should be flagged by coordinate country inconsistent     ),     capitals_rad = 1000,     centroids_rad = 500,     centroids_detail = \"both\", # test both country and province centroids     inst_rad = 100, # remove zoo and herbaria within 100m     range_rad = 0,     zeros_rad = 0.5,     capitals_ref = NULL,     centroids_ref = NULL,     country_ref = NULL,     country_refcol = \"countryCode\",     inst_ref = NULL,     range_ref = NULL,     # seas_scale = 50,     value = \"spatialvalid\" # result of tests are appended in separate columns   ) check_space <- tempSpace %>%   # Re-bind with the records that were removed earlier   dplyr::bind_rows(check_space %>%                       dplyr::filter(.coordinates_empty == FALSE |                                       .coordinates_outOfRange == FALSE) ) %>%   dplyr::select(!tidyselect::starts_with(\".summary\")) ## New names: ## • `.summary` -> `.summary...101` ## • `.summary` -> `.summary...112` rm(tempSpace) check_space %>%   readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_inter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"diagonal-grid","dir":"Articles","previous_headings":"5.0 Space","what":"5.3 Diagonal + grid","title":"BeeBDC vignette","text":"Finds sequential numbers fill-errors lat long, groups ‘groupingColumns’. accomplished using sliding window length determined minRepeats. coordinates precision ‘ndec’ (number decimals decimal degree format) examined. Note, function RAM-intensive use multiple threads approached caution depending dataset. However, option provided. Spatial gridding rasterisation: Select records X occurrences. Run gridding analysis find datasets might gridded. Integrate results main dataset. Save gridded_datasets file later examination. Now remove file.","code":"check_space <- BeeBDC::diagonAlley(   data = check_space,   # The minimum number of repeats needed to find a sequence in for flagging   minRepeats = 6,   ndec = 3,   groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),   mc.cores = 1) ## Removing rounded coordinates with BeeBDC::jbd_coordinates_precision... ## jbd_coordinates_precision: ## Removed 68 records. ##  ## jbd_diagonAlley: ## Flagged 0 records ## The .sequential column was added to the database. ##  - Completed in 0 secs griddingDF <- check_space %>%   # Exclude NA lat and lon values   tidyr::drop_na(c(\"decimalLatitude\", \"decimalLongitude\")) %>%   # Group by the dataset name   dplyr::group_by(datasetName) %>%   # Remove rows that aren't unique for lat and long   dplyr::distinct(decimalLongitude, decimalLatitude,                   .keep_all = TRUE) %>%   # Find the groups with 4 or more occurrence records    dplyr::filter(dplyr::n() >= 4) %>%   dplyr::ungroup() gridded_datasets <- CoordinateCleaner::cd_round(   x = griddingDF,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   ds = \"datasetName\",   T1 = 7,   min_unique_ds_size = 4,   test = \"both\",   value = \"dataset\",   graphs = FALSE,   verbose = TRUE,   reg_out_thresh = 2,   reg_dist_min = 0.1,   reg_dist_max = 2 ) %>%    dplyr::tibble() ## Testing for rasterized collection # The griddingDF is no longer needed. remove it. rm(griddingDF) check_space <- check_space %>%   # Join the datasets   dplyr::left_join(     # Select the columns of interest     dplyr::select(gridded_datasets, dataset, lon.flag, lat.flag, summary),     by = c(\"datasetName\" = \"dataset\")) %>%   # Make new columns with more-consistent naming and change the NA vlaues to = TRUE (not flagged)   dplyr::mutate(.lonFlag = tidyr::replace_na(lon.flag, TRUE),                 .latFlag = tidyr::replace_na(lat.flag, TRUE),                 .gridSummary = tidyr::replace_na(summary, TRUE)) %>%   # Remove old columns   dplyr::select(!c(lon.flag, lat.flag, summary)) gridded_datasets %>%   readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_griddedDatasets.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found rm(gridded_datasets)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"uncertainty","dir":"Articles","previous_headings":"5.0 Space","what":"5.4 Uncertainty","title":"BeeBDC vignette","text":"Flag records exceed coordinateUncertaintyInMeters threshold.","code":"check_space <- coordUncerFlagR(data = check_space,                                uncerColumn = \"coordinateUncertaintyInMeters\",                                threshold = 1000) ## \\coordUncerFlagR: ##  Flagged 33 geographically uncertain records: ##  The column '.uncertaintyThreshold' was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"country-checklist","dir":"Articles","previous_headings":"5.0 Space","what":"5.5 Country Checklist","title":"BeeBDC vignette","text":"Read country-level checklist.","code":"data(\"beesChecklist\", package = \"BeeBDC\") check_space <- BeeBDC::countryOutlieRs(checklist = beesChecklist,                         data = check_space,                         keepAdjacentCountry = TRUE,                         pointBuffer = 0.05,                           # Scale of map to return, one of 110, 50, 10 OR 'small', 'medium', 'large'                           # Smaller numbers will result in much longer calculation times.                            # We have not attempted a scale of 10.                         rnearthScale = 50,                         mc.cores = 4) ## dist is assumed to be in decimal degrees (arc_degrees). ##  - Extracting country data from points... ## although coordinates are longitude/latitude, st_intersection assumes that they ## are planar ##  - Buffering failed points by pointBuffer... ## dist is assumed to be in decimal degrees (arc_degrees). ## although coordinates are longitude/latitude, st_intersection assumes that they ## are planar ##  - Prepare the neighbouring country dataset... ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ##  - Compare points with the checklist... ##  - Combining data... ##  - Sorting and removing potentially duplicated buffered points... ##  - Finished.  ## We have matched 159 records to their exact country and 2 to an adjacent country ## We failed to match 0 occurrences to any 'exact' or 'neighbouring' country. ## There are 0 'NA' occurrences for this column. ## countryOutlieRs: ## Flagged 0  for country outlier and flagged  2  for in the .sea records. ## Three columns were added to the database: ##  1.  The '.countryOutlier' column was added which is a filtering column.  ##  2.  The 'countryMatch' columns indicates exact, neighbour, or noMatch.  ##  3. The '.sea' column was added as a filtering column for points in the ocean.  The '.sea' column includes the user input buffer in its calculation. ##  - Completed in 0.1 secs # A list of failed species-country combinations and their numbers can be output here check_space %>%   dplyr::filter(.countryOutlier == FALSE) %>%   dplyr::select(database_id, scientificName, country) %>%   dplyr::group_by(scientificName) %>%    dplyr::mutate(count_scientificName = n()) %>%   distinct(scientificName, country, .keep_all = TRUE) %>%    readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_failedCountryChecklist.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"map-spatial-errors","dir":"Articles","previous_headings":"5.0 Space","what":"5.6 Map spatial errors","title":"BeeBDC vignette","text":"Rebuild .summary column. Use col_to_map order map ONE spatial flag time map .summary column flags.","code":"check_space <- BeeBDC::summaryFun(   data = check_space,   dontFilterThese = NULL,   removeFilterColumns = FALSE,   filterClean = FALSE) ##  - We will flag all columns starting with '.' ##  - summaryFun: ## Flagged 124  ##   The .summary column was added to the database. check_space %>%   dplyr::filter(.summary == FALSE) %>% # map only records flagged as FALSE   bdc::bdc_quickmap(     data = .,     lon = \"decimalLongitude\",     lat = \"decimalLatitude\",     col_to_map = \".summary\",     size = 0.9   ) ## Loading required package: ggplot2 ## Error in `map_data()`: ## ! The package \"maps\" is required for `map_data()`"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space-report","dir":"Articles","previous_headings":"5.0 Space","what":"5.7 Space report","title":"BeeBDC vignette","text":"Create space report using bdc.","code":"(report <-    bdc::bdc_create_report(      data = dplyr::tibble(check_space %>% dplyr::select(!.uncer_terms)),      database_id = \"database_id\",      workflow_step = \"space\",      save_report = TRUE) ) ##  ## bdc_create_report: ## Check the report summarizing the results of the space in: ##  /home/runner/work/BeeBDC/BeeBDC/Output/Report"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space-figures","dir":"Articles","previous_headings":"5.0 Space","what":"5.8 Space figures","title":"BeeBDC vignette","text":"Create figures spatial data filtering results. Check figure, options : - .cap = Records around country capital centroid - .cen = Records around country province centroids - .dbl = Duplicated coordinates per species - .equ = Identical coordinates - .otl = Geographical outliers - .gbf = Records around GBIF headquarters - .inst = Records around biodiversity institutions - .rou = Rounded (probably imprecise) coordinates - .urb = Records within urban areas — (Likely relevant bees.) Save interim dataset.","code":"(figures <-     BeeBDC::jbd_create_figures(       data = dplyr::tibble(check_space %>% dplyr::select(!.uncer_terms)),       path = DataPath,       database_id = \"database_id\",       workflow_step = \"space\",       save_figures = TRUE) ) ## Error in eval(expr, envir, enclos): object 'DataPath' not found You can examine these figures, for example, by running:          figures$.rou check_space %>%   readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_inter_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-1","dir":"Articles","previous_headings":"5.0 Space","what":"5.9 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(   data = check_space,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = TRUE,   printSummary = TRUE) ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-1","dir":"Articles","previous_headings":"5.0 Space","what":"5.10 Save","title":"BeeBDC vignette","text":"Save intermediate dataset","code":"check_space %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"03_space_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time","dir":"Articles","previous_headings":"","what":"6.0 Time","title":"BeeBDC vignette","text":"Read last database, needed. can plot histogram dates .  Filter silly dates don’t make sense.","code":"if(!exists(\"check_space\")){   check_time <-     readr::read_csv(paste(OutPath_Intermediate, \"03_space_database.csv\", sep = \"/\"),                     col_types = BeeBDC::ColTypeR())   }else{   check_time <- check_space       # Remove the spent file   rm(check_space)} hist(lubridate::ymd_hms(check_time$eventDate, truncated = 5), breaks = 20) check_time$year <- ifelse(check_time$year > lubridate::year(Sys.Date()) | check_time$year < 1600,                         NA, check_time$year) check_time$month <- ifelse(check_time$month > 12 | check_time$month < 1,                          NA, check_time$month) check_time$day <- ifelse(check_time$day > 31 | check_time$day < 1,                        NA, check_time$day)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"recover-dates","dir":"Articles","previous_headings":"6.0 Time","what":"6.1 Recover dates","title":"BeeBDC vignette","text":"dateFindR() function search columns order find rescue dates may made correct columns. update eventDate, day, month, year columns data ) missing b) located one searched columns.","code":"check_time <- BeeBDC::dateFindR(data = check_time,                         # Years above this are removed (from the recovered dates only)                         maxYear = lubridate::year(Sys.Date()),                         # Years below this are removed (from the recovered dates only)                         minYear = 1700) ##  - Preparing data... ##  - Extracting dates from year, month, day columns... ##  - Extracting dates from fieldNotes, locationRemarks, and verbatimEventDate columns in unambiguous ymd, dmy, mdy, and my formats... ##  - Extracting year from fieldNotes, locationRemarks, and verbatimEventDate columns in ambiguous formats... ##  - Formating and combining the new data.. ##  - Merging all data, nearly there... ##  - Finished.  ## We rescued:  ## 175 occurrences with missing eventDate. ##  - As it stands, there are 175 complete eventDates and 30 missing dates. ##  - There are also 175 complete year occurrences to filter from. This is up from an initial count of 174 At this rate, you will stand to lose 30 occurrences on the basis of missing year - Operation time: 0.247704029083252 secs"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"no-eventdate","dir":"Articles","previous_headings":"6.0 Time","what":"6.2 No eventDate","title":"BeeBDC vignette","text":"Flag records simply lack collection date. :*(","code":"check_time <-   bdc::bdc_eventDate_empty(data = check_time, eventDate = \"eventDate\") ##  ## bdc_eventDate_empty: ## Flagged 30 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"old-records","dir":"Articles","previous_headings":"6.0 Time","what":"6.3 Old records","title":"BeeBDC vignette","text":"flag records prior date selected. 1970 frequently chosen SDM work. may need filter old records , think critically use. chosen 1950 lower extreme.","code":"check_time <-   bdc::bdc_year_outOfRange(data = check_time,                            eventDate = \"year\",                            year_threshold = 1950) ##  ## bdc_year_outOfRange: ## Flagged 21 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time-report","dir":"Articles","previous_headings":"6.0 Time","what":"6.4 Time report","title":"BeeBDC vignette","text":"time, just time pertaining precise occurrence records. Firstly, update .summary column.","code":"check_time <- BeeBDC::summaryFun(   data = check_time,   # Don't filter these columns (or NULL)   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\"),   # Remove the filtering columns?   removeFilterColumns = FALSE,   # Filter to ONLY cleaned data?   filterClean = FALSE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms ##  - summaryFun: ## Flagged 117  ##   The .summary column was added to the database. ( report <-     bdc::bdc_create_report(data = check_time,                            database_id = \"database_id\",                            workflow_step = \"time\",                            save_report = FALSE) )"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time-figures","dir":"Articles","previous_headings":"6.0 Time","what":"6.5 Time figures","title":"BeeBDC vignette","text":"Create time results figures. can check figures using… Save ~raw time dataset intermediate folder.","code":"figures <-   BeeBDC::jbd_create_figures(data = check_time,                      path = DataPath,                      database_id = \"database_id\",                      workflow_step = \"time\",                      save_figures = TRUE) ## Error in eval(expr, envir, enclos): object 'DataPath' not found figures$year ## Error in eval(expr, envir, enclos): object 'figures' not found check_time %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"04_time_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-2","dir":"Articles","previous_headings":"6.0 Time","what":"6.6 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(   data = check_time,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = TRUE,   printSummary = TRUE) ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"de-duplication","dir":"Articles","previous_headings":"","what":"7.0 De-duplication","title":"BeeBDC vignette","text":"raw dataset can re-read already exist.","code":"if(!exists(\"check_time\")){   check_time <-     readr::read_csv(paste(OutPath_Intermediate, \"04_time_database.csv\",                           sep = \"/\"),                     col_types = BeeBDC::ColTypeR())}"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"deduplicate","dir":"Articles","previous_headings":"7.0 De-duplication","what":"7.1 deDuplicate","title":"BeeBDC vignette","text":"FLAG duplicates . input columns can hacked de-duplicate wish. function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns. encourage , see ‘?dupeSummary()’ details function quite modifiable ot user needs. Save dataset intermediate folder.","code":"check_time <- BeeBDC::dupeSummary(   data = check_time,   path = OutPath_Report,    # options are \"ID\",\"collectionInfo\", or \"both\"   duplicatedBy = \"collectionInfo\",      # The columns to generate completeness info from (and to sort by completness)   completeness_cols = c(\"decimalLatitude\",  \"decimalLongitude\",                         \"scientificName\", \"eventDate\"),    # The columns to ADDITIONALLY consider when finding duplicates in collectionInfo   collectionCols = c(\"decimalLatitude\", \"decimalLongitude\", \"scientificName\", \"eventDate\",                       \"recordedBy\"),     # The columns to combine, one-by-one with the collectionCols   collectInfoColumns = c(\"catalogNumber\", \"otherCatalogNumbers\"),     # Custom comparisons — as a list of columns to compare      # RAW custom comparisons do not use the character and number thresholds   CustomComparisonsRAW = dplyr::lst(c(\"catalogNumber\", \"institutionCode\", \"scientificName\")),      # Other custom comparisons use the character and number thresholds   CustomComparisons = dplyr::lst(c(\"gbifID\", \"scientificName\"),                                   c(\"occurrenceID\", \"scientificName\"),                                   c(\"recordId\", \"scientificName\"),                                   c(\"id\", \"scientificName\")),    # The order in which you want to KEEP duplicated based on data source    # try unique(check_time$dataSource)   sourceOrder = c(\"CAES\", \"Gai\", \"Ecd\",\"BMont\", \"BMin\", \"EPEL\", \"ASP\", \"KP\", \"EcoS\", \"EaCO\",                   \"FSCA\", \"Bal\", \"SMC\", \"Lic\", \"Arm\",                   \"USGS\", \"ALA\", \"GBIF\",\"SCAN\",\"iDigBio\"),     # Paige ordering is done using the database_id prefix, not the dataSource prefix.   prefixOrder = c(\"Paige\", \"Dorey\"),     # Set the complexity threshold for id letter and number length      # minimum number of characters when WITH the numberThreshold   characterThreshold = 2,      # minimum number of numbers when WITH the characterThreshold   numberThreshold = 3,      # Minimum number of numbers WITHOUT any characters   numberOnlyThreshold = 5 ) %>% # END dupeSummary   dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) ## Loading required namespace: igraph ##  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. ## This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. ##  - Updating the .summary column to sort by... ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold, .unLicensed ##  - summaryFun: ## Flagged 93  ##   The .summary column was added to the database. ##  - Working on CustomComparisonsRAW duplicates... ##  ## Completed iteration 1 of 1: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## catalogNumber, institutionCode, scientificName ##  - Working on CustomComparisons duplicates... ##  ## Completed iteration 1 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## gbifID, scientificName ##  ## Completed iteration 2 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## occurrenceID, scientificName ##  ## Completed iteration 3 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## recordId, scientificName ##  ## Completed iteration 4 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## id, scientificName ##  - Working on collectionInfo duplicates... ##  ## Completed iteration 1 of 2: ##  - Identified 0 duplicate records and kept 0 unique records using the columns:  ## decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and catalogNumber ##  ## Completed iteration 2 of 2: ##  - Identified 0 duplicate records and kept 0 unique records using the columns:  ## decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and otherCatalogNumbers ##  - Clustering duplicate pairs... ## Duplicate pairs clustered. There are 0 duplicates across 0 kept duplicates. ##  - Ordering prefixs... ##  - Ordering data by 1. dataSource, 2. completeness and 3. .summary column... ##  - Find and FIRST duplicate to keep and assign other associated duplicates to that one (i.e., across multiple tests a 'kept duplicate', could otherwise be removed)... ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found check_time %>%   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"04_2_dup_database.csv\",                          sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-3","dir":"Articles","previous_headings":"7.0 De-duplication","what":"7.2 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(   data = check_time,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = TRUE,   printSummary = TRUE) ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-filtering","dir":"Articles","previous_headings":"","what":"8.0 Data filtering","title":"BeeBDC vignette","text":"dataset can re-read already exist.","code":"if(!exists(\"check_time\")){  check_time <-    readr::read_csv(paste(OutPath_Intermediate, \"04_2_dup_database.csv\",                           sep = \"/\"))}"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"rm-outliers","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.1 rm Outliers","title":"BeeBDC vignette","text":"Read -recent duplicates file (generated dupeSummary()) order identify duplicates expert outliers. Identify outliers get list database_ids. require source outlier files provided BeeBDC paper. files can modified include outliers.","code":"if(!exists(\"duplicates\")){   duplicates <- BeeBDC::fileFinder(path = DataPath,                             fileName = \"duplicateRun_\") %>%     readr::read_csv()} ## Error in eval(expr, envir, enclos): object 'DataPath' not found check_time <- BeeBDC::manualOutlierFindeR(   data = check_time,   DataPath = DataPath,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"^All_outliers_ANB_14March.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   # A .csv with manual outlier records that are too close to otherwise TRUE records   NearTRUE = \"nearTRUE.csv\",   duplicates = duplicates)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-uncleaned","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.2 Save uncleaned","title":"BeeBDC vignette","text":"Save uncleaned dataset.","code":"# Make sure that the .summary column is updated check_time <- BeeBDC::summaryFun(   data = check_time,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",                       \".uncertaintyThreshold\"),   removeFilterColumns = FALSE,   filterClean = FALSE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 93  ##   The .summary column was added to the database. # Save the uncleaned dataset check_time %>% readr::write_excel_csv(.,                                 paste(OutPath_Intermediate, \"05_unCleaned_database.csv\",                                       sep = \"/\")) ## Error: object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"filter","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.3 Filter","title":"BeeBDC vignette","text":"Now clean dataset extra columns failed rows save .","code":"BeeBDC::summaryFun(   data = check_time,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",                       \".uncertaintyThreshold\"),   # Remove the filtering columns?   removeFilterColumns = TRUE,   # Filter to ONLY cleaned data?   filterClean = TRUE) %>%  # Save this CLEANED dataset   readr::write_excel_csv(.,                    paste(OutPath_Intermediate, \"05_cleaned_database.csv\",                          sep = \"/\")) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 93  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column. ## Error: object 'OutPath_Intermediate' not found"},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"duplicate-chorddiagrams","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.1 Duplicate chordDiagrams","title":"BeeBDC vignette","text":"Install BiocManager ComplexHeatmap missed start. Read recent duplicate file, ’s already environment. Choose global figure parameters. Create chorDiagram. can leave many values show defaults. [internal] duplicates test dataset BeeBDC throw informative error. However, show full output figure bee dataset . Full chord diagram Dorey et al. 2023","code":"if (!require(\"BiocManager\", quietly = TRUE))   install.packages(\"BiocManager\") BiocManager::install(\"ComplexHeatmap\") ## 'getOption(\"repos\")' replaces Bioconductor standard repositories, see ## 'help(\"repositories\", package = \"BiocManager\")' for details. ## Replacement repositories: ##     CRAN: https://cloud.r-project.org ## Bioconductor version 3.17 (BiocManager 1.30.22), R 4.3.1 (2023-06-16) ## Installation paths not writeable, unable to update packages ##   path: /opt/R/4.3.1/lib/R/library ##   packages: ##     KernSmooth, Matrix, mgcv, nlme, spatial, survival ## Old packages: 'DT', 'labeling', 'pak' if(!exists(\"duplicates\")){   duplicates <- BeeBDC::fileFinder(path = DataPath,                             fileName = \"duplicateRun_\") %>%     readr::read_csv()} ## Error in eval(expr, envir, enclos): object 'DataPath' not found par(mar = c(2, 2, 2, 2)/2, mfrow = c(1,1)) BeeBDC::chordDiagramR(   # The duplicate data from the dupeSummary function output     dupeData = duplicates,   outPath = OutPath_Figures,   fileName = \"ChordDiagram.pdf\",   # These can be modified to help fit the final pdf that's exported.   width = 9,   height = 7.5,   bg = \"white\",   # How few distinct dataSources should a group have to be listed as \"other\"   smallGrpThreshold = 3,   title = \"Duplicated record sources\",   # The default list of colour palettes to choose from usign the paleteer package   palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",                 \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",                \"cartography::purple.pal\", \"cartography::brown.pal\"),   canvas.ylim = c(-1.0,1.0),    canvas.xlim = c(-0.6, 0.25),   text.col = \"black\",   legendX = grid::unit(6, \"mm\"),   legendY = grid::unit(18, \"mm\"),   legendJustify = c(\"left\", \"bottom\"),   niceFacing = TRUE) ## Error in eval(expr, envir, enclos): object 'duplicates' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"duplicate-histogram","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.2 Duplicate histogram","title":"BeeBDC vignette","text":"Read uncleaned dataset, ’s already present. Create plot two bar graphs. One shows absolute number duplicate records data source shows proportion records duplicated within data source. (‘dataSource’ simplified text first underscore).","code":"if(!exists(\"check_time\")){ beeData <- readr::read_csv(paste(OutPath_Intermediate, \"05_unCleaned_database.csv\",                                  sep = \"/\"),                            col_types = BeeBDC::ColTypeR()) }else{   beeData <- check_time   rm(check_time) } BeeBDC::dupePlotR(   data = beeData,   # The outPath to save the plot as   outPath = OutPath_Figures,   fileName = \"duplicatePlot.pdf\",   # Colours in order: duplicate, kept duplicate, unique   dupeColours = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"),   # Plot size and height   base_height = 7, base_width = 7,   legend.position = c(0.85, 0.8),   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", Ecd = \"Ecd\",   returnPlot = TRUE ) ## Loading required namespace: forcats ## Loading required namespace: cowplot ## Error in eval(expr, envir, enclos): object 'OutPath_Figures' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flags-by-source","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.3 Flags by source","title":"BeeBDC vignette","text":"Create compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE. (dataSource simplified text first underscore.)","code":"BeeBDC::plotFlagSummary(   data = beeData,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"FlagsPlot_\", Sys.Date(),\".pdf\"),   outPath = paste0(OutPath_Figures),   width = 15, height = 9,     # OPTIONAL:       #   # Filter to a single species       #       speciesName = \"Holcopasites heliopsis\",       #         # column to look in       #       nameColumn = \"species\",       #        # Save the filtered data       #       saveFiltered = TRUE,       #   # Filter column to display on map       #       filterColumn = \".summary\",       #       plotMap = TRUE,       #   # amount to jitter points if desired, e.g. 0.25 or NULL       #       jitterValue = NULL,       #        # Map opacity value for points between 0 and 1       #   mapAlpha = 1,       #        # If a user wants to output the table used to make the figure, change this to TRUE       #   saveTable = FALSE,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'BMont' = \"BMont\", 'BMin' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\",   returnPlot = TRUE ) ## Error in eval(expr, envir, enclos): object 'OutPath_Figures' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"maps","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.4 Maps","title":"BeeBDC vignette","text":"Import CLEANED dataset (can change option).","code":"mapData <- readr::read_csv(paste(OutPath_Intermediate, \"05_cleaned_database.csv\",                                  sep = \"/\"),                            col_types = BeeBDC::ColTypeR()) ## Error in eval(expr, envir, enclos): object 'OutPath_Intermediate' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--summary-maps","dir":"Articles","previous_headings":"9.0 Figures and tables > 9.4 Maps","what":"a. Summary maps","title":"BeeBDC vignette","text":"Draw global summary map occurrence species number country.","code":"BeeBDC::summaryMaps(   data = mapData,   width = 10, height = 10,   class_n = 3,   class_Style = \"fisher\",   fileName = \"CountryMaps_fisher.pdf\",   outPath = OutPath_Figures ) ## Error in eval(expr, envir, enclos): object 'mapData' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--interactive-maps","dir":"Articles","previous_headings":"9.0 Figures and tables > 9.4 Maps","what":"b. Interactive maps","title":"BeeBDC vignette","text":"Use occurrence data (preferably uncleaned order show pass/fail points) outputs interactive .html maps, can opened browser, specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can updated first running summaryFun() choose columns want highlighted. also highlight occurrences flagged expert-identified country outliers separately. function can categorical variable fed ‘speciesColumn’, users may choose another column interest map; however, large categories can slow produce unwieldy view.","code":"BeeBDC::interactiveMapR(    # occurrence data   data = beeData,    # Directory where to save files   outPath = paste0(OutPath_Figures, \"interactiveMaps\", sep = \"/\"),   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",     # Occurrence dataset column with species names   speciesColumn = \"scientificName\",     # Which species to map — a character vector of names or \"ALL\"     # Note: \"ALL\" is defined AFTER filtering for country   speciesList = \"ALL\",   countryList = NULL, # studyArea     # Point jitter to see stacked points — jitters an amount in decimal degrees   jitterValue = 0.01 ) ## Loading required namespace: leaflet ## Error in eval(expr, envir, enclos): object 'OutPath_Figures' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-providers","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.5 Data providers","title":"BeeBDC vignette","text":"Read clean data ’s already environment. function attempt find build table data providers contributed input data, especially using ‘institutionCode’ column. also look variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions (perhaps lesser degree).","code":"if(!exists(\"mapData\")){   mapData <- readr::read_csv(paste(OutPath_Intermediate, \"05_cleaned_database.csv\",                                 sep = \"/\"),                           col_types = BeeBDC::ColTypeR(),   locale = readr::locale(encoding = \"UTF-8\"))} ## Error in eval(expr, envir, enclos): object 'OutPath_Intermediate' not found dataProvTable <- BeeBDC::dataProvTables(data = mapData,                                         runBeeDataChecks = TRUE,                                         outPath = OutPath_Report,                                         fileName = \"dataProvTable.csv\") ## Error in eval(expr, envir, enclos): object 'mapData' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-summary","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.6 Flag summary","title":"BeeBDC vignette","text":"Takes flagged dataset returns total number fails (FALSE) per flag (columns starting “.”) per species. Users may define column group summary . intended work scientificName column, users may select grouping column (e.g., country). Fin.","code":"summaryTable <- BeeBDC::flagSummaryTable(data = beeData,                                           column = \"scientificName\",                                           outPath = OutPath_Report,                                          fileName = \"flagTable.csv\") ##  - We will flag all columns starting with '.' ##  - summaryFun: ## Flagged 135  ##   The .summary column was added to the database. ## Error in eval(expr, envir, enclos): object 'OutPath_Report' not found"},{"path":"https://jbdorey.github.io/BeeBDC/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James B. Dorey. Author, maintainer, copyright holder. Robert O'Reilly. Author. Silas Bossert. Author. Fischer Fischer. Author.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Dorey, J. B., Chesshire, P. R., Bolaños, . N., O’reilly, R. L., Bossert, S., Collins, S. M., Lichtenberg, E. M., Tucker, E., Smith-Pardo, ., Falcon-Brindis, ., Guevara, D. ., Ribeiro, B. R., De Pedro, D., Fischer, E., Hung, J. K.-L., Parys, K. ., Rogan, M. S., Minckley, R. L., Velzco, S. J. E., Griswold, T., Zarrillo, T. ., Sica, Y., Orr, M. C., Guzman, L. M., Ascher, J., Hughes, . C. & Cobb, N. S. review. BeeBDC: new R package globally synthesised flagged bee occurrence dataset. Scientific Data. Dorey, J. B., O’Reilly, R. L., Bossert, S., Fischer, E. (2023). BeeBDC: occurrence data cleaning package. R package version 0.0.5. url: https://github.com/jbdorey/BeeBDC","code":"@Article{,   title = {BeeBDC: A new R package and globally synthesised and flagged bee occurrence dataset},   author = {{Dorey, James B [aut],Chesshire, Paige R [aut],Bolaños, Angela N [aut],O’Reilly, Robert L [aut],Bossert, Silas [aut],Collins, Shannon M [aut],Lichtenberg, Elinor M [aut],Tucker, Erika [aut],Smith-Pardo, Allan [aut],Falcon-Brindis, Armando [aut],Guevara, Diego A [aut],Ribeiro, Bruno R [aut],de Pedro, Diego [aut],Fischer, Erica [aut],Hung, James Keng-Lou [aut],Parys, Katherine A [aut],Rogan, Matthew S [aut],Minckley, Robert L [aut],Velzco, Santiago J E [aut],Griswold, Terry [aut],Zarrillo, Tracy A [aut],Sica, Yanina [aut],Orr, Michael C [aut],Guzman, Laura Melissa [aut],Ascher, John [aut],Hughes, Alice C [aut],Cobb, Neil S [aut]}},   journal = {Scientific Data},   year = {2023},   volume = {1},   number = {1},   pages = {1},   url = {NA}, } @Manual{,   title = {BeeBDC: an occurrence data cleaning package},   author = {{Dorey, James B [aut],O’Reilly, Robert L [aut],Bossert, Silas [aut],Fischer, Erica [aut]}},   year = {2023},   note = {R package version 0.0.1},   url = {https://github.com/jbdorey/BeeBDC}, }"},{"path":[]},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"overview","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Overview","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"consistent implementation biodiversity data continues challenge ecological researchers. present BeeBDC package provides novel udpated functions flagging, cleaning, visualising occurrence datasets. functions mostly general nature also provide functions data specific use bee occurrence data. build upon functions conventions fantastic R packages, especially bdc CoordinateCleaner. Hence, package name Bee Biodiversity Data Cleaning (BeeBDC). provide full workflow uses BeeBDC, bdc, CoordinateCleaner clean occurrence data Articles page encourage users read also cite primary publication.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"structure-of-beebdc","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Structure of BeeBDC","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"BeeBDC toolkit organized using conventions set bdc, modules related different biodiversity dimensions. ⚠️ modules illustrated, functions within, linked form proposed reproducible workflow (see vignettes). However, functions can also executed independently.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_1-data-merge","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"1. Data merge","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Integrate merge different datasets major data repositories — GBIF, SCAN, iDigBio, USGS, ALA. atlasDownloader() Downloads ALA data creates new file path put data. function can also request downloads atlases (see: http://galah.ala.org.au/articles/choosing_an_atlas.html). However, send download email must rest point. repoMerge() Locates data GBIF, ALA, iDigBio, SCAN within directory reads along eml metadata. repoFinder() Find GBIF, ALA, iDigBio, SCAN files directory. importOccurrences() Looks imports -recent version occurrence data created repoMerge() function. USGS_formatter() function finds, imports, formats, creates metadata USGS dataset. formattedCombiner() Merges Darwin Core version USGS dataset created using USGS_formatter() main dataset. dataSaver() Used end 1.x example workflow order save occurrence dataset associated eml metadata.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_2-data-preperation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"2. Data preperation","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"reading formatting major minor [bee] occurrence repositories well data modifications. section mostly, entirely, related bee occurrence data. fileFinder() function can used find files within user-defined directory based user-provided character string. PaigeIntegrater() Replaces publicly available data data manually cleaned error-corrected use paper Chesshire, P. R., Fischer, E. E., Dowdy, N. J., Griswold, T., Hughes, . C., Orr, M. J., . . . McCabe, L. M. (Press). Completeness analysis 3000 United States bee species identifies persistent data gaps. Ecography. readr_BeeBDC() Read variety data files specific certain smaller data providers. internal readr function dataset one functions called readr_BeeBDC. functions internal, displayed documentation readr_BeeBDC clarity. idMatchR() function attempts match database_ids prior bdc BeeBDC run order keep column somewhat consistent iterations. However, records contain sufficient information work flawlessly.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_3-initial-flags","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"3. Initial flags","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Flagging carpentry several, mostly general, data issues. See bdc’s pre-filter related functions. countryNameCleanR() basic function user manually fix country name inconsistencies. jbd_CfC_chunker() jbd_country_from_coordinates() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_country_from_coordinates(). jbd_Ctrans_chunker() jbd_coordinates_transposed() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_coordinates_transposed(). jbd_coordCountryInconsistent() Compares stated country name occurrence record record’s coordinates using rnaturalearth data. prefix, jbd_ meant distinguish function original bdc::bdc_coordinates_country_inconsistent(). flagAbsent() Flags occurrences “ABSENT” occurrenceStatus (user-specified) column. GBIFissues() function flag records subject user-specified vector GBIF issues. flagRecorder() function used save flag data occurrence data run BeeBDC script. read append existing files, asked . flags also saved occurrence file automatically.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_4-taxonomy","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"4. Taxonomy","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Harmonisation scientific names custom taxonomy provided Discover Life website’s taxonomic reference. harmoniseR() Uses Discover Life taxonomy harmonise bee occurrences flag match checklist. function hijacked service taxa user matched format beesTaxonomy file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_5-space","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"5. Space","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Flagging erroneous, suspicious, low-precision geographic coordinates. jbd_coordinates_precision() function flags occurrences latitude longitude values rounded. contrasts original function, bdc::bdc_coordinates_precision() flag occurrences one latitude longitude rounded. BeeBDC approach saves occurrences may terminal zeros rounded one coordinate column. diagonAlley() simple function looks potential latitude longitude fill-errors identifying consecutive occurrences coordinates regular intervals. accomplished using sliding window length determined minRepeats. coordUncerFlagR() use function, user must choose column, probably “coordinateUncertaintyInMeters” threshold occurrences flagged geographic uncertainty. countryOutlieRs() function flags country-level outliers using checklist provided package. additional context column names, see ?beesChecklist(). jbd_create_figures() Creates figures (.e., bar plots, maps, histograms) reporting results data quality tests implemented bdc BeeBDC packages. Works like bdc::bdc_create_figures(), allows user specify save path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_6-time","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"6. Time","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Flagging , whenever possible, correction inconsistent collection date. dateFindR() function made search columns dates add eventDate column. function searches columns locality, fieldNotes, locationRemarks, verbatimEventDate relevant information.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_7-de-duplication","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"7. De-duplication","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"dupeSummary() function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_8-filtering","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"8. Filtering","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"manualOutlierFindeR() Uses expert-identified outliers source spreadsheets may edited users. function also use duplicates file made using dupeSummary() identify duplicates expert-identified outliers flag well. function add flagging column called .expertOutlier records FALSE expert outliers. summaryFun() Using flag columns (column names starting “.”), function either creates updates .summary flag column FALSE flag columns FALSE. Columns can excluded removed creating .summary column. Additionally, occurrence dataset can filtered .summary = TRUE end function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_9-figures-and-tables","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"9. Figures and tables","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"chordDiagramR() function outputs figure shows relative size direction occurrence points duplicated data providers, , SCAN, GBIF, ALA, etc. dupePlotR() Creates plot two bar graphs. One shows absolute number duplicate records data source shows proportion records duplicated within data source. plotFlagSummary() Creates compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE. summaryMaps() Builds output figure shows number species number occurrences per country. Breaks data classes visualisation. Users may filter data taxa interest produce figures interest. interactiveMapR() Uses occurrence data (preferably uncleaned) outputs interactive .html maps can opened browser specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can modified first running summaryFun() set columns want highlighted. can also highlight occurrences flagged expert-identified country outliers. dataProvTables() function attempt find build table data providers contributed input data, especially using ‘institutionCode’ column. also look variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions. flagSummaryTable() Takes flagged dataset returns total number fails (FALSE) per flag (columns starting “.”) per species. Users may define column group summary . intended work scientificName column, users may select grouping column (e.g., country).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"installation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Installation","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"can install BeeBDC GitHub Load package :","code":"# Some dependencies if (!require(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\") if (!require(\"devtools\", quietly = TRUE))     install.packages(\"devtools\")  devtools::install_github(\"ropensci/rnaturalearthhires\") BiocManager::install(\"ComplexHeatmap\")  remotes::install_github(\"https://github.com/jbdorey/BeeBDC.git\", ref = \"main\",                          auth_token = \"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\") library(BeeBDC)"},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"package-website","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Package website","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"See BeeBDC package website (https://jbdorey.github.io/BeeBDC/reference/index.html) detailed explanation module.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"getting-help","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Getting help","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"encounter clear bug, please file issue . questions suggestion, please send us email (jbdorey@icloud.com).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"citation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Citation","title":"BeeBDC: an Occurrence Data Cleaning Package","text":"Paper, dataset, package citation: Dorey, J. B., Chesshire, P. R., Bolaños, . N., O’reilly, R. L., Bossert, S., Collins, S. M., Lichtenberg, E. M., Tucker, E., Smith-Pardo, ., Falcon-Brindis, ., Guevara, D. ., Ribeiro, B. R., De Pedro, D., Fischer, E., Hung, J. K.-L., Parys, K. ., Rogan, M. S., Minckley, R. L., Velzco, S. J. E., Griswold, T., Zarrillo, T. ., Sica, Y., Orr, M. C., Guzman, L. M., Ascher, J., Hughes, . C. & Cobb, N. S. review. BeeBDC: new R package globally synthesised flagged bee occurrence dataset. Scientific Data. Package citation: Dorey, J. B., O’Reilly, R. L., Bossert, S., Fischer, E. (2023). BeeBDC: occurrence data cleaning package. R package version 0.2.8. url: https://github.com/jbdorey/BeeBDC","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the bee taxonomy and country checklist — BeeBDCQuery","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"simple function return information particular species, including name validity country occurrences.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"","code":"BeeBDCQuery(beeName = NULL, searchChecklist = TRUE, printAllSynonyms = FALSE)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"beeName Character character vector. single several bee species names search beesTaxonomy beesChecklist tables. searchChecklist Logical. TRUE (default), search country checklist species. printAllSynonyms Logical. TRUE, synonyms printed entered name. default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"Returns list elements 'taxonomyReport' 'SynonymReport'. searchChecklist TRUE, 'checklistReport' also returned.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"","code":"# Single entry example testQuery <- BeeBDCQuery(   beeName = \"Homalictus fijiensis\",   searchChecklist = TRUE,   printAllSynonyms = TRUE) #> Starting taxonomy report... #> Homalictus fijiensis is a synonym of Lasioglossum fijiense (Perkins and Cheesman, 1928) with the taxon id number 32620. #>  - 'Homalictus fijiensis' has the synonyms: Halictus fijiensis Perkins and Cheesman, 1928, Halictus suvaensis Cockerell, 1929, Homalictus fijiensis (Perkins and Cheesman, 1928) #> Starting checklist report... #>  - Lasioglossum fijiense (Perkins and Cheesman, 1928) is reportedly found in:  #> Fiji, Solomon Islands #> The output will be returned as a list with the elements: 'taxonomyReport', 'SynonymReport', and 'checklistReport'.  #> These can be accessed using 'output'$taxonomyReport, 'output'$SynonymReport, 'output'$checklistReport, or 'output'$failedReport.    # Multiple entry example testQuery <- BeeBDCQuery(   beeName = c(\"Homalictus fijiensis\", \"Homalictus urbanus\",   \"Lasioglossum fijiense (Perkins and Cheesman, 1928)\"),   searchChecklist = TRUE,   printAllSynonyms = TRUE) #> Starting taxonomy report... #> Lasioglossum fijiense (Perkins and Cheesman, 1928) is an accpeted name with the taxon id number 32620. #> Homalictus fijiensis is a synonym of Lasioglossum fijiense (Perkins and Cheesman, 1928) with the taxon id number 32620. #> Homalictus urbanus is a synonym of Lasioglossum urbanum (Smith, 1879) with the taxon id number 36429. #>  - 'Lasioglossum fijiense (Perkins and Cheesman, 1928)' has the synonyms: Halictus fijiensis Perkins and Cheesman, 1928, Halictus suvaensis Cockerell, 1929, Homalictus fijiensis (Perkins and Cheesman, 1928), Halictus fijiensis Perkins and Cheesman, 1928, Halictus suvaensis Cockerell, 1929, Homalictus fijiensis (Perkins and Cheesman, 1928) #>  - 'Homalictus fijiensis' has the synonyms: Halictus fijiensis Perkins and Cheesman, 1928, Halictus suvaensis Cockerell, 1929, Homalictus fijiensis (Perkins and Cheesman, 1928), Halictus fijiensis Perkins and Cheesman, 1928, Halictus suvaensis Cockerell, 1929, Homalictus fijiensis (Perkins and Cheesman, 1928) #>  - 'Homalictus urbanus' has the synonyms: Halictus urbanus Smith, 1879, Halictus urbanus baudinensis Cockerell, 1905, Halictus cretinicola Friese, 1909, Halictus kesteveni Cockerell, 1912, Halictus hackeriellus Cockerell, 1914, Halictus pavonellus Cockerell, 1915, Halictus olivinus Cockerell, 1922, Halictus urbanus var lomatiae Cockerell, 1922, Halictus microchalceus Cockerell, 1929, Halictus subcarus Cockerell, 1930, Halictus williamsi Cockerell, 1930, Halictus suburbanus Cockerell, 1930, Halictus aponi Cheesman and Perkins, 1939, Halictus aponi var erromangana Cheesman and Perkins, 1939, Homalictus urbanus (Smith, 1879), Homalictus urbanus aponi (Cheesman and Perkins, 1939) #> Starting checklist report... #>  - Lasioglossum fijiense (Perkins and Cheesman, 1928) is reportedly found in:  #> Fiji, Solomon Islands #>  - Lasioglossum fijiense (Perkins and Cheesman, 1928) is reportedly found in:  #> Fiji, Solomon Islands #> The output will be returned as a list with the elements: 'taxonomyReport', 'SynonymReport', and 'checklistReport'.  #> These can be accessed using 'output'$taxonomyReport, 'output'$SynonymReport, 'output'$checklistReport, or 'output'$failedReport.        # Example way to examine a report from the output list   testQuery$checklistReport #> # A tibble: 7 × 23 #>   validName      DiscoverLife_name rNaturalEarth_name shortName DiscoverLife_ISO #>   <chr>          <chr>             <chr>              <chr>     <chr>            #> 1 Lasioglossum … Fiji              Fiji               Fiji      FJ               #> 2 Lasioglossum … Solomon Islands   Solomon Islands    Solomon … BP               #> 3 Lasioglossum … Australia         Australia          Australia AS               #> 4 Lasioglossum … Indonesia         Indonesia          Indonesia ID               #> 5 Lasioglossum … New Caledonia     New Caledonia      New Cale… NC               #> 6 Lasioglossum … Papua New Guinea  Papua New Guinea   Papua Ne… PP               #> 7 Lasioglossum … Vanuatu           Vanuatu            Vanuatu   NH               #> # ℹ 18 more variables: `Alpha-2` <chr>, `Alpha-3` <chr>, official <chr>, #> #   Source <chr>, matchCertainty <chr>, canonical <chr>, #> #   canonical_withFlags <chr>, family <chr>, subfamily <chr>, genus <chr>, #> #   subgenus <lgl>, specificEpithet <chr>, species <chr>, infraspecies <chr>, #> #   scientificNameAuthorship <chr>, taxon_rank <chr>, #> #   infraspecificEpithet <chr>, Notes <chr>"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up column names and types — ColTypeR","title":"Sets up column names and types — ColTypeR","text":"function uses readr::cols_only() assign column name type data (e.g., readr::col_character(), readr::col_integer()). see default columns simply run ColTypeR(). intended use readr::read_csv(). Columns present included resulting tibble unless specified using ....","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up column names and types — ColTypeR","text":"","code":"ColTypeR(...)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up column names and types — ColTypeR","text":"... Additional arguments. can specified addition ones default function.  example: newCharacterColumn = readr::col_character(), newNumericColumn = readr::col_integer(), newLogicalColumn = readr::col_logical()","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up column names and types — ColTypeR","text":"Returns object class col_spec. See readr::.col_spec() additional context explication.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up column names and types — ColTypeR","text":"","code":"# You can simply return the below for default values   library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union BeeBDC::ColTypeR()  #> cols_only( #>   database_id = col_character(), #>   scientificName = col_character(), #>   family = col_character(), #>   subfamily = col_character(), #>   genus = col_character(), #>   subgenus = col_character(), #>   subspecies = col_character(), #>   species = col_character(), #>   specificEpithet = col_character(), #>   infraspecificEpithet = col_character(), #>   acceptedNameUsage = col_character(), #>   taxonRank = col_character(), #>   scientificNameAuthorship = col_character(), #>   identificationQualifier = col_character(), #>   higherClassification = col_character(), #>   identificationReferences = col_character(), #>   typeStatus = col_character(), #>   previousIdentifications = col_character(), #>   verbatimIdentification = col_character(), #>   identifiedBy = col_character(), #>   dateIdentified = col_character(), #>   decimalLatitude = col_double(), #>   decimalLongitude = col_double(), #>   verbatimLatitude = col_character(), #>   verbatimLongitude = col_character(), #>   verbatimElevation = col_character(), #>   stateProvince = col_character(), #>   country = col_character(), #>   continent = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   locality = col_character(), #>   island = col_character(), #>   county = col_character(), #>   municipality = col_character(), #>   countryCode = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   license = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   issue = col_character(), #>   eventDate = col_character(), #>   eventTime = col_character(), #>   startDayOfYear = col_integer(), #>   endDayOfYear = col_integer(), #>   day = col_integer(), #>   month = col_integer(), #>   year = col_integer(), #>   basisOfRecord = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   type = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   recordNumber = col_character(), #>   recordedBy = col_character(), #>   eventID = col_character(), #>   Location = col_character(), #>   samplingProtocol = col_character(), #>   samplingEffort = col_character(), #>   individualCount = col_double(), #>   organismQuantity = col_double(), #>   coordinatePrecision = col_double(), #>   coordinateUncertaintyInMeters = col_double(), #>   spatiallyValid = col_logical(), #>   catalogNumber = col_character(), #>   gbifID = col_character(), #>   datasetID = col_character(), #>   institutionCode = col_character(), #>   datasetName = col_character(), #>   otherCatalogNumbers = col_character(), #>   occurrenceID = col_character(), #>   taxonKey = col_character(), #>   coreid = col_character(), #>   recordId = col_character(), #>   collectionID = col_character(), #>   associatedSequences = col_character(), #>   verbatimScientificName = col_character(), #>   verbatimEventDate = col_character(), #>   associatedTaxa = col_character(), #>   associatedOrganisms = col_character(), #>   fieldNotes = col_character(), #>   sex = col_character(), #>   rights = col_character(), #>   rightsHolder = col_character(), #>   accessRights = col_character(), #>   dctermsLicense = col_character(), #>   dctermsType = col_character(), #>   dctermsAccessRights = col_character(), #>   associatedReferences = col_character(), #>   bibliographicCitation = col_character(), #>   dctermsBibliographicCitation = col_character(), #>   references = col_character(), #>   flags = col_character(), #>   informationWithheld = col_character(), #>   isDuplicateOf = col_character(), #>   hasCoordinate = col_logical(), #>   hasGeospatialIssues = col_logical(), #>   assertions = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceYear = col_datetime(format = \"\"), #>   id = col_character(), #>   duplicateStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   associatedOccurrences = col_character(), #>   locationRemarks = col_character(), #>   dataSource = col_character(), #>   dataBase_scientificName = col_character(), #>   .rou = col_logical(), #>   .val = col_logical(), #>   .equ = col_logical(), #>   .zer = col_logical(), #>   .cap = col_logical(), #>   .cen = col_logical(), #>   .sea = col_logical(), #>   .otl = col_logical(), #>   .gbf = col_logical(), #>   .inst = col_logical(), #>   .dpl = col_logical(), #>   .summary = col_logical(), #>   names_clean = col_character(), #>   verbatim_scientificName = col_character(), #>   .uncer_terms = col_logical(), #>   .eventDate_empty = col_logical(), #>   .year_outOfRange = col_logical(), #>   .duplicates = col_logical(), #>   .lonFlag = col_logical(), #>   .latFlag = col_logical(), #>   .gridSummary = col_logical(), #>   .basisOfRecords_notStandard = col_logical(), #>   .scientificName_empty = col_logical(), #>   .coordinates_empty = col_logical(), #>   .coordinates_outOfRange = col_logical(), #>   coordinates_transposed = col_logical(), #>   country_suggested = col_character(), #>   .countryOutlier = col_logical(), #>   countryMatch = col_character(), #>   .expertOutlier = col_logical(), #>   .occurrenceAbsent = col_logical(), #>   .coordinates_country_inconsistent = col_logical(), #>   .unLicensed = col_logical(), #>   .invalidName = col_logical(), #>   .sequential = col_logical(), #>   idContinuity = col_logical(), #>   .uncertaintyThreshold = col_logical(), #>   .GBIFflags = col_logical(), #>   finalLatitude = col_double(), #>   finalLongitude = col_double(), #>   Source = col_character() #> )    # To add new columns you can write ColTypeR(newCharacterColumn = readr::col_character(),           newNumericColumn = readr::col_integer(),           newLogicalColumn = readr::col_logical())  #> cols_only( #>   database_id = col_character(), #>   scientificName = col_character(), #>   family = col_character(), #>   subfamily = col_character(), #>   genus = col_character(), #>   subgenus = col_character(), #>   subspecies = col_character(), #>   species = col_character(), #>   specificEpithet = col_character(), #>   infraspecificEpithet = col_character(), #>   acceptedNameUsage = col_character(), #>   taxonRank = col_character(), #>   scientificNameAuthorship = col_character(), #>   identificationQualifier = col_character(), #>   higherClassification = col_character(), #>   identificationReferences = col_character(), #>   typeStatus = col_character(), #>   previousIdentifications = col_character(), #>   verbatimIdentification = col_character(), #>   identifiedBy = col_character(), #>   dateIdentified = col_character(), #>   decimalLatitude = col_double(), #>   decimalLongitude = col_double(), #>   verbatimLatitude = col_character(), #>   verbatimLongitude = col_character(), #>   verbatimElevation = col_character(), #>   stateProvince = col_character(), #>   country = col_character(), #>   continent = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   locality = col_character(), #>   island = col_character(), #>   county = col_character(), #>   municipality = col_character(), #>   countryCode = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   license = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   issue = col_character(), #>   eventDate = col_character(), #>   eventTime = col_character(), #>   startDayOfYear = col_integer(), #>   endDayOfYear = col_integer(), #>   day = col_integer(), #>   month = col_integer(), #>   year = col_integer(), #>   basisOfRecord = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   type = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   recordNumber = col_character(), #>   recordedBy = col_character(), #>   eventID = col_character(), #>   Location = col_character(), #>   samplingProtocol = col_character(), #>   samplingEffort = col_character(), #>   individualCount = col_double(), #>   organismQuantity = col_double(), #>   coordinatePrecision = col_double(), #>   coordinateUncertaintyInMeters = col_double(), #>   spatiallyValid = col_logical(), #>   catalogNumber = col_character(), #>   gbifID = col_character(), #>   datasetID = col_character(), #>   institutionCode = col_character(), #>   datasetName = col_character(), #>   otherCatalogNumbers = col_character(), #>   occurrenceID = col_character(), #>   taxonKey = col_character(), #>   coreid = col_character(), #>   recordId = col_character(), #>   collectionID = col_character(), #>   associatedSequences = col_character(), #>   verbatimScientificName = col_character(), #>   verbatimEventDate = col_character(), #>   associatedTaxa = col_character(), #>   associatedOrganisms = col_character(), #>   fieldNotes = col_character(), #>   sex = col_character(), #>   rights = col_character(), #>   rightsHolder = col_character(), #>   accessRights = col_character(), #>   dctermsLicense = col_character(), #>   dctermsType = col_character(), #>   dctermsAccessRights = col_character(), #>   associatedReferences = col_character(), #>   bibliographicCitation = col_character(), #>   dctermsBibliographicCitation = col_character(), #>   references = col_character(), #>   flags = col_character(), #>   informationWithheld = col_character(), #>   isDuplicateOf = col_character(), #>   hasCoordinate = col_logical(), #>   hasGeospatialIssues = col_logical(), #>   assertions = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceYear = col_datetime(format = \"\"), #>   id = col_character(), #>   duplicateStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   associatedOccurrences = col_character(), #>   locationRemarks = col_character(), #>   dataSource = col_character(), #>   dataBase_scientificName = col_character(), #>   .rou = col_logical(), #>   .val = col_logical(), #>   .equ = col_logical(), #>   .zer = col_logical(), #>   .cap = col_logical(), #>   .cen = col_logical(), #>   .sea = col_logical(), #>   .otl = col_logical(), #>   .gbf = col_logical(), #>   .inst = col_logical(), #>   .dpl = col_logical(), #>   .summary = col_logical(), #>   names_clean = col_character(), #>   verbatim_scientificName = col_character(), #>   .uncer_terms = col_logical(), #>   .eventDate_empty = col_logical(), #>   .year_outOfRange = col_logical(), #>   .duplicates = col_logical(), #>   .lonFlag = col_logical(), #>   .latFlag = col_logical(), #>   .gridSummary = col_logical(), #>   .basisOfRecords_notStandard = col_logical(), #>   .scientificName_empty = col_logical(), #>   .coordinates_empty = col_logical(), #>   .coordinates_outOfRange = col_logical(), #>   coordinates_transposed = col_logical(), #>   country_suggested = col_character(), #>   .countryOutlier = col_logical(), #>   countryMatch = col_character(), #>   .expertOutlier = col_logical(), #>   .occurrenceAbsent = col_logical(), #>   .coordinates_country_inconsistent = col_logical(), #>   .unLicensed = col_logical(), #>   .invalidName = col_logical(), #>   .sequential = col_logical(), #>   idContinuity = col_logical(), #>   .uncertaintyThreshold = col_logical(), #>   .GBIFflags = col_logical(), #>   finalLatitude = col_double(), #>   finalLongitude = col_double(), #>   Source = col_character(), #>   newCharacterColumn = col_character(), #>   newNumericColumn = col_integer(), #>   newLogicalColumn = col_logical() #> )  # Try reading in one of the test datasets as an example: beesFlagged %>% dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) #> # A tibble: 100 × 124 #>    database_id scientificName family subfamily genus subgenus subspecies species #>    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #>  1 Dorey_data… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #>  2 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #>  3 Dorey_data… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #>  4 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #>  5 Dorey_data… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #>  6 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #>  7 Dorey_data… Megachile api… Megac… Megachil… Mega… NA       NA         Megach… #>  8 Dorey_data… Trigona dalla… Apidae Apinae    Trig… NA       NA         Trigon… #>  9 Dorey_data… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… #> 10 Dorey_data… Lasioglossum … Halic… Halictin… Lasi… NA       NA         Lasiog… #> # ℹ 90 more rows #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …   # OR beesRaw %>% dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) #> # A tibble: 100 × 90 #>    database_id scientificName family subfamily genus subgenus subspecies species #>    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #>  1 Dorey_data… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #>  2 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #>  3 Dorey_data… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #>  4 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #>  5 Dorey_data… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #>  6 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #>  7 Dorey_data… Megachile api… Megac… Megachil… Mega… NA       NA         Megach… #>  8 Dorey_data… Trigona dalla… Apidae Apinae    Trig… NA       NA         Trigon… #>  9 Dorey_data… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… #> 10 Dorey_data… Lasioglossum … Halic… Halictin… Lasi… NA       NA         Lasiog… #> # ℹ 90 more rows #> # ℹ 82 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags records with GBIF issues — GBIFissues","title":"Flags records with GBIF issues — GBIFissues","text":"function flag records subject user-specified vector GBIF issues.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags records with GBIF issues — GBIFissues","text":"","code":"GBIFissues(data = NULL, issueColumn = \"issue\", GBIFflags = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags records with GBIF issues — GBIFissues","text":"data data frame tibble. Occurrence records input. issueColumn Character. column look GBIF issues. Default = \"issue\". GBIFflags Character vector. GBIF issues flag. Users may choose vector issues flag use pre-set vector vectors, including c(\"allDates\", \"allMetadata\", \"allObservations\", \"allSpatial\", \"allTaxo\", \"\"). Default = c(\"COORDINATE_INVALID\", \"PRESUMED_NEGATED_LONGITUDE\", \"PRESUMED_NEGATED_LATITUDE\", \"COUNTRY_COORDINATE_MISMATCH\", \"ZERO_COORDINATE\")","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags records with GBIF issues — GBIFissues","text":"Returns data new column, \".GBIFflags\", FALSE = records provided GBIFflags.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags records with GBIF issues — GBIFissues","text":"","code":"# Import the example data data(beesRaw) # Run the function beesRaw_Out <- GBIFissues(data = beesRaw,     issueColumn = \"issue\",     GBIFflags = c(\"COORDINATE_INVALID\", \"ZERO_COORDINATE\"))  #>  - jbd_GBIFissues: #> Flagged 0  #>   The .GBIFflags column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":null,"dir":"Reference","previous_headings":"","what":"Harmonise taxonomy of bee occurrence data — harmoniseR","title":"Harmonise taxonomy of bee occurrence data — harmoniseR","text":"Uses Discover Life taxonomy harmonise bee occurrences flag match checklist. function hijacked service taxa user matched format beesTaxonomy file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harmonise taxonomy of bee occurrence data — harmoniseR","text":"","code":"harmoniseR(   data = NULL,   path = NULL,   taxonomy = BeeBDC::beesTaxonomy,   speciesColumn = \"scientificName\",   rm_names_clean = TRUE,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harmonise taxonomy of bee occurrence data — harmoniseR","text":"data data frame tibble. Occurrence records input. path directory character. path folder output can saved. taxonomy data frame tibble. bee taxonomy use. Default = BeeBDC::beesTaxonomy. speciesColumn Character. name column containing species names. Default = \"scientificName\". rm_names_clean Logical. TRUE names_clean column removed end function help reduce confusion column later. Default = TRUE stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harmonise taxonomy of bee occurrence data — harmoniseR","text":"occurrences returned update taxonomy columns, including: scientificName, species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, scientificNameAuthorship. new column, .invalidName, also added FALSE occurrence's name match supplied taxonomy.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harmonise taxonomy of bee occurrence data — harmoniseR","text":"","code":"beesRaw_out <- harmoniseR(   #The path to a folder that the output can be saved path = tempdir(), # The formatted taxonomy file taxonomy = BeeBDC::beesTaxonomy,  data = BeeBDC::beesFlagged, speciesColumn = \"scientificName\") #>  - Formatting taxonomy for matching... #>  #>  - Harmonise the occurrence data with unambiguous names... #>  #>  - Attempting to harmonise the occurrence data with ambiguous names... #>  - Formatting merged datasets... #> Removing the names_clean column... #>  - We matched valid names to 96 of 100 occurrence records. This leaves a total of 4 unmatched occurrence records. #>  #> harmoniseR: #> 4 #> records were flagged. #> The column, '.invalidName' was added to the database. #>  #>  - We updated the following columns: scientificName, species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, and scientificNameAuthorship. The previous scientificName column was converted to verbatimScientificName #>  - Completed in 0.03 secs table(beesRaw_out$.invalidName, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>     4    96     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"Replaces publicly available data data manually cleaned error-corrected use paper Chesshire, P. R., Fischer, E. E., Dowdy, N. J., Griswold, T., Hughes, . C., Orr, M. J., . . . McCabe, L. M. (Press). Completeness analysis 3000 United States bee species identifies persistent data gaps. Ecography.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"","code":"PaigeIntegrater(db_standardized = NULL, PaigeNAm = NULL, columnStrings = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"db_standardized data frame tibble. Occurrence records input. PaigeNAm data frame tibble. Paige Chesshire dataset. columnStrings list character vectors. vector set columns used iteratively match public dataset Paige dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"Returns db_standardized (input occurrence records) Paige Chesshire data integrated.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"","code":"if (FALSE) { # Integrate Paige Chesshire's cleaned dataset. PaigeNAm <- readr::read_csv(paste(DataPath, \"Paige_data\", \"NorAmer_highQual_only_ALLfamilies.csv\",                                  sep = \"/\"), col_types = ColTypeR()) %>%  # Change the column name from Source to dataSource to match the rest of the data.  dplyr::rename(dataSource = Source) %>%  # add a NEW database_id column  dplyr::mutate(    database_id = paste0(\"Paige_data_\", 1:nrow(.)),    .before = scientificName)   # Set up the list of character vectors to iteratively check for matches with public data. columnList <- list(  c(\"decimalLatitude\", \"decimalLongitude\",     \"recordNumber\", \"recordedBy\", \"individualCount\", \"samplingProtocol\",    \"associatedTaxa\", \"sex\", \"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",    \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 1  c(\"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",    \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 2  c(\"decimalLatitude\", \"decimalLongitude\",     \"recordedBy\", \"genus\", \"specificEpithet\"), # Iteration 3  c(\"id\", \"decimalLatitude\", \"decimalLongitude\"), # Iteration 4  c(\"recordedBy\", \"genus\", \"specificEpithet\", \"locality\"), # Iteration 5  c(\"recordedBy\", \"institutionCode\", \"genus\",     \"specificEpithet\",\"locality\"),# Iteration 6  c(\"occurrenceID\",\"decimalLatitude\", \"decimalLongitude\"), # Iteration 7  c(\"catalogNumber\",\"decimalLatitude\", \"decimalLongitude\"), # Iteration 8  c(\"catalogNumber\", \"locality\") # Iteration 9 )   # Merge Paige's data with downloaded data db_standardized <- BeeBDC::PaigeIntegrater(  db_standardized = db_standardized,  PaigeNAm = PaigeNAm,  columnStrings = columnList) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Find, import, and format USGS data to Darwin Core — USGS_formatter","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"function finds, imports, formats, creates metadata USGS dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"","code":"USGS_formatter(path, pubDate)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"path character path directory contains USGS data, found using fileFinder(). function look \"USGS_DRO_flat\". pubDate Character. publication date dataset update metadata citation.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"Returns list occurrence data, \"USGS_data\", EML data, \"EML_attributes\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"","code":"if (FALSE) { USGS_data <- USGS_formatter(path = DataPath, pubDate = \"19-11-2022\") }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"Downloads ALA data creates new file path put data. function can also request downloads atlases (see: http://galah.ala.org.au/articles/choosing_an_atlas.html). However, send download email must rest point.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"","code":"atlasDownloader(   path,   userEmail = NULL,   ALA_taxon,   DL_reason = 4,   atlas = \"ALA\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"path character directory. path folder download stored. userEmail character string. email used associated user’s ALA account; user must make ALA account download data. ALA_taxon character string. taxon download ALA. Uses galah::galah_identify() DL_reason Numeric. reason data download according galah::galah_config() atlas Character. atlas download occurrence data - see https://galah.ala.org.au/R/articles/choosing_an_atlas.html details. Note: default \"ALA\" probably atlas work seamlessly rest workflow. However, different atlases can still downloaded doi sent email.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"Completes ALA data download saves data path provided.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"","code":"if (FALSE) { remotes::install_github(\"AtlasOfLivingAustralia/galah\") atlasDownloader(path = DataPath,                userEmail = \"InsertYourEmail\",                ALA_taxon = \"Apiformes\",                DL_reason = 4)                }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":null,"dir":"Reference","previous_headings":"","what":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"test dataset includes 105 random occurrence records three bee species. included species : \"Agapostemon tyleri Cockerell, 1917\", \"Centris rhodopus Cockerell, 1897\", \"Perdita octomaculata (Say, 1824)\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"","code":"data(beesFlagged)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full scientific name subspecies name — ALA column specificEpithet species name (specific epithet) infraspecificEpithet subspecies name (intraspecific epithet) acceptedNameUsage full scientific name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName column. scientificNameAuthorship authorship information scientificName column formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts identification. higherClassification list (concatenated separated) taxon names terminating rank immediately superior taxon referenced taxon record.) identificationReferences list (concatenated separated) references (e.g. publications, global unique identifier, URI, etc.) used identification occurrence. typeStatus list (concatenated separated) nomenclatural types (e.g. type status, typified scientific name, publication) applied occurrence. previousIdentifications list (concatenated separated) previous assignments names occurrence. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date occurrence identified belonging taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center location. Positive values north Equator, negative values south , valid values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center location. Positive values east Greenwich Meridian, negative values west . Valid values lie -180 180, inclusive. stateProvince name next smaller administrative region country (e.g. state, province, canton, department, region, etc.) location occurrence found. continent name continent location occurrence found. locality specific description place occurrence found. island name island near location occurrence found, applicable. county full, unabbreviated name next smaller administrative region stateProvince (e.g. county, shire, department, etc.) location occurrence found. municipality full, unabbreviated name next smaller administrative region county (e.g. city, municipality, etc.) location occurrence found. use term nearby named place contain actual location occurrence. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate time interval Event occurred. occurrences, time interval event recorded. eventTime time interval Event occurred. day integer day month Event occurred. occurrences, day event recorded. month integer month Event occurred. occurrences, month event recorded. year four-digit year Event occurred, according Common Era Calendar. occurrences, year event recorded. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit location occurrence found. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) % biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatimScientificName Scientific name recorded specimen label, necessarily valid. verbatimEventDate verbatim original representation date time information event. occurrences, date-time event recorded noted collector. associatedTaxa list (concatenated separated) identifiers names taxa associations occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations occurrence . fieldNotes One ) indicator existence , b) reference (publication, URI), c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf code another occerrence specimen. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers occurrence records associations occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name .scientificName_empty Flag produced bdc::bdc_scientificName_empty() FALSE == scientific name provided TRUE means text column. .coordinates_empty Flag produced bdc::bdc_coordinates_empty() FALSE == coordinates provided. .coordinates_outOfRange Flag column produced bdc::bdc_coordinates_outOfRange() FALSE == coordinates represent point Earth. say, function identifies records --range coordinates (-90 90 latitude; -180 180 longitude). .basisOfRecords_notStandard Flag produced bdc::bdc_basisOfRecords_notStandard() FALSE == occurrence basisOfRecord defined acceptable user. country_suggested country name suggested bdc::bdc_country_standardized() function. countryCode country code suggested bdc::bdc_country_standardized() function. coordinates_transposed column indicating coordinates identified transposed function BeeBDC::jbd_Ctrans_chunker() FALSE == transposed. .coordinates_country_inconsistent flag generated jbd_coordCountryInconsistent() FALSE == occurrence country name coordinates match. .occurrenceAbsent flag generated flagAbsent() FALSE == occurrences marked \"ABSENT\" \"occurrenceStatus\" column .unLicensed flag generated flagLicense() FALSE == occurrences protected restrictive license. .GBIFflags flag generated GBIFissues() FALSE == occurrence user-specified GBIF issues flag. .uncer_terms flag generated bdc::bdc_clean_names() FALSE == presence taxonomic uncertainty terms. names_clean column made bdc::bdc_clean_names() indicating cleaned scientificName .invalidName flag generated harmoniseR() FALSE == occurrences whose scientificName match Discover Life taxonomy. .rou flag generated CoordinateCleaner::clean_coordinates() FALSE == rounded (probably imprecise) coordinates. .val flag generated CoordinateCleaner::clean_coordinates() FALSE == invalid coordinates. .equ flag generated CoordinateCleaner::clean_coordinates() FALSE == equal coordinates (e.g., 0.1, 0.1). .zer flag generated CoordinateCleaner::clean_coordinates() FALSE == zeros coordinates .cap flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country capital centroid. .cen flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country province centroids. .gbf flag generated CoordinateCleaner::clean_coordinates() FALSE == records around GBIF headquarters. .inst flag generated CoordinateCleaner::clean_coordinates() FALSE == records around biodiversity institutions. .sequential flag generated diagonAlley() FALSE == records possibly result fill-errors sequence. .lonFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding longitude column within dataset. .latFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding latitude column within dataset. .gridSummary flag generated CoordinateCleaner::cd_round() FALSE == potential gridding either longitude latitude columns within dataset. .uncertaintyThreshold flag generated coordUncerFlagR() FALSE == occurrences pass user-specified threshold \"coordinateUncertaintyInMeters\" column. countryMatch column made countryOutlieRs(). Summarises occurrence-level result: species known occur country (noMatch), known bordering country (neighbour), known occur country (exact). .countryOutlier flag generated countryOutlieRs() FALSE == occurrences occur country concurs Discover Life country checklist adjacent country. .sea flag generated countryOutlieRs() FALSE == occurrences ocean. .summary flag generated summaryFun() FALSE == occurrences flagged FALSE .flag columns. example excludes flags \".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\" columns. .eventDate_empty flag generated bdc::bdc_eventDate_empty() FALSE == occurrences eventDate provided. .year_outOfRange flag column generated bdc::bdc_year_outOfRange() FALSE == occurrences older threshold date. case bee dataset used package, lower threshold 1950 .duplicates flag generated dupeSummary() FALSE == occurrences identified duplicates. associated kept duplicate (.duplictes == TRUE) duplicate clusters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"small bee occurrence dataset flags generated BeeBDC can used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"data set created generating random subset 105 rows full BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"","code":"data(bees3sp) head(bees3sp) #> # A tibble: 6 × 124 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <lgl>    <lgl>      <chr>   #> 1 Dorey_data_… Agapostemon t… Halic… Halictin… Agap… NA       NA         Agapos… #> 2 Dorey_data_… Agapostemon t… Halic… Halictin… Agap… NA       NA         Agapos… #> 3 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 4 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 5 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 6 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <lgl>, #> #   acceptedNameUsage <chr>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <lgl>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":null,"dir":"Reference","previous_headings":"","what":"A country-level checklist of bees from Discover Life — beesChecklist","title":"A country-level checklist of bees from Discover Life — beesChecklist","text":"table contains taxonomic country information bees world based data collated Discover Life. See beesTaxonomy() context.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A country-level checklist of bees from Discover Life — beesChecklist","text":"","code":"data(beesChecklist)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A country-level checklist of bees from Discover Life — beesChecklist","text":"object class \"tibble\" validName valid scientificName occur scientificName column. DiscoverLife_name full country name occurs Discover Life. rNaturalEarth_name Country name rnaturalearth's name_long. shortName short version country name. DiscoverLife_ISO ISO country name occurs Discover Life. Alpha-2 Alpha-2 rnaturalearth. Alpha-3 Alpha-3 rnaturalearth. official Official country name = \"yes\" Discover Life name = \"\". Source text strign denoting source author name-country pair. matchCertainty Quality name's match Discover Life checklist. canonical valid species name without scientificNameAuthority. canonical_withFlags validName without scientificNameAuthority Discover Life flags. family Bee family. subfamily Bee subfamily. genus Bee genus. subgenus Bee subgenus. infraspecies Bee infraSpecificEpithet. infraspecificEpithet Bee infraspecificEpithet. species Bee specificEpithet. scientificNameAuthorship Bee scientificNameAuthorship. taxon_rank Rank taxon name. Notes Discover Life country name notes.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A country-level checklist of bees from Discover Life — beesChecklist","text":"dataset created using Discover Life checklist taxonomy. information download date file name. Dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data. checklist data mostly compiled Discover Life data, www.discoverlife.org: ASCHER, J. S. & PICKERING, J. 2020. Discover Life bee species guide world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A country-level checklist of bees from Discover Life — beesChecklist","text":"","code":"## Not run: data(beesChecklist) head(beesChecklist) #> # A tibble: 6 × 23 #>   validName      DiscoverLife_name rNaturalEarth_name shortName DiscoverLife_ISO #>   <chr>          <chr>             <chr>              <chr>     <chr>            #> 1 Halictus lute… Colombia          Colombia           Colombia  CO               #> 2 Megachile umb… Kiribati          Kiribati           Kiribati  KR               #> 3 Megachile umb… Nauru             Nauru              Nauru     NR               #> 4 Andrena afgha… Afghanistan       Afghanistan        Afghanis… AF               #> 5 Andrena afzel… Afghanistan       Afghanistan        Afghanis… AF               #> 6 Andrena albop… Afghanistan       Afghanistan        Afghanis… AF               #> # ℹ 18 more variables: `Alpha-2` <chr>, `Alpha-3` <chr>, official <chr>, #> #   Source <chr>, matchCertainty <chr>, canonical <chr>, #> #   canonical_withFlags <chr>, family <chr>, subfamily <chr>, genus <chr>, #> #   subgenus <lgl>, specificEpithet <chr>, species <chr>, infraspecies <chr>, #> #   scientificNameAuthorship <chr>, taxon_rank <chr>, #> #   infraspecificEpithet <chr>, Notes <chr> ## End(Not run)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":null,"dir":"Reference","previous_headings":"","what":"A flagged dataset of 100 random bee occurrence records — beesFlagged","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"","code":"data(beesFlagged)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full name subspecies name — ALA column specificEpithet species name infraspecificEpithet subspecies name acceptedNameUsage full name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName. scientificNameAuthorship authorship information scientificName formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts Identification. higherClassification list (concatenated separated) taxa names terminating rank immediately superior taxon referenced taxon record.) identificationReferences list (concatenated separated) references (publication, global unique identifier, URI) used Identification. typeStatus list (concatenated separated) nomenclatural types (type status, typified scientific name, publication) applied subject. previousIdentifications list (concatenated separated) previous assignments names Organism. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date subject determined representing Taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values north Equator, negative values south . Legal values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values east Greenwich Meridian, negative values west . Legal values lie -180 180, inclusive. stateProvince name next smaller administrative region country (state, province, canton, department, region, etc.) Location occurs. continent name continent Location occurs. locality specific description place. island name island near Location occurs. county full, unabbreviated name next smaller administrative region stateProvince (county, shire, department, etc.) Location occurs. municipality full, unabbreviated name next smaller administrative region county (city, municipality, etc.) Location occurs. use term nearby named place contain actual location. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate date-time interval Event occurred. occurrences, date-time event recorded. suitable time geological context. eventTime time interval Event occurred. day integer day month Event occurred. month integer month Event occurred. year four-digit year Event occurred, according Common Era Calendar. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit Location occurs. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) % biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatim_scientificName verbatim (originally-provided) scientific name verbatimEventDate verbatim original representation date time information Event. associatedTaxa list (concatenated separated) identifiers names taxa associations Occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations Organism . fieldNotes One ) indicator existence , b) reference (publication, URI), c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf Additional information exists, shared given record. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers Occurrence records associations Occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name .scientificName_empty Flag produced bdc::bdc_scientificName_empty() FALSE == scientific name provided TRUE means text column. .coordinates_empty Flag produced bdc::bdc_coordinates_empty() FALSE == coordinates provided. .coordinates_outOfRange Flag produced bdc::bdc_coordinates_outOfRange() FALSE == point earth. function identifies records --range coordinates (-90 90 latitude; -180 180 longitude). .basisOfRecords_notStandard Flag produced bdc::bdc_basisOfRecords_notStandard() FALSE == occurrence basisOfRecord defined acceptable user. country_suggested country name suggested bdc::bdc_country_standardized() function. countryCode country code suggested bdc::bdc_country_standardized() function. coordinates_transposed column indicating coordinates tansposed jbd_Ctrans_chunker() FALSE == transposed. .coordinates_country_inconsistent flag generated jbd_coordCountryInconsistent() FALSE == occurrence country name coordinates match. .occurrenceAbsent flag generated flagAbsent() FALSE == occurrences marked \"ABSENT\" \"occurrenceStatus\" column .unLicensed flag generated flagLicense() FALSE == occurrences protected restrictive license. .GBIFflags flag generated GBIFissues() FALSE == occurrence user-specified GBIF issues flag. .uncer_terms flag generated bdc::bdc_clean_names() FALSE == presence taxonomic uncertainty terms. names_clean column made bdc::bdc_clean_names() indicating cleaned scientificName .invalidName flag generated harmoniseR() FALSE == occurrences whose scientificName match Discover Life taxonomy. .rou flag generated CoordinateCleaner::clean_coordinates() FALSE == rounded (probably imprecise) coordinates. .val flag generated CoordinateCleaner::clean_coordinates() FALSE == invalid coordinates. .equ flag generated CoordinateCleaner::clean_coordinates() FALSE == equal coordinates (e.g., 0.1, 0.1). .zer flag generated CoordinateCleaner::clean_coordinates() FALSE == zeros coordinates .cap flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country capital centroid. .cen flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country province centroids. .gbf flag generated CoordinateCleaner::clean_coordinates() FALSE == records around GBIF headquarters. .inst flag generated CoordinateCleaner::clean_coordinates() FALSE == records around biodiversity institutions. .sequential flag generated diagonAlley() FALSE == records possibly result fill-errors sequence. .lonFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding longitude column within dataset. .latFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding latitude column within dataset. .gridSummary flag generated CoordinateCleaner::cd_round() FALSE == potential gridding either longitude latitude columns within dataset. .uncertaintyThreshold flag generated coordUncerFlagR() FALSE == occurrences pass user-specified threshold \"coordinateUncertaintyInMeters\" column. countryMatch column made countryOutlieRs(). Summarises occurrence-level result: species known occur country (noMatch), known bordering country (neighbour), known occur country (exact). .countryOutlier flag generated countryOutlieRs() FALSE == occurrences occur country concurs Discover Life country checklist adjacent country. .sea flag generated countryOutlieRs() FALSE == occurrences ocean. .summary flag generated summaryFun() FALSE == occurrences flagged FALSE .flag columns. example excludes flags \".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\" columns. .eventDate_empty flag generated bdc::bdc_eventDate_empty() FALSE == occurrences eventDate provided. .year_outOfRange flag generated bdc::bdc_year_outOfRange() FALSE == occurrences older threshold date. case 1950. .duplicates flag generated dupeSummary() FALSE == occurrences identified duplicates. associated kept duplicate (.duplictes == TRUE) duplicate clusters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"data set created generating random subset 100 rows full BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"","code":"data(beesFlagged) head(beesFlagged) #> # A tibble: 6 × 124 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #> 1 Dorey_data_… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #> 2 Dorey_data_… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #> 3 Dorey_data_… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #> 4 Dorey_data_… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #> 5 Dorey_data_… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #> 6 Paige_data_… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"","code":"data(beesRaw)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full name subspecies name — ALA column specificEpithet species name infraspecificEpithet subspecies name acceptedNameUsage full name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName. scientificNameAuthorship authorship information scientificName formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts Identification. higherClassification list (concatenated separated) taxa names terminating rank immediately superior taxon referenced taxon record.) identificationReferences list (concatenated separated) references (publication, global unique identifier, URI) used Identification. typeStatus list (concatenated separated) nomenclatural types (type status, typified scientific name, publication) applied subject. previousIdentifications list (concatenated separated) previous assignments names Organism. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date subject determined representing Taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values north Equator, negative values south . Legal values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values east Greenwich Meridian, negative values west . Legal values lie -180 180, inclusive. stateProvince name next smaller administrative region country (state, province, canton, department, region, etc.) Location occurs. continent name continent Location occurs. locality specific description place. island name island near Location occurs. county full, unabbreviated name next smaller administrative region stateProvince (county, shire, department, etc.) Location occurs. municipality full, unabbreviated name next smaller administrative region county (city, municipality, etc.) Location occurs. use term nearby named place contain actual location. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate date-time interval Event occurred. occurrences, date-time event recorded. suitable time geological context. eventTime time interval Event occurred. day integer day month Event occurred. month integer month Event occurred. year four-digit year Event occurred, according Common Era Calendar. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit Location occurs. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) % biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatim_scientificName verbatim (originally-provided) scientific name verbatimEventDate verbatim original representation date time information Event. associatedTaxa list (concatenated separated) identifiers names taxa associations Occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations Organism . fieldNotes One ) indicator existence , b) reference (publication, URI), c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf Additional information exists, shared given record. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers Occurrence records associations Occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"data set created generating random subset 100 rows full, unfiltered unflagged, BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"","code":"data(beesRaw) head(beesRaw) #> # A tibble: 6 × 90 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #> 1 Dorey_data_… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #> 2 Dorey_data_… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #> 3 Dorey_data_… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #> 4 Dorey_data_… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #> 5 Dorey_data_… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #> 6 Paige_data_… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #> # ℹ 82 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":null,"dir":"Reference","previous_headings":"","what":"A nearly complete taxonomy of bees globally — beesTaxonomy","title":"A nearly complete taxonomy of bees globally — beesTaxonomy","text":"Contains taxonomic information bees world. Source taxonomy listed \"source\" mostly derived Discover Life website.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A nearly complete taxonomy of bees globally — beesTaxonomy","text":"","code":"data(beesTaxonomy)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A nearly complete taxonomy of bees globally — beesTaxonomy","text":"object class \"tibble\" ## beesTaxonomy flags Flags comments taxon name. taxonomic_status Taxonomic status. Values \"accepted\" \"synonym\" source Source name. accid id accepted taxon name \"0\" taxonomic_status == accepted. id id number taxon name. kingdom biological kingdom taxon belongs . bees, kingdom == Animalia. phylum biological phylum taxon belongs . bees, phylum == Arthropoda. class biological class taxon belongs . bees, class == Insecta. order biological order taxon belongs . bees, order == Hymenoptera. family family bee species belongs . subfamily subfamily bee species belongs . tribe tribe bee species belongs . subtribe subtribe bee species belongs . validName valid scientific name occur “scientificName” column Darwin Core file. canonical scientificName without scientificNameAuthority. canonical_withFlags scientificName without scientificNameAuthority Discover Life taxonomy flags. genus genus bee species belongs . subgenus subgenus bee species belongs . species specific epithet bee species. infraspecies infraspecific epithet bee addressed. authorship author described bee species. taxon_rank Rank bee taxon addressed entry. valid Logical name valid. TRUE == valid name, FALSE == invalid scientific name. notes Additional notes name/taxon.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A nearly complete taxonomy of bees globally — beesTaxonomy","text":"dataset created using Discover Life taxonomy. See rawDataWrite.R information download date file name. Dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data. taxonomy data mostly compiled Discover Life data, www.discoverlife.org: ASCHER, J. S. & PICKERING, J. 2020. Discover Life bee species guide world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A nearly complete taxonomy of bees globally — beesTaxonomy","text":"","code":"data(beesTaxonomy) head(beesTaxonomy) #> # A tibble: 6 × 24 #>   flags taxonomic_status source    accid    id kingdom phylum class order family #>   <chr> <chr>            <chr>     <dbl> <dbl> <chr>   <chr>  <chr> <chr> <chr>  #> 1 NA    accepted         Discover…     0     4 Animal… Arthr… Inse… Hyme… Andre… #> 2 NA    synonym          Discover…     4     5 Animal… Arthr… Inse… Hyme… Andre… #> 3 NA    accepted         Discover…     0     6 Animal… Arthr… Inse… Hyme… Andre… #> 4 NA    accepted         Discover…     0     7 Animal… Arthr… Inse… Hyme… Andre… #> 5 NA    synonym          Discover…     7     8 Animal… Arthr… Inse… Hyme… Andre… #> 6 NA    accepted         Discover…     0     9 Animal… Arthr… Inse… Hyme… Andre… #> # ℹ 14 more variables: subfamily <chr>, tribe <chr>, subtribe <chr>, #> #   validName <chr>, canonical <chr>, canonical_withFlags <chr>, genus <chr>, #> #   subgenus <chr>, species <chr>, infraspecies <chr>, authorship <chr>, #> #   taxon_rank <chr>, valid <lgl>, notes <chr>"},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a chord diagram of duplicate occurrence links — chordDiagramR","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"function outputs figure shows relative size direction occurrence points duplicated data providers, , SCAN, GBIF, ALA, etc.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"","code":"chordDiagramR(   dupeData = NULL,   outPath = NULL,   fileName = NULL,   width = 7,   height = 6,   bg = \"white\",   smallGrpThreshold = 3,   title = \"Duplicated record sources\",   palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",     \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",     \"cartography::purple.pal\", \"cartography::brown.pal\"),   canvas.ylim = c(-1, 1),   canvas.xlim = c(-0.6, 0.25),   text.col = \"black\",   legendX = grid::unit(6, \"mm\"),   legendY = grid::unit(18, \"mm\"),   legendJustify = c(\"left\", \"bottom\"),   niceFacing = TRUE,   self.link = 2 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"dupeData tibble data frame. duplicate file produced dupeSummary() outPath Character. path directory (folder) output saved. fileName Character. name output file, ending '.pdf'. width Numeric. width figure save (inches). Default = 7. height Numeric. height figure save (inches). Default = 6. bg plot's background colour. Default = \"white\". smallGrpThreshold Numeric. upper threshold sub-dataSources listed \"\". Default = 3. title character string. figure title. Default = \"Duplicated record sources\". palettes vector palettes used. One palette major dataSource \"\" using paletteer package. Default = c(\"cartography::blue.pal\", \"cartography::green.pal\", \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\", \"cartography::purple.pal\", \"cartography::brown.pal\") canvas.ylim Canvas limits circlize::circos.par(). Default = c(-1.0,1.0). canvas.xlim Canvas limits circlize::circos.par(). Default = c(-0.6, 0.25). text.col character string. Text colour legendX x position legends, measured current viewport. Passed ComplexHeatmap::draw(). Default = grid::unit(6, \"mm\"). legendY y position legends, measured current viewport. Passed ComplexHeatmap::draw(). Default = grid::unit(18, \"mm\"). legendJustify character vector declaring justification legends. Passed ComplexHeatmap::draw(). Default = c(\"left\", \"bottom\"). niceFacing TRUE/FALSE. niceFacing option automatically adjusts text facing according positions circle. Passed circlize::highlight.sector(). self.link 1 2 (numeric). Passed circlize::chordDiagram(): self link one sector, 1 means link degenerated 'mountain' width corresponds value connection. 2 means width starting root ending root width corresponds value connection.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"Saves figure provided file path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"","code":"if (FALSE) {  chordDiagramR( dupeData = duplicates, outPath = tempdir(), fileName = \"ChordDiagram.pdf\", # These can be modified to help fit the final pdf that's exported. width = 9, height = 7.5, bg = \"white\", # How few distinct dataSources should a group have to be listed as \"other\" smallGrpThreshold = 3, title = \"Duplicated record sources\", # The default list of colour palettes to choose from using the paleteer package palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",               \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",              \"cartography::purple.pal\", \"cartography::brown.pal\"), canvas.ylim = c(-1.0,1.0),  canvas.xlim = c(-0.6, 0.25), text.col = \"black\", legendX = grid::unit(6, \"mm\"), legendY = grid::unit(18, \"mm\"), legendJustify = c(\"left\", \"bottom\"), niceFacing = TRUE)}"},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"use function, user must choose column, probably \"coordinateUncertaintyInMeters\" threshold occurrences flagged geographic uncertainty.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"","code":"coordUncerFlagR(   data = NULL,   uncerColumn = \"coordinateUncertaintyInMeters\",   threshold = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"data data frame tibble. Occurrence records input. uncerColumn Character. column flag uncertainty . threshold Numeric. uncertainty threshold. Values equal , greater , threshold flagged.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"input data new column, .uncertaintyThreshold.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"","code":"# Run the function beesRaw_out <- coordUncerFlagR(data = beesRaw,                                uncerColumn = \"coordinateUncertaintyInMeters\",                                threshold = 1000) #> \\coordUncerFlagR: #>  Flagged 15 geographically uncertain records: #>  The column '.uncertaintyThreshold' was added to the database. # View the output table(beesRaw_out$.uncertaintyThreshold, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    15    23    62"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix country name issues using a user-input list — countryNameCleanR","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"function basic user manually fix country name inconsistencies.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"","code":"countryNameCleanR(data = NULL, ISO2_table = NULL, commonProblems = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"data data frame tibble. Occurrence records input. ISO2_table data frame tibble columns ISO2 long names country names. Default static version Wikipedia. commonProblems data frame tibble. must two columns: one containing user-identified problem one user-defined fix","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"Returns input data, countries occurring user-supplied problem column (\"commonProblems\") replaced user-supplied fix column","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"","code":"beesFlagged_out <- countryNameCleanR( data = BeeBDC::beesFlagged, commonProblems = dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',                         'United States','U.S.A','MX','CA','Bras.','Braz.',                         'Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                         fix = c('United States of America','United States of America',                                 'United States of America','United States of America',                                 'United States of America','United States of America',                                 'United States of America','Mexico','Canada','Brazil',                                 'Brazil','Brazil','Northern Mariana Islands','PUERTO.RICO'))) #>  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022."},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag country-level outliers with a provided checklist. — countryOutlieRs","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"function flags country-level outliers using checklist provided package. additional context column names, see beesChecklist().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"","code":"countryOutlieRs(   checklist = NULL,   data = NULL,   keepAdjacentCountry = TRUE,   pointBuffer = NULL,   rnearthScale = 50,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"checklist data frame tibble. formatted checklist built based Discover Life website. data data frame tibble. Darwin Core occurrence dataset. keepAdjacentCountry Logical. TRUE, occurrences countries adjacent checklist countries kept. FALSE, flagged. pointBuffer Numeric. buffer around points help align country coastline. provides good way retain points occur right along coast borders maps rnaturalearth rnearthScale Numeric. value fed map scale parameter rnaturalearth::ne_countries()'s scale parameter: Scale map return, one 110, 50, 10 'small', 'medium', 'large', smaller numbers higher resolution. WARNING: function tested 110 50. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"input data new column, .countryOutlier. three possible values new column: TRUE == passed, FALSE == failed, NA == overlap rnaturalearth map.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"","code":"beesRaw_out <- countryOutlieRs(checklist = BeeBDC::beesChecklist,                                data = BeeBDC::beesRaw,                                keepAdjacentCountry = TRUE,                                pointBuffer = 0.05,                                rnearthScale = 50,                                stepSize = 1000000,                                mc.cores = 1) #> Spherical geometry (s2) switched off #>  - Extracting country data from points... #> although coordinates are longitude/latitude, st_intersection assumes that they #> are planar #>  - Buffering failed points by pointBuffer... #> dist is assumed to be in decimal degrees (arc_degrees). #> although coordinates are longitude/latitude, st_intersection assumes that they #> are planar #>  - Prepare the neighbouring country dataset... #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #>  - Compare points with the checklist... #>  - Combining data... #>  - Sorting and removing potentially duplicated buffered points... #>  - Finished.  #> We have matched 75 records to their exact country and 2 to an adjacent country #> We failed to match 0 occurrences to any 'exact' or 'neighbouring' country. #> There are 0 'NA' occurrences for this column. #>  #> countryOutlieRs: #> Flagged 0  for country outlier and flagged  0  for in the .sea records. #> Three columns were added to the database: #>  1.  The '.countryOutlier' column was added which is a filtering column.  #>  2.  The 'countryMatch' columns indicates exact, neighbour, or noMatch.  #>  3. The '.sea' column was added as a filtering column for points in the ocean.  The '.sea' column includes the user input buffer in its calculation. #>  - Completed in 0.27 secs table(beesRaw_out$.countryOutlier, useNA = \"always\") #>  #> TRUE <NA>  #>   77   23"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a table of data providers for bee occurrence records — dataProvTables","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"function attempt find build table data providers contributed input data, especially using 'institutionCode' column. also look variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"","code":"dataProvTables(   data = NULL,   runBeeDataChecks = FALSE,   outPath = OutPath_Report,   fileName = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"data data frame tibble. Occurrence records input. runBeeDataChecks Logical. TRUE, search columns specific clues determine institution. outPath character path. path directory figure saved. Default = OutPath_Report. fileName Character. name file saved, ending \".csv\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"Returns table data providers, specimen count, species count.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"","code":"data(beesFlagged)  testOut <- dataProvTables( data = beesFlagged, runBeeDataChecks = TRUE, outPath = tempdir(), fileName = \"testFile.csv\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple function to save occurrence AND EML data as a list — dataSaver","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"Used end 1.x example workflow order save occurrence dataset associated eml metadata.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"","code":"dataSaver(   path = NULL,   save_type = NULL,   occurrences = NULL,   eml_files = NULL,   file_prefix = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"path Character. main file path look data . save_type Character. file format save occurrence EML data. Either \"R_file\" \"CSV_file\" occurrences occurrences save data frame tibble. eml_files list EML files. file_prefix Character. prefix resulting output file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"function saves occurrence EML data list save_type = \"R_File\" individual csv files save_type = \"CSV_file\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"","code":"if (FALSE) { dataSaver(path = tempdir(),# The main path to look for data in save_type = \"CSV_file\", # \"R_file\" OR \"CSV_file\" occurrences = Complete_data$Data_WebDL, # The existing datasheet eml_files = Complete_data$eml_files, # The existing EML files file_prefix = \"Fin_\") # The prefix for the file name }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":null,"dir":"Reference","previous_headings":"","what":"Find dates in other columns — dateFindR","title":"Find dates in other columns — dateFindR","text":"function made search columns dates add eventDate column. function searches columns locality, fieldNotes, locationRemarks, verbatimEventDate relevant information.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find dates in other columns — dateFindR","text":"","code":"dateFindR(data = NULL, maxYear = lubridate::year(Sys.Date()), minYear = 1700)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find dates in other columns — dateFindR","text":"data data frame tibble. Occurrence records input. maxYear Numeric. maximum year considered reasonable find. Default = lubridate::year(Sys.Date()). minYear Numeric. minimum year considered reasonable find. Default = 1700.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find dates in other columns — dateFindR","text":"function results input occurrence data updated eventDate, year, month, day columns occurrences data ) missing b) located one searched columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find dates in other columns — dateFindR","text":"","code":"# Using the example dataset, you may not find any missing eventDates are rescued (dependent on  # which version of the example dataset the user inputs. beesRaw_out <- dateFindR(data = beesRaw,                          # Years above this are removed (from the recovered dates only)                          maxYear = lubridate::year(Sys.Date()),                          # Years below this are removed (from the recovered dates only)                          minYear = 1700) #>  - Preparing data... #>  - Extracting dates from year, month, day columns... #>  - Extracting dates from fieldNotes, locationRemarks, and verbatimEventDate columns in unambiguous ymd, dmy, mdy, and my formats... #>  - Extracting year from fieldNotes, locationRemarks, and verbatimEventDate columns in ambiguous formats... #>  - Formating and combining the new data.. #>  - Merging all data, nearly there... #>  - Finished.  #> We rescued:  #> 89 occurrences with missing eventDate. #>  - As it stands, there are 89 complete eventDates and 11 missing dates. #>  - There are also 89 complete year occurrences to filter from. This is up from an initial count of 88 At this rate, you will stand to lose 11 occurrences on the basis of missing year - Operation time: 0.222136497497559 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":null,"dir":"Reference","previous_headings":"","what":"Find fill-down errors — diagonAlley","title":"Find fill-down errors — diagonAlley","text":"simple function looks potential latitude longitude fill-errors identifying consecutive occurrences coordinates regular intervals. accomplished using sliding window length determined minRepeats.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find fill-down errors — diagonAlley","text":"","code":"diagonAlley(   data = NULL,   minRepeats = NULL,   groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),   ndec = 3,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find fill-down errors — diagonAlley","text":"data data frame tibble. Occurrence records input. minRepeats Numeric. minimum number lat lon repeats needed flag record groupingColumns Character. column(s) group analysis search fill-errors within. Default = c(\"eventDate\", \"recordedBy\", \"datasetName\"). ndec Numeric. number decimal places records considered diagonAlley function. fed jbd_coordinates_precision(). Default = 3. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find fill-down errors — diagonAlley","text":"function returns input data new column, .sequential, FALSE = records consecutive latitudes longitudes greater equal user-defined threshold.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find fill-down errors — diagonAlley","text":"sliding window (hence fill-errors) examined within user-defined groupingColumns; columns empty, record excluded.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find fill-down errors — diagonAlley","text":"","code":"# Read in the example data   data(beesRaw)  # Run the function   beesRaw_out <- diagonAlley(     data = beesRaw,     # The minimum number of repeats needed to find a sequence in for flagging     minRepeats = 4,     groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),     ndec = 3,     stepSize = 1000000,     mc.cores = 1) #> Removing rounded coordinates with BeeBDC::jbd_coordinates_precision... #> jbd_coordinates_precision: #> Removed 32 records. #> Warning: object 'runningData_LonGrp' not found #>  #> jbd_diagonAlley: #> Flagged 0 records #> The .sequential column was added to the database. #>  - Completed in 0 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up global directory paths and create folders — dirMaker","title":"Set up global directory paths and create folders — dirMaker","text":"function sets directory saving outputs (.e. data, figures) generated use BeeBDC package, required folders already exist.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up global directory paths and create folders — dirMaker","text":"","code":"dirMaker(   RootPath = RootPath,   ScriptPath = NULL,   DataPath = NULL,   DataSubPath = \"/Data_acquisition_workflow\",   DiscLifePath = NULL,   OutPath = NULL,   OutPathName = \"Output\",   Report = TRUE,   Check = TRUE,   Figures = TRUE,   Intermediate = TRUE,   RDoc = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up global directory paths and create folders — dirMaker","text":"RootPath character String. RootPath base path project, paths ideally located within RootPath. However, users may specify paths contained RootPath ScriptPath character String. ScriptPath path additional functions like read use BeeBDC. DataPath character string. path folder containing bee occurrence data flagged /cleaned DataSubPath character String. DataPath provided, used DataPath folder name within RootPath. Default \"/Data_acquisition_workflow\" DiscLifePath character String. path folder contains data Ascher Pcikering's Discover Life website. OutPath character String. path folder output data saved. OutPathName character String. name OutPath subfolder located within RootPath. Default \"Output\". Report Logical. TRUE, function creates \"Report\" folder within OutPath-defined folder. Default = TRUE. Check Logical. TRUE, function creates \"Check\" folder within OutPath-defined folder. Default = TRUE. Figures Logical. TRUE, function creates \"Figures\" folder within OutPath-defined folder. Default = TRUE. Intermediate Logical. TRUE, function creates \"Intermediate\" folder within OutPath-defined folder save intermediate datasets. Default = TRUE. RDoc character String. path current script report, relative project root. Passing absolute path raises error. argument used ::i_am() incorrectly setting may result bdc figures saved computer's root directory","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up global directory paths and create folders — dirMaker","text":"Results generation list containing BeeBDC-required directories global environment. function run start session. Additionally, function create BeeBDC-required folders already exist supplied directory","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up global directory paths and create folders — dirMaker","text":"","code":"if (FALSE) { # Standard/basic usage: RootPath <- tempdir() dirMaker( RootPath = RootPath, # Input the location of the workflow script RELATIVE to the RootPath RDoc = \"BDC_repo/BeeCleaning_SciData.R\") %>%   # Add paths created by this function to the .GlobalEnv   list2env(envir = .GlobalEnv)   # Set the working directory setwd(DataPath)  # Custom OutPathName provided   dirMaker(  RootPath = RootPath,  # Set some custom OutPath info  OutPath = NULL,  OutPathName = \"T2T_Output\",  # Input the location of the workflow script RELATIVE to the RootPath  RDoc = \"BDC_repo/BeeCleaning_SciData.R\") %>%    # Add paths created by this function to the .GlobalEnv    list2env(envir = .GlobalEnv)    # Set the working directory  setwd(DataPath)  # Further customisations are also possible dirMaker(   RootPath = RootPath,   ScriptPath = \"...path/Bee_SDM_paper/BDC_repo/BeeBDC/R\",   DiscLifePath = \"...path/BDC_repo/DiscoverLife_Data\",   OutPathName = \"AsianPerspective_Output\",   # Input the location of the workflow script RELATIVE to the RootPath   RDoc = \"AsianPerspecitve_workflow.R\") %>%   # Add paths created by this function to the .GlobalEnv   list2env(envir = .GlobalEnv)   # Set the working directory setwd(DataPath) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a compound bar graph of duplicate data sources — dupePlotR","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"Creates plot two bar graphs. One shows absolute number duplicate records data source shows proportion records duplicated within data source.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"","code":"dupePlotR(   data = NULL,   outPath = NULL,   fileName = NULL,   legend.position = c(0.85, 0.8),   base_height = 7,   base_width = 7,   ...,   dupeColours = c(\"#F2D2A2\", \"#B9D6BC\", \"#349B90\"),   returnPlot = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"data data frame tibble. Occurrence records input. outPath Character. path directory (folder) output saved. fileName Character. name output file, ending '.pdf'. legend.position position legend coordinates. Default = c(0.85, 0.8). base_height Numeric. height plot inches. Default = 7. base_width Numeric. width plot inches. Default = 7. ... arguments used change factor levels data sources. dupeColours vector colours levels duplicate, kept duplicate, unique. Default = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"). returnPlot Logical. TRUE, return plot environment. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"Outputs .pdf figure.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"","code":"# This example will show a warning for the factor levels taht are not present in the specific  # test dataset dupePlotR(   data = beesFlagged,   # The outPath to save the plot as     # Should be something like: #paste0(OutPath_Figures, \"/duplicatePlot_TEST.pdf\"),   outPath = tempdir(),    fileName = \"duplicatePlot_TEST.pdf\",   # Colours in order: duplicate, kept duplicate, unique   dupeColours = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"),   # Plot size and height   base_height = 7, base_width = 7,   legend.position = c(0.85, 0.8),   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'B. Mont.' = \"BMont\", 'B. Minckley' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\", Lic = \"Lic\", Bal = \"Bal\", Arm = \"Arm\"   ) #> Loading required namespace: forcats #> Loading required namespace: cowplot #> Warning: Unknown levels in `f`: CAES, BMont, BMin, Ecd, Gai, EPEL, Lic, Bal, Arm"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifies duplicate occurrence records — dupeSummary","title":"Identifies duplicate occurrence records — dupeSummary","text":"function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifies duplicate occurrence records — dupeSummary","text":"","code":"dupeSummary(   data = NULL,   path = NULL,   duplicatedBy = NULL,   completeness_cols = NULL,   idColumns = NULL,   collectionCols = NULL,   collectInfoColumns = NULL,   CustomComparisonsRAW = NULL,   CustomComparisons = NULL,   sourceOrder = NULL,   prefixOrder = NULL,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",     \".uncertaintyThreshold\", \".unLicensed\"),   characterThreshold = 2,   numberThreshold = 3,   numberOnlyThreshold = 5,   catalogSwitch = TRUE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifies duplicate occurrence records — dupeSummary","text":"data data frame tibble. Occurrence records input. path character path location duplicateRun_ file saved. duplicatedBy character vector. Options c(\"ID\", \"collectionInfo\", \"\"). \"ID\" columns runs series ID-columns defined idColumns. \"collectionInfo\" runs series columns defined collectInfoColumns, checked combination collectionCols. \"\" runs . completeness_cols character vector. set columns used order select duplicates . occurrence, function calculate sum complete.cases(). Within duplicate clusters occurrences greater number completeness_cols filled kept fewer. idColumns character vector. columns checked individually internal duplicates. Intended use ID columns . collectionCols character vector. columns checked combination completeness_cols. collectInfoColumns character vector. columns checked combinatino collectionCols columns. CustomComparisonsRAW list character vectors. Custom comparisons - list columns iteratively compare duplicates. differ CustomComparisons ignore minimum number character thresholds IDs. CustomComparisons list character vectors. Custom comparisons - list columns iteratively compare duplicates. comparisons made character number thresholds accounted ID columns. sourceOrder character vector. order want KEEP duplicated based dataSource column (.e. order prioritize data sources). NOTE: dataSources simplified string prior first \"_\". Hence, \"GBIF_Anthophyla\" becomes \"GBIF.\" prefixOrder character vector. Like sourceOrder, except based database_id prefix, rather dataSource. Additionally, examined prefixOrder != NULL. Default = NULL. dontFilterThese character vector. contain flag columns ignored creation updating .summary column. Passed  summaryFun(). characterThreshold Numeric. complexity threshold ID letter length. minimum number characters need present ADDITION numberThreshold ID number tested duplicates. Ignored CustomComparisonsRAW. columns checked occurrenceID, recordId, id, catalogNumber, otherCatalogNumbers. Default = 2. numberThreshold Numeric. complexity threshold ID number length. minimum number numeric characters need present ADDITION characterThreshold ID number tested duplicates. Ignored CustomComparisonsRAW. columns checked occurrenceID, recordId, id, catalogNumber, otherCatalogNumbers. Default = 3. numberOnlyThreshold Numeric. numberThreshold except characterThreshold ignored. Default = 5. catalogSwitch Logical. TRUE, catalogNumber empty function copy otherCatalogNumbers catalogNumber visa versa. Hence, function attempt matchmore catalog numbers functions can problematic. Default = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifies duplicate occurrence records — dupeSummary","text":"Returns data additional column called .duplicates FALSE occurrences duplicates TRUE occurrences either kept duplicates unique. Also exports .csv user-specified location information duplicate matching. file used functions including manualOutlierFindeR() chordDiagramR()","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifies duplicate occurrence records — dupeSummary","text":"","code":"beesFlagged_out <- dupeSummary( data = BeeBDC::beesFlagged,   # Should start with paste0(DataPath, \"/Output/Report/\"), instead of tempdir(): path = paste0(tempdir(), \"/\"), # options are \"ID\",\"collectionInfo\", or \"both\" duplicatedBy = \"collectionInfo\", # I'm only running ID for the first lot because we might  # recover other info later # The columns to generate completeness info from completeness_cols = c(\"decimalLatitude\",  \"decimalLongitude\",                       \"scientificName\", \"eventDate\"), # idColumns = c(\"gbifID\", \"occurrenceID\", \"recordId\",\"id\"), # The columns to ADDITIONALLY consider when finding duplicates in collectionInfo collectionCols = c(\"decimalLatitude\", \"decimalLongitude\", \"scientificName\", \"eventDate\",                     \"recordedBy\"), # The columns to combine, one-by-one with the collectionCols collectInfoColumns = c(\"catalogNumber\", \"otherCatalogNumbers\"), # Custom comparisons - as a list of columns to compare # RAW custom comparisons do not use the character and number thresholds CustomComparisonsRAW = dplyr::lst(c(\"catalogNumber\", \"institutionCode\", \"scientificName\")), # Other custom comparisons use the character and number thresholds CustomComparisons = dplyr::lst(c(\"gbifID\", \"scientificName\"),                                 c(\"occurrenceID\", \"scientificName\"),                                 c(\"recordId\", \"scientificName\"),                                 c(\"id\", \"scientificName\")), # The order in which you want to KEEP duplicated based on data source # try unique(check_time$dataSource) sourceOrder = c(\"CAES\", \"Gai\", \"Ecd\",\"BMont\", \"BMin\", \"EPEL\", \"ASP\", \"KP\", \"EcoS\", \"EaCO\",                 \"FSCA\", \"Bal\", \"SMC\", \"Lic\", \"Arm\",                 \"USGS\", \"ALA\", \"GBIF\",\"SCAN\",\"iDigBio\"), # !!!!!! BELS > GeoLocate # Set the complexity threshold for id letter and number length # minimum number of characters when WITH the numberThreshold characterThreshold = 2, # minimum number of numbers when WITH the characterThreshold numberThreshold = 3, # Minimum number of numbers WITHOUT any characters numberOnlyThreshold = 5) #> Loading required namespace: igraph #>  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. #> This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. #>  - Updating the .summary column to sort by... #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold, .unLicensed #>  - summaryFun: #> Flagged 74  #>   The .summary column was added to the database. #>  - Working on CustomComparisonsRAW duplicates... #>  #> Completed iteration 1 of 1: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> catalogNumber, institutionCode, scientificName #>  - Working on CustomComparisons duplicates... #>  #> Completed iteration 1 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> gbifID, scientificName #>  #> Completed iteration 2 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> occurrenceID, scientificName #>  #> Completed iteration 3 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> recordId, scientificName #>  #> Completed iteration 4 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> id, scientificName #>  - Working on collectionInfo duplicates... #>  #> Completed iteration 1 of 2: #>  - Identified 0 duplicate records and kept 0 unique records using the columns:  #> decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and catalogNumber #>  #> Completed iteration 2 of 2: #>  - Identified 0 duplicate records and kept 0 unique records using the columns:  #> decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and otherCatalogNumbers #>  - Clustering duplicate pairs... #> Duplicate pairs clustered. There are 0 duplicates across 0 kept duplicates. #>  - Ordering data by 1. dataSource, 2. completeness and 3. .summary column... #>  - Find and FIRST duplicate to keep and assign other associated duplicates to that one (i.e., across multiple tests a 'kept duplicate', could otherwise be removed)... #>  - Duplicates have been saved in the file and location: /tmp/RtmpTlRRs7/duplicateRun_collectionInfo_2023-08-30.csv #>  - Across the entire dataset, there are now 0 duplicates from a total of 100 occurrences. #>  - Completed in 0.01 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds files within a directory — fileFinder","title":"Finds files within a directory — fileFinder","text":"function can used find files within user-defined directory based user-provided character string.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds files within a directory — fileFinder","text":"","code":"fileFinder(path, fileName)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds files within a directory — fileFinder","text":"path directory character. directory recursively search. fileName character/regex string. file name find.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds files within a directory — fileFinder","text":"Returns directory -recent file matches provied file Using regex can greatly improve specificity. Using regex can greatly improve specificity. function also write console file found - worthwhile check correct file avoid complications line","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds files within a directory — fileFinder","text":"","code":"if (FALSE) { fileFinder(path = RootPath, fileName = \"beesRaw\") # more specifically the .csv version fileFinder(path = RootPath, fileName = \"beesRaw.csv\") }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags occurrences that are marked as absent — flagAbsent","title":"Flags occurrences that are marked as absent — flagAbsent","text":"Flags occurrences \"ABSENT\" occurrenceStatus (user-specified) column.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags occurrences that are marked as absent — flagAbsent","text":"","code":"flagAbsent(data = NULL, PresAbs = \"occurrenceStatus\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags occurrences that are marked as absent — flagAbsent","text":"data data frame tibble. Occurrence records input. PresAbs Character. column function find \"ABSENT\" \"PRESENT\" records. Default = \"occurrenceStatus\"","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags occurrences that are marked as absent — flagAbsent","text":"input data new column called \".occurrenceAbsent\" FALSE == \"ABSENT\" records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags occurrences that are marked as absent — flagAbsent","text":"","code":"# Bring in the data data(beesRaw)   # Run the function beesRaw_out <- flagAbsent(data = beesRaw, PresAbs = \"occurrenceStatus\") #> \\.occurrenceAbsent: #>  Flagged 8 absent records: #>  One column was added to the database.   # See the result table(beesRaw_out$.occurrenceAbsent, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>     8    92     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag license protected records — flagLicense","title":"Flag license protected records — flagLicense","text":"function search strings indicate record restricted use flag restricted records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag license protected records — flagLicense","text":"","code":"flagLicense(data = NULL, strings_to_restrict = \"all\", excludeDataSource = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag license protected records — flagLicense","text":"data data frame tibble. Occurrence records input. strings_to_restrict character vector. contain strings used detect protected records. Default =  c(\"Rights Reserved\", \"rights reserved\", \"rights reserved.\", \"ND\", \"public\") excludeDataSource Optional. character vector. vector data sources (dataSource) flagged protected, even . useful private dataset listed  \"rights reserved\" want ignored flag.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag license protected records — flagLicense","text":"Returns data new column, .unLicensed, FALSE = records protected license.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag license protected records — flagLicense","text":"","code":"# Read in the example data data(\"beesRaw\")   # Run the function beesRaw_out <- flagLicense(data = beesRaw,                         strings_to_restrict = \"all\",                         # DON'T flag if in the following data# source(s)                         excludeDataSource = NULL) #> \\.unLicensed: #>  Flagged 0 records that may NOT be used. #>  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads, appends, and saves occurrence flag data — flagRecorder","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"function used save flag data occurrence data run BeeBDC script. read append existing files, asked . flags also saved occurrence file automatically.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"","code":"flagRecorder(   data = NULL,   outPath = NULL,   fileName = NULL,   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = NULL,   printSummary = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"data data frame tibble. Occurrence records input. outPath character path. file saved. fileName Character. name file saved idColumns character vector. names columns kept along flag columns. columns useful identifying unique records flags. Default = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"). append Logical. TRUE, find append existing file generated function. printSummary Logical. TRUE, print summary() filter columns - .e. tidyselect::starts_with(\".\")","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"Saves file id flag columns returns object.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"","code":"# Load the example data data(\"beesFlagged\")    # Run the function   OutPath_Report <- tempdir() flagFile <- flagRecorder(   data = beesFlagged,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"),   # These are the columns that will be kept along with the flags   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   # TRUE if you want to find a file from a previous part of the script to append to   append = FALSE) #>  - .summary column detected. This will be over-written. #>  - Data saved to /tmp/RtmpTlRRs7/flagsRecorded_2023-08-30.csv #>  - Selected 34 columns. These include: #> database_id, id, catalogNumber, occurrenceID, dataSource, .scientificName_empty, .coordinates_empty, .coordinates_outOfRange, .basisOfRecords_notStandard, .coordinates_country_inconsistent, .occurrenceAbsent, .unLicensed, .GBIFflags, .uncer_terms, .invalidName, .rou, .val, .equ, .zer, .cap, .cen, .gbf, .inst, .sequential, .lonFlag, .latFlag, .gridSummary, .uncertaintyThreshold, .countryOutlier, .sea, .summary, .eventDate_empty, .year_outOfRange, and .duplicates"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a per-species summary for each and all flags — flagSummaryTable","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"Takes flagged dataset returns total number fails (FALSE) per flag (columns starting \".\") per species. Users may define column group summary . intended work scientificName column, users may select grouping column (e.g., country).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"","code":"flagSummaryTable(   data = NULL,   column = \"scientificName\",   outPath = OutPath_Report,   fileName = \"flagTable.csv\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"data data frame tibble. flagged dataset. column Character. name column group summarise failed occurrences. Default = \"scientificName\". outPath character path. path directory figure saved. Default = OutPath_Report. fileName Character. name file saved, ending \".csv\". Default = \"flagTable.csv\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"tibble column flag column (starting \".\") showing number failed (FALSE) occurrences per group. Also shows () total number records, (ii) total number failed records, (iii) percentage failed records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"","code":"# Load the toy flagged bee data data(\"beesFlagged\")    # Run the function and build the flag table flagTibble <- flagSummaryTable(data = beesFlagged,                               column = \"scientificName\",                               outPath = paste0(tempdir()),                               fileName = \"flagTable.csv\") #>  - We will flag all columns starting with '.' #>  - summaryFun: #> Flagged 81  #>   The .summary column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine the formatted USGS data with the main dataset — formattedCombiner","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"Merges Darwin Core version USGS dataset created using USGS_formatter() main dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"","code":"formattedCombiner(path, strings, existingOccurrences, existingEMLs)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"path directory character. directory look formatted USGS data. strings regex string. string find -recent formatted USGS dataset. existingOccurrences data frame. existing occurrence dataset. existingEMLs EML file. existing EML data file appended.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"list combined occurrence dataset updated EML file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"","code":"if (FALSE) { strings = c(\"USGS_DRO_flat_27-Apr-2022\")     # Combine the USGS data and the existing big dataset Complete_data <- formattedCombiner(path = DataPath,                                      strings = strings,                                      # This should be the list-format with eml attached                                     existingOccurrences = DataImp$Data_WebDL,                                     existingEMLs = DataImp$eml_files)                                      }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":null,"dir":"Reference","previous_headings":"","what":"Attempt to match database_ids from a prior run — idMatchR","title":"Attempt to match database_ids from a prior run — idMatchR","text":"function attempts match database_ids prior bdc BeeBDC run order keep column somewhat consistent iterations. However, records contain sufficient information work flawlessly.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attempt to match database_ids from a prior run — idMatchR","text":"","code":"idMatchR(   currentData = NULL,   priorData = NULL,   matchBy = NULL,   completeness_cols = NULL,   excludeDataset = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attempt to match database_ids from a prior run — idMatchR","text":"currentData data frame tibble. NEW occurrence records input. priorData data frame tibble. PRIOR occurrence records input. matchBy list character vectors contain columns iteratively compare. completeness_cols character vector. columns check completeness, arrange, assign relevant prior database_id. excludeDataset character vector. dataSources excluded data matching. static dataSources minor providers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attempt to match database_ids from a prior run — idMatchR","text":"input data frame returned updated database_id column shows database_ids priorData matched. Additionally, columnd called idContinuity returned TRUE indicates match prior database_id FALSE indicates new database_id assigned.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Attempt to match database_ids from a prior run — idMatchR","text":"","code":"# Which datasets are static and should be excluded from matching? excludeDataset <- c(\"BMin\", \"BMont\", \"CAES\", \"EaCO\", \"Ecd\", \"EcoS\",                     \"Gai\", \"KP\", \"EPEL\", \"USGS\", \"FSCA\", \"SMC\", \"Bal\", \"Lic\", \"Arm\", \"BBD\",                      \"MEPB\")   # Match the data to itself just as an example of running the code. beesRaw_out <- idMatchR(   currentData = BeeBDC::beesRaw,   priorData = BeeBDC::beesRaw,   # First matches will be given preference over later ones   matchBy = dplyr::lst(c(\"gbifID\"),                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\"),                         c(\"occurrenceID\", \"dataSource\"),                         c(\"recordId\", \"dataSource\"),                         c(\"id\"),                         # Because INHS was entered as it's own dataset but is now included in                            # the GBIF download...                         c(\"catalogNumber\", \"institutionCode\")),   # You can exclude datasets from prior by matching their prefixs - before first underscore:   excludeDataset = excludeDataset) #> Warning message:  #>  - No completeness_cols provided. Using default of: c('decimalLatitude',  'decimalLongitude', 'scientificName', and 'eventDate') #>  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. #> This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. #>  - Starting core loop... #>  - we matched 47 records using gbifID. #> This leaves 51 unmatched data in the priorData file #>  - we matched 45 records using catalogNumber, institutionCode, dataSource. #> This leaves 6 unmatched data in the priorData file #>  - we matched 4 records using occurrenceID, dataSource. #> This leaves 2 unmatched data in the priorData file #>  - we matched 0 records using recordId, dataSource. #> This leaves 2 unmatched data in the priorData file #>  - we matched 1 records using id. #> This leaves 1 unmatched data in the priorData file #>  - we matched 0 records using catalogNumber, institutionCode. #> This leaves 1 unmatched data in the priorData file #>  - Combining ids and assigning new ones where needed... #>  - We matched a total of 97 database_id numbers. We then assigned new database_id numbers to 1 unmatched occurrences."},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":null,"dir":"Reference","previous_headings":"","what":"Imports the most-recent repoMerge data — importOccurrences","title":"Imports the most-recent repoMerge data — importOccurrences","text":"Looks imports -recent version occurrence data created repoMerge() function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imports the most-recent repoMerge data — importOccurrences","text":"","code":"importOccurrences(path = path, fileName = \"^BeeData_\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imports the most-recent repoMerge data — importOccurrences","text":"path directory character. directory recursively look data. fileName Character. String text look -recent dataset. Default = \"^BeeData_\". Find faults modifying fileFinder() logic-checking file found.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Imports the most-recent repoMerge data — importOccurrences","text":"list data frame merged occurrence records, \"Data_WebDL\", list EML files contained \"eml_files\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imports the most-recent repoMerge data — importOccurrences","text":"","code":"if (FALSE) { DataImp <- importOccurrences(path = DataPath) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates interactive html maps for species — interactiveMapR","title":"Creates interactive html maps for species — interactiveMapR","text":"Uses occurrence data (preferably uncleaned) outputs interactive .html maps can opened browser specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can modified first running summaryFun() set columns want highlighted. can also highlight occurrences flagged expert-identified country outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates interactive html maps for species — interactiveMapR","text":"","code":"interactiveMapR(   data = NULL,   outPath = NULL,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   speciesColumn = \"scientificName\",   speciesList = NULL,   countryList = NULL,   jitterValue = NULL,   onlySummary = TRUE,   overWrite = TRUE,   TrueAlwaysTop = FALSE,   excludeApis_mellifera = TRUE,   pointColours = c(\"blue\", \"darkred\", \"#ff7f00\", \"black\") )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates interactive html maps for species — interactiveMapR","text":"data data frame tibble. Occurrence records use input. outPath directory character. Directory save output maps. lon Character. name longitude column. Default = \"decimalLongitude\". lat Character. name latitude column. Default = \"decimalLatitude\". speciesColumn Character. name column containing species names (another factor) build individual maps . Default = \"scientificName\". speciesList character vector. contain species names appear speciesColumn make maps . User can also specify \"\" order make maps species present data. Hence, user may first filter data use \"\". countryList character vector. Country names map, NULL map countries. jitterValue Numeric. amount, decimal degrees, jitter map points - important separating stacked points coordinates. onlySummary Logical. TRUE, function look plot country expert-identified outliers different colours. overWrite Logical. TRUE, function overwrite existing files provided directory name. Default = TRUE. TrueAlwaysTop TRUE, quality (TRUE) points always displayed top points. FALSE, whichever layer turned -recently displayed top. excludeApis_mellifera Logical. TRUE, map records Apis mellifera. Note: cases . mellifera many points, resulting map take long time make difficult open. Default = TRUE. pointColours character vector colours. order provide colour TRUE, FALSE, countryOutlier, customOutlier. Default = c(\"blue\", \"darkred\",\"#ff7f00\", \"black\").","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates interactive html maps for species — interactiveMapR","text":"Exports .html interactive maps bee occurrences specified directory.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates interactive html maps for species — interactiveMapR","text":"","code":"OutPath_Figures <- tempdir()  interactiveMapR( # occurrence data - start with entire dataset, filter down to these species data = BeeBDC::bees3sp, # %>%   # Select only those species in the 100 randomly chosen   # dplyr::filter(scientificName %in% beeData_interactive$scientificName),   # Select only one species to map   # dplyr::filter(scientificName %in% \"Agapostemon sericeus (Forster, 1771)\"), # Directory where to save files outPath = paste0(OutPath_Figures, \"/interactiveMaps_TEST\"), # lat long columns lon = \"decimalLongitude\", lat = \"decimalLatitude\", # Occurrence dataset column with species names speciesColumn = \"scientificName\", # Which species to map - a character vector of names or \"ALL\" # Note: \"ALL\" is defined AFTER filtering for country speciesList = \"ALL\", # studyArea countryList = NULL,  # Point jitter to see stacked points - jitters an amount in decimal degrees jitterValue = 0.01, # If TRUE, it will only map the .summary column. Otherwise, it will map .summary # which will be over-written by countryOutliers and manualOutliers onlySummary = TRUE, excludeApis_mellifera = TRUE, overWrite = TRUE,   # Colours for points which are flagged as TRUE, FALSE, countryOutlier, and customOutlier pointColours = c(\"blue\", \"darkred\",\"#ff7f00\", \"black\") ) #> Loading required namespace: leaflet #> Loading required package: ggplot2 #>  #> Attaching package: ‘plotly’ #> The following object is masked from ‘package:ggplot2’: #>  #>     last_plot #> The following object is masked from ‘package:stats’: #>  #>     filter #> The following object is masked from ‘package:graphics’: #>  #>     layout #> The column .expertOutlier was not found. One will be created with all values = TRUE."},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","title":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","text":"jbd_country_from_coordinates() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_country_from_coordinates().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","text":"","code":"jbd_CfC_chunker(   data = NULL,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   stepSize = 1e+06,   chunkStart = 1,   progressiveSave = TRUE,   append = FALSE,   scale = \"large\",   path = tempdir(),   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","text":"data data frame tibble. Occurrence records use input. lat Character. name column use latitude. Default = \"decimalLatitude\". lon Character. name column use longitude. Default = \"decimalLongitude\". country Character. name column containing country names. Default = \"country. stepSize Numeric. number occurrences process chunk. Default = 1000000. chunkStart Numeric. chunk number start . can > 1 need restart function certain chunk. example, can used R failed unexpectedly. progressiveSave Logical. TRUE country output list saved iteration append can used function stopped part way . function mc.cores > 1. append Logical. TRUE, function look append existing file. function mc.cores > 1. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". path Character. directory path folder save running countrylist csv file. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","text":"data frame containing database_ids country column needs re-merged data input.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper around jbd_country_from_coordinates() to chunk analyses — jbd_CfC_chunker","text":"","code":"# Because this function iteratively adds to a save file in the background, for simplicity's sake # and for the sake of transparency the output needs to be added to the data input # outside of the main function. library(dplyr) data(beesFlagged) HomePath = tempdir() # Tibble of common issues in country names and their replacements commonProblems <- dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES', 'United States','U.S.A','MX','CA','Bras.','Braz.','Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                                  fix = c('United States of America','United States of America',                                  'United States of America','United States of America',                                  'United States of America','United States of America',                                  'United States of America','Mexico','Canada','Brazil','Brazil',                                  'Brazil','Northern Mariana Islands','Puerto Rico'))                                   beesFlagged <- beesFlagged %>%       # Replace a name to test    dplyr::mutate(country = stringr::str_replace_all(country, \"Brazil\", \"Brasil\"))  beesFlagged_out <- countryNameCleanR(   data = beesFlagged,   commonProblems = commonProblems) #>  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022.  suppressWarnings(   countryOutput <- jbd_CfC_chunker(data = beesFlagged_out,                                    lat = \"decimalLatitude\",                                    lon = \"decimalLongitude\",                                    country = \"country\",                                    # How many rows to process at a time                                    stepSize = 1000000,                                    # Start row                                    chunkStart = 1,                                     # Progressively save the country list between each iteration?                                    progressiveSave = FALSE,                                    path = HomePath,                                    scale = \"medium\",                                    append = FALSE),   classes = \"warning\") #>  - Running chunker with: #> stepSize = 1,000,000 #> chunkStart = 1 #> chunkEnd = 1,000,000 #> append = FALSE #>  - Starting chunk 1... #> From 1 to 1,000,000 #> Loading required package: rnaturalearth #> Support for Spatial objects (`sp`) will be deprecated in {rnaturalearth} and will be removed in a future release of the package. Please use `sf` objects with {rnaturalearth}. For example: `ne_download(returnclass = 'sf')` #>  #> bdc_country_from_coordinates: #> Country names were added to 5 records. #>  - Cleaning RAM. #>  - Finished chunk 1 of 1 chunks. Records examined: 1,000,000 #>  - Completed in 1.63 secs   # Left join these datasets beesFlagged_out <- left_join(beesFlagged_out, countryOutput, by = \"database_id\")  %>%    # merge the two country name columns into the \"country\" column   dplyr::mutate(country = dplyr::coalesce(country.x, country.y)) %>%   # remove the now redundant country columns    dplyr::select(!c(country.x, country.y)) %>%   # put the column back    dplyr::relocate(country) %>%    # Remove duplicates if they arose!   dplyr::distinct()  # Remove illegal characters beesFlagged_out$country <- beesFlagged_out$country %>%   stringr::str_replace(., pattern = paste(\"\\\\[\", \"\\\\]\", \"\\\\?\",                                           sep=  \"|\"), replacement = \"\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":null,"dir":"Reference","previous_headings":"","what":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","title":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","text":"jbd_coordinates_transposed() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_coordinates_transposed().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","text":"","code":"jbd_Ctrans_chunker(   data = NULL,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   idcol = \"databse_id\",   country = \"country_suggested\",   countryCode = \"countryCode\",   sci_names = \"scientificName\",   border_buffer = 0.2,   save_outputs = TRUE,   stepSize = 1e+06,   chunkStart = 1,   progressiveSave = TRUE,   path = tempdir(),   append = TRUE,   scale = \"large\",   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","text":"data data frame tibble. Occurrence records input. lat Character. column latitude decimal degrees. Default = \"decimalLatitude\". lon Character. column longitude decimal degrees. Default = \"decimalLongitude\". idcol Character. column name unique record identifier. Default = \"database_id\". country Character. name column containing country names. Default = \"country\". countryCode Character. Identifies column containing ISO-2 country codes Default = \"countryCode\". sci_names Character. column containing scientific names. Default = \"scientificName\". border_buffer Numeric. buffer, decimal degrees, around points help match countries. Default = 0.2 (~22 km equator). save_outputs Logical. TRUE, transposed occurrences saved file. stepSize Numeric. number occurrences process chunk. Default = 1000000. chunkStart Numeric. chunk number start . can > 1 need restart function certain chunk; example R failed unexpectedly. progressiveSave Logical. TRUE country output list saved iteration append can used function stopped part way . path Character. path file save 01_coordinates_transposed_ output. append Logical. TRUE, function look append existing file. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". mc.cores Numeric. > 1, jbd_correct_coordinates function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.#'","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","text":"Returns input data frame new column, coordinates_transposed, FALSE = columns coordinates transposed.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences — jbd_Ctrans_chunker","text":"","code":"library(dplyr)   # Import and prepare the data data(beesFlagged) beesFlagged <- beesFlagged %>% dplyr::select(!c(.val, .sea))   # Run the function beesFlagged_out <- jbd_Ctrans_chunker( # bdc_coordinates_transposed inputs data = beesFlagged, idcol = \"database_id\", lat = \"decimalLatitude\", lon = \"decimalLongitude\", country = \"country_suggested\", countryCode = \"countryCode\", # in decimal degrees (~22 km at the equator) border_buffer = 0.2,  save_outputs = TRUE, sci_names = \"scientificName\", # chunker inputs # How many rows to process at a time stepSize = 1000000,   # Start row chunkStart = 1,   # Progressively save the output between each iteration? progressiveSave = FALSE, path = tempdir(), # If FALSE it may overwrite existing dataset append = FALSE,   # Users should select scale = \"large\" as it is more thoroughly tested scale = \"medium\", mc.cores = 1 )  #>  - Running chunker with: #> stepSize = 1,000,000 #> chunkStart = 1 #> chunkEnd = 1,000,000 #> append = FALSE #>  - Starting chunk 1... #> From 1 to 1,000,000 #> Loading required package: readr #> Spherical geometry (s2) switched on #> Correcting latitude and longitude transposed #> 3 occurrences will be tested #> No latitude and longitude were transposed #>  - Cleaning RAM. #>  - Finished chunk 1 with 1 remaining. Records examined: 100 #>  - Completed in 0.12 secs table(beesFlagged_out$coordinates_transposed, useNA = \"always\") #>  #> TRUE <NA>  #>  100    0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"Compares stated country name occurrence record record’s coordinates using rnaturalearth data. prefix, jbd_ meant distinguish function original bdc::bdc_coordinates_country_inconsistent().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"","code":"jbd_coordCountryInconsistent(   data = NULL,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   mapResolution = 50,   pointBuffer = 0.01,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"data data frame tibble. Occurrence records input. lon Character. name column use longitude. Default = \"decimalLongitude\". lat Character. name column use latitude. Default = \"decimalLatitude\". mapResolution Numeric character. passed rnaturalearth::ne_countries()'s scale. Scale map return, one 110, 50, 10 “small”, “medium”, “large”. Smaller values return higher-resolution maps. pointBuffer Numeric. Amount buffer points, decimal degrees. point outside country, within point buffer, flagged. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, st_intersects function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"input occurrence data new column, .coordinates_country_inconsistent","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"","code":"beesRaw_out <- jbd_coordCountryInconsistent(   data = BeeBDC::beesRaw,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   mapResolution = 50,   pointBuffer = 0.01) #> No '.coordinates_outOfRange' column found, running bdc_coordinates_outOfRange... #>  #> bdc_coordinates_outOfRange: #> Flagged 0 records. #> One column was added to the database. #> No '.coordinates_empty' column found, running bdc_coordinates_empty #>  #> bdc_coordinates_empty: #> Flagged 23 records. #> One column was added to the database. #>  - Downloading naturalearth map... #> Spherical geometry (s2) switched off #>  - Extracting initial country names without buffer... #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #>  - Buffering naturalearth map by pointBuffer... #> dist is assumed to be in decimal degrees (arc_degrees). #>  - Extracting FAILED country names WITH buffer... #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #>  #> jbd_coordinates_country_inconsistent: #> Flagged 2 records. #> The column, '.coordinates_country_inconsistent', was added to the database. #>  - Completed in 0.02 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags coordinates for imprecision — jbd_coordinates_precision","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"function flags occurrences latitude longitude values rounded. contrasts original function, bdc::bdc_coordinates_precision() flag occurrences one latitude longitude rounded. BeeBDC approach saves occurrences may terminal zeros rounded one coordinate column.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"","code":"jbd_coordinates_precision(   data,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   ndec = NULL,   quieter = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"data data frame tibble. Occurrence records input. lat Character. name column use latitude. Default = \"decimalLatitude\". lon Character. name column use longitude. Default = \"decimalLongitude\". ndec Numeric. number decimal places flag decimal degrees. example, argument value 2 flag occurrences nothing hundredths place (0.0x). quieter Logical. TRUE, functino run little quieter. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"Returns input data frame new column, .rou, FALSE indicates occurrences failed test.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"","code":"beesRaw_out <- jbd_coordinates_precision(   data = BeeBDC::beesRaw,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",     # number of decimals to be tested   ndec = 2 ) #> jbd_coordinates_precision: #> Flagged 30 records #> The '.rou' column was added to the database. table(beesRaw_out$.rou, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    30    70     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify transposed geographic coordinates — jbd_coordinates_transposed","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"function flags corrects records latitude longitude appear transposed.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"","code":"jbd_coordinates_transposed(   data,   idcol = \"database_id\",   sci_names = \"scientificName\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   countryCode = \"countryCode\",   border_buffer = 0.2,   save_outputs = FALSE,   fileName = NULL,   scale = \"large\",   path = NULL,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"data data frame tibble. Containing unique identifier record, geographical coordinates, country names. Coordinates must expressed decimal degrees WGS84. idcol character string. column name unique record identifier. Default = \"database_id\". sci_names character string. column name species' scientific names. Default = \"scientificName\". lat character string. column name latitudes. Coordinates must expressed decimal degrees WGS84. Default = \"decimalLatitude\". lon character string. column name longitudes. Coordinates must expressed decimal degrees WGS84. Default = \"decimalLongitude\". country character string. column name country assignment occurrence record. Default = \"country\". countryCode character string. column name containing ISO-2 country code record. border_buffer Numeric. Must value greater equal 0. distance decimal degrees used created buffer around country. Records within given country specified distance border corrected. Default = 0.2 (~22 km equator). save_outputs Logical. Indicates table containing transposed coordinates saved inspection. Default = FALSE. fileName character string. file's name. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". path character string. path character vector create directories save figures. path provided (default), directories created using ::(). mc.cores Numeric. > 1, jbd_correct_coordinates function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.#'","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"tibble containing column \"coordinates_transposed\" indicates verbatim coordinates transposed (TRUE). Otherwise records flagged (FALSE) , case, verbatim coordinates replaced corrected coordinates.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"test identifies transposed coordinates based mismatches country provided record record’s latitude longitude coordinates. Transposed coordinates often fall outside indicated country (.e., countries sea). Different coordinate transformations performed correct country/coordinates mismatches. Importantly, verbatim coordinates replaced corrected ones returned database. database containing verbatim corrected coordinates created \"Output/Check/01_coordinates_transposed.csv\" save_outputs == TRUE. columns \"country\" \"countryCode\" can retrieved using function bdc::bdc_country_standardized.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"","code":"if (FALSE) { idcol <- c(1, 2, 3, 4) scientificName <- c(   \"Rhinella major\", \"Scinax ruber\",   \"Siparuna guianensis\", \"Psychotria vellosiana\" ) decimalLatitude <- c(63.43333, -14.43333, -41.90000, -46.69778) decimalLongitude <- c(-17.90000, -67.91667, -13.25000, -13.82444) country <- c(\"BOLIVIA\", \"bolivia\", \"Brasil\", \"Brazil\")  x <- data.frame(   idcol, scientificName, decimalLatitude,   decimalLongitude, country )  # Get country codes x <- bdc::bdc_country_standardized(data = x, country = \"country\")  jbd_coordinates_transposed(   data = x,   idcol = \"idcol\",   sci_names = \"scientificName\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country_suggested\",   countryCode = \"countryCode\",   border_buffer = 0.2,   save_outputs = FALSE,   scale = \"medium\" )  }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":null,"dir":"Reference","previous_headings":"","what":"Get country names from coordinates — jbd_country_from_coordinates","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"Country names derived valid geographic coordinates added records missing country names. prefix, jbd_ meant distinguish function original bdc::bdc_country_from_coordinates().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"","code":"jbd_country_from_coordinates(   data,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   scale = \"large\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"data data frame tibble. needs contain, minimum, columns geographical coordinates country names. lat character string. column name latitude decimal degrees WGS84. Default = \"decimalLatitude\". lon character string. column longitude decimal degrees WGS84. Default = \"decimalLongitude\". country character string. column name country assignment record. Default = \"country\". column name provided new column \"country\" created. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"tibble original input data country names added records missing information country determination made.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"function assigns country name records missing information. Country names extracted valid geographic coordinates using high-quality map world (rnaturalearth package). country name added records whose coordinates sea.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_country_from_coordinates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get country names from coordinates — jbd_country_from_coordinates","text":"","code":"if (FALSE) { x <- data.frame(   decimalLatitude = c(-22.9834, -39.857030, -17.06811, -46.69778),   decimalLongitude = c(-69.095, -68.443588, 37.438108, -13.82444),   country = c(\"\", NA, NA, \"Brazil\"))  bdc_country_from_coordinates(   data = x,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\" ) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":null,"dir":"Reference","previous_headings":"","what":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"Creates figures (.e., bar plots, maps, histograms) reporting results data quality tests implemented bdc BeeBDC packages. Works like bdc::bdc_create_figures(), allows user specify save path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"","code":"jbd_create_figures(   data,   path = OutPath_Figures,   database_id = \"database_id\",   workflow_step = NULL,   save_figures = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"data data frame tibble. Needs contain results data quality tests; , columns starting \".\". path character directory. path directory save figures. Default = OutPath_Figures. database_id character string. column name unique record identifier. Default = \"database_id\". workflow_step character string. Name workflow step. Options available \"prefilter\", \"space\", \"time\". save_figures Logical. Indicates figures saved inspection use. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"List containing figures showing results data quality tests implemented one module bdc/BeeBDC. save_figures = TRUE, figures also saved locally .png format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"function creates figures based results data quality tests. pre-defined list test names used creating figures depending name workflow step informed. Figures saved \"Output/Figures\" save_figures = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"","code":"if (FALSE) { database_id <- c(\"GBIF_01\", \"GBIF_02\", \"GBIF_03\", \"FISH_04\", \"FISH_05\") lat <- c(-19.93580, -13.01667, -22.34161, -6.75000, -15.15806) lon <- c(-40.60030, -39.60000, -49.61017, -35.63330, -39.52861) .scientificName_emptys <- c(TRUE, TRUE, TRUE, FALSE, FALSE) .coordinates_empty <- c(TRUE, TRUE, TRUE, TRUE, TRUE) .invalid_basis_of_records <- c(TRUE, FALSE, TRUE, FALSE, TRUE) .summary <- c(TRUE, FALSE, TRUE, FALSE, FALSE)  x <- data.frame(   database_id,   lat,   lon,   .scientificName_emptys,   .coordinates_empty,   .invalid_basis_of_records,   .summary )  figures <-  jbd_create_figures(   data = x,    database_id = \"database_id\",   workflow_step = \"prefilter\",   save_figures = FALSE ) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"Uses expert-identified outliers source spreadsheets may edited users. function also use duplicates file made using dupeSummary() identify duplicates expert-identified outliers flag well. function add flagging column called .expertOutlier records FALSE expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"","code":"manualOutlierFindeR(   data = NULL,   DataPath = NULL,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"All_outliers_ANB.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   duplicates = NULL,   NearTRUE = NULL,   NearTRUE_threshold = 5 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"data data frame tibble. Occurrence records input. DataPath character path directory contains outlier spreadsheets. PaigeOutliersName character patch. lead outlier spreadsheet Paige Chesshire (csv file). newOutliersName character path. lead appropriate outlier spreadsheet (xlsx file). ColombiaOutliers_all character path. lead spreadsheet bee outliers Colombia (csv file). duplicates data frame tibble. duplicate file produced dupeSummary(). NearTRUE Optional. character file name csv file. want remove expert outliers close TRUE points, use name NearTRUE.csv. Note: implementation basic now unless greater need future. NearTRUE_threshold Numeric. threshold (km) distance TRUE points keep expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"Returns data new column, .expertOutlier records FALSE expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"","code":"if (FALSE) {   # Read example data   data(beesFlagged) # Read in the most-recent duplicates file as well if(!exists(\"duplicates\")){   duplicates <- fileFinder(path = DataPath,                             fileName = \"duplicateRun_\") %>%     readr::read_csv()} # identify the outliers and get a list of their database_ids beesFlagged_out <- manualOutlierFindeR(   data = beesFlagged,   DataPath = DataPath,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"^All_outliers_ANB_14March.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   duplicates = duplicates) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a plot summarising flagged data — plotFlagSummary","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"Creates compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"","code":"plotFlagSummary(   data = NULL,   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = NULL,   outPath = OutPath_Figures,   width = 15,   height = 9,   units = \"in\",   dpi = 300,   bg = \"white\",   device = \"pdf\",   speciesName = NULL,   saveFiltered = FALSE,   filterColumn = FALSE,   nameColumn = NULL,   plotMap = FALSE,   mapAlpha = 0.5,   saveTable = FALSE,   jitterValue = NULL,   returnPlot = FALSE,   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"data data frame tibble. Occurrence records input. flagColours character vector. Colours order pass (TRUE), fail (FALSE), NA. Default = c(\"#127852\", \"#A7002D\", \"#BDBABB\"). fileName Character. name file saved, ending \".pdf\". saving different file type, change file type suffix - See device. outPath character path. path directory figure saved. Default = OutPath_Figures. width Numeric. width output figure user-defined units Default = 15. height Numeric. height output figure user-defined units Default = 9. units Character. units figure width height passed ggplot2::ggsave() (\"\", \"cm\", \"mm\", \"px\"). Default = \"\". dpi Numeric. Passed ggplot2::ggsave(). Plot resolution. Also accepts string input: \"retina\" (320), \"print\" (300), \"screen\" (72). Applies raster output types. Default = 300. bg Character. Passed ggplot2::ggsave(). Background colour. NULL, uses plot.background fill value plot theme. Default = \"white.\" device Character. Passed ggplot2::ggsave(). Device use. Can either device function (e.g. png), one \"eps\", \"ps\", \"tex\" (pictex), \"pdf\", \"jpeg\", \"tiff\", \"png\", \"bmp\", \"svg\" \"wmf\" (windows ). Default = \"pdf\". using default, change file name suffix fileName argument. speciesName Optional. Character. species name, occurs user-input nameColumn. provided, data filtered species plot. saveFiltered Optional. Logical. TRUE, filtered data saved computer .csv file. filterColumn Optional. flag column display map. Default = .summary. nameColumn Optional. Character. speciesName NULL, enter column look species . User might realise , combined speciesName, figures can made variety factors. plotMap Logical. TRUE, function produce point map. Tested use one species time; .e., speciesName NULL. mapAlpha Optional. Numeric. opacity points map. saveTable Optional. Logical. TRUE, function save data used produce compound bar plot. jitterValue Optional. Numeric. value jitter points map decimal degrees. returnPlot Logical. TRUE, return plot environment. Default = FALSE. ... Optional. Extra variables fed forcats::fct_recode() change names plot. example... 'B. Mont.' = \"BMont\", 'B. Minkley' = \"BMin\", Ecd = \"Ecd\", Gaiarsa = \"Gai\"","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"Exports compound bar plot summarises flag columns. Optionally can also return point map particular species tandem summary plot.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"","code":"# import data data(beesFlagged) OutPath_Figures <- tempdir()  # Visualise all flags for each dataSource (simplified to the text before the first underscore) plotFlagSummary(   data = beesFlagged,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"FlagsPlot_TEST_\", Sys.Date(),\".pdf\"),   outPath = OutPath_Figures,   width = 15, height = 9,   # OPTIONAL:   #\\   #  # Filter to species   #\\   speciesName = \"Holcopasites heliopsis\",   #\\   # column to look in   #\\   nameColumn = \"species\",   #\\   # Save the filtered data   #\\   saveFiltered = TRUE,   #\\   # Filter column to display on map   #\\   filterColumn = \".summary\",   #\\   plotMap = TRUE,   #\\   # amount to jitter points if desired, e.g. 0.25 or NULL   #\\   jitterValue = NULL,   #\\   # Map opacity value for points between 0 and 1   #\\   mapAlpha = 1,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'B. Mont.' = \"BMont\", 'B. Minkley' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\" ) #>  - Preparing data to plot... #>  - Building plot..."},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":null,"dir":"Reference","previous_headings":"","what":"Read in specific bee datasets — readr_BeeBDC","title":"Read in specific bee datasets — readr_BeeBDC","text":"Read variety data files specific certain smaller data providers. internal readr function dataset one functions called readr_BeeBDC. functions internal, displayed documentation readr_BeeBDC clarity.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read in specific bee datasets — readr_BeeBDC","text":"","code":"readr_BeeBDC(   dataset = NULL,   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = NULL )  readr_EPEL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_ASP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_BMin(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_BMont(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Ecd(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Gai(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_CAES(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Sheet1\" )  readr_KP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_EcoS(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_GeoL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_EaCO(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MABC(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Hoja1\" )  readr_Col(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = sheet )  readr_FSCA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_SMC(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Bal(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"animal_data\" )  readr_Lic(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Arm(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Sheet1\" )  readr_Dor(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MEPB(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = NULL )  readr_BBD(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MPUJ(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = sheet )  readr_STRI(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_PALA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_JoLa(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = c(\"pre-1950\", \"post-1950\") )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read in specific bee datasets — readr_BeeBDC","text":"dataset Character. name dataset read . example readr_CAES can called using \"readr_CAES\" \"CAES\". caps sensitive. path character path. path directory containing data. inFile Character character path. name file (can also remainder path including file name). outFile Character character path. name Darwin Core format file saved. dataLicense Character. license accompany record Darwin Core 'license' column. sheet character String. datasets read .xlsx format, provide sheet name. NOTE: ignored .csv readr_ functions required .xlsx readr_ functions.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read in specific bee datasets — readr_BeeBDC","text":"data frame Darwin Core format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read in specific bee datasets — readr_BeeBDC","text":"function wraps several internal readr functions. Users may call readr_BeeBDC select dataset name import certain dataset. datasets include: Excel (.xlsx) formatted datasets: CAES, MABC, Col, Bal, MEPB, MUPJ, Arm, JoLa. CSV (.csv) formatted datasets: EPEL, ASP, BMin, BMont, Ecd, Gai, KP, EcoS, GeoL, EaCo, FSCA, SMC, Lic, Dor, BBD, STRI, PALA See Dorey et al. 2023 BeeBDC... details.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Read in specific bee datasets — readr_BeeBDC","text":"readr_EPEL(): Reads specific data files Darwin Core format readr_ASP(): Reads specific data files Darwin Core format readr_BMin(): Reads specific data files Darwin Core format readr_BMont(): Reads specific data files Darwin Core format readr_Ecd(): Reads specific data files Darwin Core format readr_Gai(): Reads specific data files Darwin Core format readr_CAES(): Reads specific data files Darwin Core format readr_KP(): Reads specific data files Darwin Core format readr_EcoS(): Reads specific data files Darwin Core format readr_GeoL(): Reads specific data files Darwin Core format readr_EaCO(): Reads specific data files Darwin Core format readr_MABC(): Reads specific data files Darwin Core format readr_Col(): Reads specific data files Darwin Core format readr_FSCA(): Reads specific data files Darwin Core format readr_SMC(): Reads specific data files Darwin Core format readr_Bal(): Reads specific data files Darwin Core format readr_Lic(): Reads specific data files Darwin Core format readr_Arm(): Reads specific data files Darwin Core format readr_Dor(): Reads specific data files Darwin Core format readr_MEPB(): Reads specific data files Darwin Core format readr_BBD(): Reads specific data files Darwin Core format readr_MPUJ(): Reads specific data files Darwin Core format readr_STRI(): Reads specific data files Darwin Core format readr_PALA(): Reads specific data files Darwin Core format readr_JoLa(): Reads specific data files Darwin Core format","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read in specific bee datasets — readr_BeeBDC","text":"","code":"if (FALSE) { # An example using a .xlsx file Arm_Data <- readr_BeeBDC(     dataset = \"Arm\",     path = paste0(tempdir(), \"/Additional_Datasets\"),     inFile = \"/InputDatasets/Bee database Armando_Final.xlsx\",     outFile = \"jbd_Arm_Data.csv\",     sheet = \"Sheet1\",     dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")               # An example using a .csv file EPEL_Data <- readr_BeeBDC(   dataset = \"readr_EPEL\",   path = paste0(tempdir(), \"/Additional_Datasets\"),   inFile = \"/InputDatasets/bee_data_canada.csv\",   outFile = \"jbd_EPEL_data.csv\",   dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\") }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":null,"dir":"Reference","previous_headings":"","what":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"Find GBIF, ALA, iDigBio, SCAN files directory","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"","code":"repoFinder(path)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"path directory character. path within recursively look GBIF, ALA, iDigBio, SCAN files.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"Returns list directories data downloads","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"","code":"if (FALSE) { # Where DataPath is made by [BeeBDC::dirMaker()] BeeBDC::repoFinder(path = DataPath) }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":null,"dir":"Reference","previous_headings":"","what":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"Locates data GBIF, ALA, iDigBio, SCAN within directory reads along eml metadata.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"","code":"repoMerge(path, save_type, occ_paths)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"path directory character. directory recursively look data. save_type Character. data type save resulting file . Options : csv_files\" \"R_file\". occ_paths list directories. Preferably produced using repoFinder() function asks list paths relevant input datasets. can fault-find errors function checking output repoFinder().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"list data frame merged occurrence records, \"Data_WebDL\", list eml files contained \"eml_files\". Also saves files requested format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"","code":"if (FALSE) { DataImp <- repoMerge(path = DataPath,  # Find data - Many problems can be solved by running [BeeBDC::repoFinder(path = DataPath)] # And looking for problems occ_paths = BeeBDC::repoFinder(path = DataPath), save_type = \"R_file\") }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update the .summary flag column — summaryFun","title":"Create or update the .summary flag column — summaryFun","text":"Using flag columns (column names starting \".\"), function either creates updates .summary flag column FALSE flag columns FALSE. Columns can excluded removed creating .summary column. Additionally, occurrence dataset can filtered .summary = TRUE end function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update the .summary flag column — summaryFun","text":"","code":"summaryFun(   data = NULL,   dontFilterThese = NULL,   removeFilterColumns = FALSE,   filterClean = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update the .summary flag column — summaryFun","text":"data data frame tibble. Occurrence records use input. dontFilterThese character vector flag columns ignored creation updating .summary column. removeFilterColumns Logical. TRUE columns starting \".\" removed output data. makes sense use filterClean = TRUE. Default = FALSE. filterClean Logical. TRUE, data filtered occurrence .summary = TRUE (.e., completely clean according used flag columns). Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update the .summary flag column — summaryFun","text":"Returns data frame tibble input data modified based parameters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update the .summary flag column — summaryFun","text":"","code":"# Read in example data data(beesFlagged)  # To only update the .summary column beesFlagged_out <- summaryFun(     data = beesFlagged,     dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\", \".unLicensed\"),     removeFilterColumns = FALSE,     filterClean = FALSE) #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .unLicensed #>  - summaryFun: #> Flagged 81  #>   The .summary column was added to the database.   # View output table(beesFlagged_out$.summary, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    81    19     0   # Now filter to only the clean data and remove the flag columns beesFlagged_out <- summaryFun(   data = BeeBDC::beesFlagged,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\", \".unLicensed\"),   removeFilterColumns = TRUE,   filterClean = TRUE) #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .unLicensed #>  - summaryFun: #> Flagged 81  #>   The .summary column was added to the database. #>  - REMOVED all occurrences that were FALSE for the 'summary' column. # View output table(beesFlagged_out$.summary, useNA = \"always\") #> Warning: Unknown or uninitialised column: `.summary`. #>  #> <NA>  #>    0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Create country-level summary maps of species and occurrence numbers — summaryMaps","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"Builds output figure shows number species number occurrences per country. Breaks data classes visualisation. Users may filter data taxa interest produce figures interest.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"","code":"summaryMaps(   data = NULL,   class_n = 15,   class_Style = \"fisher\",   outPath = NULL,   fileName = NULL,   width = 10,   height = 5,   dpi = 300,   returnPlot = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"data data frame tibble. Occurrence records input. class_n Numeric. number categories break data . class_Style Character. class style passed classInt::classIntervals(). Options chosen style: one \"fixed\", \"sd\", \"equal\", \"pretty\", \"quantile\", \"kmeans\", \"hclust\", \"bclust\", \"fisher\", \"jenks\", \"dpih\", \"headtails\", \"maximum\". Default = \"fisher\" outPath character vector path save location output figure. fileName character vector file name output figure, ending '.pdf'. width Numeric. width, inches, resulting figure. Default = 10. height Numeric. height, inches, resulting figure. Default = 5. dpi Numeric. resolution resulting plot. Default = 300. returnPlot Logical. TRUE, return plot environment. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"Saves figure user-specified outpath name global map bee occurrence species count data input dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"","code":"# Read in data data(beesFlagged) OutPath_Figures <- tempdir() # This simple example using the test data has very few classes due to the small amount of input  # data. summaryMaps( data = beesFlagged, width = 10, height = 10, class_n = 4, class_Style = \"fisher\", outPath = OutPath_Figures, fileName = paste0(\"CountryMaps_fisher_TEST.pdf\"), ) #>  - Extracting country data from points... #> although coordinates are longitude/latitude, st_intersection assumes that they #> are planar #> Extraction complete."},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"beebdc-021","dir":"Changelog","previous_headings":"","what":"BeeBDC 0.2.1","title":"BeeBDC 0.2.1","text":"Initial CRAN submission.","code":""}]
