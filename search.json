[{"path":[]},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"working-directory","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.1 Working directory","title":"BeeBDC vignette","text":"Choose path root folder folders can found. first time run BeeBDC, want use renv package manage packages, can install renv… initialise renv project. already initialised project, can instead just activate .","code":"RootPath <- paste0(\"/your/path/here\") # Create the working directory in the RootPath if it doesn't exist already if (!dir.exists(paste0(RootPath, \"/Data_acquisition_workflow\"))) {     dir.create(paste0(RootPath, \"/Data_acquisition_workflow\"), recursive = TRUE) } # Set the working directory setwd(paste0(RootPath, \"/Data_acquisition_workflow\")) install.packages(\"renv\", repos = \"http://cran.us.r-project.org\") renv::init(project = paste0(RootPath,\"/Data_acquisition_workflow\")) renv::activate(project = paste0(RootPath, \"/Data_acquisition_workflow\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"install-packages-if-needed","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.2 Install packages (if needed)","title":"BeeBDC vignette","text":"may need install gdal computer. can done Mac using Homebrew terminal command “brew install gdal”. start , need install BiocManager, devtools, ComplexHeatmap, rnaturalearthhires install fully use BeeBDC. Now install BeeBDC. Snapshot renv environment. Set directories used BeeBDC. directories include data, figures, reports, etc. saved. RDoc needs path RELATIVE RootPath; .e., file path two diverge.","code":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\", repos = \"http://cran.us.r-project.org\")  BiocManager::install(\"ComplexHeatmap\") # Install remotes if needed if (!require(\"remotes\", quietly = TRUE)) install.packages(\"remotes\", repos = \"http://cran.us.r-project.org\") # Download and then load rnaturalearthhires remotes::install_github(\"ropensci/rnaturalearthhires\") install.packages(\"rnaturalearthhires\", repos = \"https://ropensci.r-universe.dev\",     type = \"source\") library(rnaturalearthhires) install.packages(\"BeeBDC\") library(BeeBDC) renv::snapshot(project = paste0(RootPath, \"/Data_acquisition_workflow\"), prompt = FALSE) ## The following package(s) will be updated in the lockfile: ##  ## # RSPM ----------------------------------------------------------------------- ## - renv   [* -> 1.1.4] ##  ## The version of R recorded in the lockfile will be updated: ## - R      [* -> 4.5.1] ##  ## - Lockfile written to \"/tmp/RtmpxEUPYm/Data_acquisition_workflow/renv.lock\". BeeBDC::dirMaker(RootPath = RootPath, RDoc = \"vignettes/BeeBDC_main.Rmd\") %>%     # Add paths created by this function to the environment() list2env(envir = parent.env(environment()))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"load-packages","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.3 Load packages","title":"BeeBDC vignette","text":"Load packages.","code":"lapply(c(\"ComplexHeatmap\", \"magrittr\"), library, character.only = TRUE) ## Loading required package: grid ##  ## Attaching package: 'grid' ## The following object is masked from 'package:terra': ##  ##     depth ## ======================================== ## ComplexHeatmap version 2.24.0 ## Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/ ## Github page: https://github.com/jokergoo/ComplexHeatmap ## Documentation: http://jokergoo.github.io/ComplexHeatmap-reference ##  ## If you use it in published research, please cite either one: ## - Gu, Z. Complex Heatmap Visualization. iMeta 2022. ## - Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional  ##     genomic data. Bioinformatics 2016. ##  ##  ## The new InteractiveComplexHeatmap package can directly export static  ## complex heatmaps into an interactive Shiny app with zero effort. Have a try! ##  ## This message can be suppressed by: ##   suppressPackageStartupMessages(library(ComplexHeatmap)) ## ======================================== ##  ## Attaching package: 'ComplexHeatmap' ## The following object is masked from 'package:terra': ##  ##     draw ## The following object is masked from 'package:R.utils': ##  ##     draw"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-merge","dir":"Articles","previous_headings":"","what":"1.0 Data merge","title":"BeeBDC vignette","text":"Attention:  Although line code validated, order save time knitting R markdown document next section display . data merging (section 1.0) preparing data (section 2.0), feel free skip Section 3.0 Initial flags.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"download-ala-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.1 Download ALA data","title":"BeeBDC vignette","text":"Download ALA data create new file DataPath put data . also first make account ALA order download data — https://auth.ala.org.au/userdetails/registration/createAccount","code":"BeeBDC::atlasDownloader(path = DataPath,            userEmail = \"your@email.edu.au\",            atlas = \"ALA\",            ALA_taxon = \"Apiformes\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-and-merge-ala-scan-idigbio-and-gbif-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.2 Import and merge ALA, SCAN, iDigBio, and GBIF data","title":"BeeBDC vignette","text":"Supply path data , save_type either “csv_files” “R_file”. error finding file, run repoFinder() troubleshoot. example: Load -recent version data needed. return list : occurrence dataset attributes (.$Data_WebDL) appended eml file (.$eml_files)","code":"DataImp <- BeeBDC::repoMerge(path = DataPath,                    occ_paths = BeeBDC::repoFinder(path = DataPath),                   save_type = \"R_file\") #BeeBDC::repoFinder(path = DataPath)             #OUTPUT:             #$ALA_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/ALA_galah_path/galah_download_2022-09-15/data.csv\"                #$GBIF_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0000165-220831081235567/occurrence.txt\"             #[2] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436695-210914110416597/occurrence.txt\"             #[3] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436697-210914110416597/occurrence.txt\"             #[4] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436704-210914110416597/occurrence.txt\"             #[5] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436732-210914110416597/occurrence.txt\"             #[6] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436733-210914110416597/occurrence.txt\"             #[7] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/GBIF_webDL_30Aug2022/0436734-210914110416597/occurrence.txt\"                                  #$iDigBio_data             #[1] \"F:/BeeDataCleaning2022/BeeDataCleaning/BeeDataCleaning/BeeData/iDigBio_webDL_30Aug2022/5aa5abe1-62e0-4d8c-bebf-4ac13bd9e56f/occurrence_raw.csv\"                #$SCAN_data             #character(0)             #Failing because SCAN_data seems to be missing. Downloaded separatly from the one drive DataImp <- BeeBDC::importOccurrences(path = DataPath,                        fileName = \"BeeData_\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-usgs-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.3 Import USGS Data","title":"BeeBDC vignette","text":"USGS_formatter() find, import, format, create metadata USGS dataset. pubDate must day-month-year format.","code":"USGS_data <- BeeBDC::USGS_formatter(path = DataPath, pubDate = \"19-11-2022\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"formatted-source-importer","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.4 Formatted Source Importer","title":"BeeBDC vignette","text":"Use importer find files formatted need added larger data file. attributes file must contain “attribute” name, occurrence file must . column catalogNumber, remove “.*specimennumber:” comes USGS number match duplicates.","code":"Complete_data <- BeeBDC::formattedCombiner(path = DataPath,                                  strings = c(\"USGS_[a-zA-Z_]+[0-9]{4}-[0-9]{2}-[0-9]{2}\"),                                    # This should be the list-format with eml attached                                 existingOccurrences = DataImp$Data_WebDL,                                 existingEMLs = DataImp$eml_files) Complete_data$Data_WebDL <- Complete_data$Data_WebDL %>%     dplyr::mutate(catalogNumber = stringr::str_replace(catalogNumber,                                                        pattern = \".*\\\\| specimennumber:\",                                                        replacement = \"\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-data","dir":"Articles","previous_headings":"1.0 Data merge","what":"1.5 Save data","title":"BeeBDC vignette","text":"Choose type data format want use saving work 1.x.","code":"BeeBDC::dataSaver(path = DataPath,# The main path to look for data in        save_type = \"CSV_file\", # \"R_file\" OR \"CSV_file\"        occurrences = Complete_data$Data_WebDL, # The existing datasheet        eml_files = Complete_data$eml_files, # The existing EML files        file_prefix = \"Fin_\") # The prefix for the fileNames rm(Complete_data, DataImp)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-preparation","dir":"Articles","previous_headings":"","what":"2.0 Data preparation","title":"BeeBDC vignette","text":"data preparatin section script relates mostly integrating bee occurrence datasets corrections may skipped many general taxon users.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"standardise-datasets","dir":"Articles","previous_headings":"2.0 Data preparation","what":"2.1 Standardise datasets","title":"BeeBDC vignette","text":"may either use: bdc import method (works well general datasets) jbd import method (works well data merge)","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--bdc-import","dir":"Articles","previous_headings":"2.0 Data preparation > 2.1 Standardise datasets","what":"a. bdc import","title":"BeeBDC vignette","text":"bdc import truly supported , provided example. Please go section 2.1b . Read bdc metadata standardise dataset bdc.","code":"bdc_metadata <- readr::read_csv(paste(DataPath, \"out_file\", \"bdc_integration.csv\", sep = \"/\"))         # ?issue — datasetName is a darwinCore field already!         # Standardise the dataset to bdc         db_standardized <- bdc::bdc_standardize_datasets(           metadata = bdc_metadata,           format = \"csv\",           overwrite = TRUE,           save_database = TRUE)         # read in configuration description file of the column header info         config_description <- readr::read_csv(paste(DataPath, \"Output\", \"bdc_configDesc.csv\",                                                     sep = \"/\"),                                                show_col_types = FALSE, trim_ws = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--jbd-import","dir":"Articles","previous_headings":"2.0 Data preparation > 2.1 Standardise datasets","what":"b. jbd import","title":"BeeBDC vignette","text":"Find path, read file, add database_id column.","code":"occPath <- BeeBDC::fileFinder(path = DataPath, fileName = \"Fin_BeeData_combined_\")     db_standardized <- readr::read_csv(occPath,                                         # Use the basic ColTypeR function to determine types                                      col_types = BeeBDC::ColTypeR(), trim_ws = TRUE) %>%                                      dplyr::mutate(database_id = paste(\"Dorey_data_\",                                       1:nrow(.), sep = \"\"),                                      .before = family)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--optional-thin","dir":"Articles","previous_headings":"2.0 Data preparation > 2.1 Standardise datasets","what":"c. optional thin","title":"BeeBDC vignette","text":"can thin dataset TESTING !","code":"check_pf <- check_pf %>%            # take every 100th record            filter(row_number() %% 100 == 1)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"paige-dataset","dir":"Articles","previous_headings":"2.0 Data preparation","what":"2.2 Paige dataset","title":"BeeBDC vignette","text":"Paige Chesshire’s cleaned American dataset — https://doi.org/10.1111/ecog.06584","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"import-data","dir":"Articles","previous_headings":"2.0 Data preparation > 2.2 Paige dataset","what":"Import data","title":"BeeBDC vignette","text":"haven’t figured now, don’t worry column name warning — columns occur . Attention:  recommended run code full bee dataset 16GB RAM. Robert ran laptop 16GB RAM Intel(R) Core(TM) i7-8550U processor (4 cores 8 threads) — struggled.","code":"PaigeNAm <- readr::read_csv(paste(DataPath, \"Paige_data\", \"NorAmer_highQual_only_ALLfamilies.csv\",                                     sep = \"/\"), col_types = BeeBDC::ColTypeR()) %>%      # Change the column name from Source to dataSource to match the rest of the data.     dplyr::rename(dataSource = Source) %>%      # EXTRACT WAS HERE       # add a NEW database_id column     dplyr::mutate(       database_id = paste0(\"Paige_data_\", 1:nrow(.)),       .before = scientificName)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"merge-paiges-data-with-downloaded-data","dir":"Articles","previous_headings":"2.0 Data preparation > 2.2 Paige dataset","what":"Merge Paige’s data with downloaded data","title":"BeeBDC vignette","text":"Remove spent data.","code":"db_standardized <- BeeBDC::PaigeIntegrater(       db_standardized = db_standardized,       PaigeNAm = PaigeNAm,         # This is a list of columns by which to match Paige's data to the most-recent download with.          # Each vector will be matched individually       columnStrings = list(         c(\"decimalLatitude\", \"decimalLongitude\",            \"recordNumber\", \"recordedBy\", \"individualCount\", \"samplingProtocol\",           \"associatedTaxa\", \"sex\", \"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",           \"recordId\", \"occurrenceID\", \"collectionID\"),         # Iteration 1         c(\"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",           \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 2         c(\"decimalLatitude\", \"decimalLongitude\",            \"recordedBy\", \"genus\", \"specificEpithet\"),# Iteration 3         c(\"id\", \"decimalLatitude\", \"decimalLongitude\"),# Iteration 4         c(\"recordedBy\", \"genus\", \"specificEpithet\", \"locality\"), # Iteration 5         c(\"recordedBy\", \"institutionCode\", \"genus\",            \"specificEpithet\",\"locality\"),# Iteration 6         c(\"occurrenceID\",\"decimalLatitude\", \"decimalLongitude\"),# Iteration 7         c(\"catalogNumber\",\"decimalLatitude\", \"decimalLongitude\"),# Iteration 8         c(\"catalogNumber\", \"locality\") # Iteration 9       ) ) rm(PaigeNAm)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"usgs","dir":"Articles","previous_headings":"2.0 Data preparation","what":"2.3 USGS","title":"BeeBDC vignette","text":"USGS dataset also partially occurs GBIF BISON. However, occurrence codes silly place… correct help identify duplicates later.","code":"db_standardized <- db_standardized %>%           # Remove the discoverlife html if it is from USGS       dplyr::mutate(occurrenceID = dplyr::if_else(         stringr::str_detect(occurrenceID, \"USGS_DRO\"),         stringr::str_remove(occurrenceID, \"http://www\\\\.discoverlife\\\\.org/mp/20l\\\\?id=\"),         occurrenceID)) %>%           # Use otherCatalogNumbers when occurrenceID is empty AND when USGS_DRO is detected there       dplyr::mutate(         occurrenceID = dplyr::if_else(           stringr::str_detect(otherCatalogNumbers, \"USGS_DRO\") & is.na(occurrenceID),           otherCatalogNumbers, occurrenceID)) %>%            # Make sure that no eventIDs have snuck into the occurrenceID columns             # For USGS_DRO, codes with <6 digits are event ids       dplyr::mutate(         occurrenceID = dplyr::if_else(stringr::str_detect(occurrenceID, \"USGS_DRO\", negate = TRUE),              # Keep occurrenceID if it's NOT USGS_DRO            occurrenceID,               # If it IS USGS_DRO and it has => 6 numbers, keep it, else, NA           dplyr::if_else(stringr::str_detect(occurrenceID, \"USGS_DRO[0-9]{6,10}\"),                          occurrenceID, NA_character_)),         catalogNumber = dplyr::if_else(stringr::str_detect(catalogNumber, \"USGS_DRO\", negate = TRUE),              # Keep catalogNumber if it's NOT USGS_DRO           catalogNumber,               # If it IS USGS_DRO and it has => 6 numbers, keep it, else, NA           dplyr::if_else(stringr::str_detect(catalogNumber, \"USGS_DRO[0-9]{6,10}\"),                          catalogNumber, NA_character_)))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"additional-datasets","dir":"Articles","previous_headings":"2.0 Data preparation","what":"2.4 Additional datasets","title":"BeeBDC vignette","text":"Import additional potentially private datasets. Note: Private dataset functions provided data integrated datasets become freely available. warnings rows may formatted correctly dates fail parse. normal.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--epel","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Guzman, L. M., Kelly, T. & Elle, E. data set pollinator diversity interactions plants Pacific Northwest. Ecology, e3927 (2022). https://doi.org/10.1002/ecy.3927","code":"EPEL_Data <- BeeBDC::readr_BeeBDC(dataset = \"EPEL\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/bee_data_canada.csv\",                       outFile = \"jbd_EPEL_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--allan-smith-pardo","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data Allan Smith-Pardo","code":"ASP_Data <- BeeBDC::readr_BeeBDC(dataset = \"ASP\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Allan_Smith-Pardo_Dorey_ready2.csv\",                       outFile = \"jbd_ASP_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--minckley","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data Robert Minckley","code":"BMin_Data <- BeeBDC::readr_BeeBDC(dataset = \"BMin\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Bob_Minckley_6_1_22_ScanRecent-mod_Dorey.csv\",                         outFile = \"jbd_BMin_data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"d--bmont","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Delphia, C. M. Bumble bees Montana. https://www.mtent.org/projects/Bumble_Bees/bombus_species.html. (2022)","code":"BMont_Data <- BeeBDC::readr_BeeBDC(dataset = \"BMont\",                                  path = paste0(DataPath, \"/Additional_Datasets\"),                           inFile = \"/InputDatasets/Bombus_Montana_dorey.csv\",                           outFile = \"jbd_BMont_data.csv\",                           dataLicense = \"https://creativecommons.org/licenses/by-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"e--ecd","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Ecdysis. Ecdysis: portal live-data arthropod collections, https://ecdysis.org/index.php (2022).","code":"Ecd_Data <- BeeBDC::readr_BeeBDC(dataset = \"Ecd\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Ecdysis_occs.csv\",                       outFile = \"jbd_Ecd_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"f--gai","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Gaiarsa, M. P., Kremen, C. & Ponisio, L. C. Pollinator interaction flexibility across scales affects patch colonization occupancy. Nature Ecology & Evolution 5, 787-793 (2021). https://doi.org/10.1038/s41559-021-01434-y","code":"Gai_Data <- BeeBDC::readr_BeeBDC(dataset = \"Gai\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/upload_to_scan_Gaiarsa et al_Dorey.csv\",                       outFile = \"jbd_Gai_data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"g--caes","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Connecticut Agricultural Experiment Station. Zarrillo, T. ., Stoner, K. . & Ascher, J. S. Biodiversity bees (Hymenoptera: Apoidea: Anthophila) Connecticut (USA). Zootaxa (Accepted). Ecdysis. Occurrence dataset (ID: 16fca9c2-f622-4cb1-aef0-3635a7be5aeb). https://ecdysis.org/content/dwca/CAES-CAES_DwC-.zip. (2023)","code":"CAES_Data <- BeeBDC::readr_BeeBDC(dataset = \"CAES\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/CT_BEE_DATA_FROM_PBI.xlsx\",                         outFile = \"jbd_CT_Data.csv\",                         sheet = \"Sheet1\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"h--geol","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"","code":"GeoL_Data <- BeeBDC::readr_BeeBDC(dataset = \"GeoL\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Geolocate and BELS_certain and accurate.xlsx\",                         outFile = \"jbd_GeoL_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"i--eaco","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"","code":"EaCO_Data <- BeeBDC::readr_BeeBDC(dataset = \"EaCO\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"/InputDatasets/Eastern Colorado bee 2017 sampling.xlsx\",                         outFile = \"jbd_EaCo_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"j--fsca","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Florida State Collection Arthropods","code":"FSCA_Data <- BeeBDC::readr_BeeBDC(dataset = \"FSCA\",                                 path = paste0(DataPath, \"/Additional_Datasets\"),                         inFile = \"InputDatasets/fsca_9_15_22_occurrences.csv\",                         outFile = \"jbd_FSCA_Data.csv\",                         dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"k--texas-smc","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Published unpublished data Texas literature online database, usually copied spreadsheet document format, otherwise copied differently-formatted spreadsheet. Unpublished partially published data obtained express permission lead author.","code":"SMC_Data <- BeeBDC::readr_BeeBDC(dataset = \"SMC\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/TXbeeLitOccs_31Oct22.csv\",                        outFile = \"jbd_SMC_Data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"l--texas-bal","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data GPS coordinates (missing accidentally records Dryad) Ballare, K. M., Neff, J. L., Ruppel, R. & Jha, S. Multi-scalar drivers biodiversity: local management mediates wild bee community response regional urbanization. Ecological Applications 29, e01869 (2019), https://doi.org/10.1002/eap.1869. version Dryad missing site GPS coordinates (accident). Kim okay data made public long paper referenced. - Elinor Lichtenberg","code":"Bal_Data <- BeeBDC::readr_BeeBDC(dataset = \"Bal\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Beedata_ballare.xlsx\",                        outFile = \"jbd_Bal_Data.csv\",                       sheet = \"animal_data\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"m--palouse-lic","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Elinor Lichtenberg’s canola data: Lichtenberg, E. M., Milosavljević, ., Campbell, . J. & Crowder, D. W. Differential effects soil conservation practices arthropods crop yields. Journal Applied Entomology, (2023) https://doi.org/10.1111/jen.13188. data putting SCAN. - Elinor Lichtenberg","code":"Lic_Data <- BeeBDC::readr_BeeBDC(dataset = \"Lic\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Lichtenberg_canola_records.csv\",                        outFile = \"jbd_Lic_Data.csv\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"n--arm","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"Data Armando Falcon-Brindis University Kentucky.","code":"Arm_Data <- BeeBDC::readr_BeeBDC(dataset = \"Arm\",                                path = paste0(DataPath, \"/Additional_Datasets\"),                       inFile = \"/InputDatasets/Bee database Armando_Final.xlsx\",                       outFile = \"jbd_Arm_Data.csv\",                       sheet = \"Sheet1\",                       dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"o--dor","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"several papers: Dorey, J. B., Fagan-Jeffries, E. P., Stevens, M. ., & Schwarz, M. P. (2020). Morphometric comparisons novel observations diurnal low-light-foraging bees. Journal Hymenoptera Research, 79, 117–144. doi:https://doi.org/10.3897/jhr.79.57308 Dorey, J. B. (2021). Missing almost 100 years: rare potentially threatened bee Pharohylaeus lactiferus (Hymenoptera, Colltidae). Journal Hymenoptera Research, 81, 165-180. doi: https://doi.org/10.3897/jhr.81.59365 Dorey, J. B., Schwarz, M. P., & Stevens, M. . (2019). Review bee genus Homalictus Cockerell (Hymenoptera: Halictidae) Fiji description nine new species. Zootaxa, 4674(1), 1–46. doi:https://doi.org/10.11646/zootaxa.4674.1.1","code":"Dor_Data <- BeeBDC::readr_BeeBDC(dataset = \"Dor\",                     path = paste0(DataPath, \"/Additional_Datasets\"),                     inFile = \"/InputDatasets/DoreyData.csv\",                     outFile = \"jbd_Dor_Data.csv\",                     dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"p--vicwam","dir":"Articles","previous_headings":"","what":"BeeBDC vignette","title":"BeeBDC vignette","text":"data originally Victorian Museum Western Australian Museum Australia. However, current form Dorey et al. 2021. PADIL. (2020). PaDIL. https://www.PADIL.gov.au/ Houston, T. F. (2000). Native bees wildflowers Western Australia. Western Australian Insect Study Society. Dorey, J. B., Rebola, C. M., Davies, O. K., Prendergast, K. S., Parslow, B. ., Hogendoorn, K., . . . Caddy-Retalic, S. (2021). Continental risk assessment understudied taxa post catastrophic wildfire indicates severe impacts Australian bee fauna. Global Change Biology, 27(24), 6551-6567. doi:https://doi.org/10.1111/gcb.15879","code":"VicWam_Data <- BeeBDC::readr_BeeBDC(dataset = \"VicWam\",                     path = paste0(DataPath, \"/Additional_Datasets\"),                     inFile = \"/InputDatasets/Combined_Vic_WAM_databases.xlsx\",                     outFile = \"jbd_VicWam_Data.csv\",                     dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\",                     sheet = \"Combined\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"merge-all","dir":"Articles","previous_headings":"2.0 Data preparation > 2.4 Additional datasets","what":"2.5 Merge all","title":"BeeBDC vignette","text":"Remove spent datasets. Read merge . readr_BeeBDC() supported currently implemented represent datasets publicly released future. See ‘?readr_BeeBDC()’ details.","code":"rm(EPEL_Data, ASP_Data, BMin_Data, BMont_Data, Ecd_Data, Gai_Data, CAES_Data,    GeoL_Data, EaCO_Data, FSCA_Data, SMC_Data, Bal_Data, Lic_Data, Arm_Data, Dor_Data,   VicWam_Data) db_standardized <- db_standardized %>%   dplyr::bind_rows(     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_ASP_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_EPEL_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_BMin_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_BMont_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Ecd_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Gai_data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_CT_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_GeoL_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_EaCo_Data.csv\"), col_types = BeeBDC::ColTypeR()),      readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_SMC_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Bal_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Lic_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Arm_Data.csv\"), col_types = BeeBDC::ColTypeR()),     readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                             \"/jbd_Dor_Data.csv\"), col_types = BeeBDC::ColTypeR()), readr::read_csv(paste0(DataPath, \"/Additional_Datasets\",                         \"/jbd_VicWam_Data.csv\"), col_types = BeeBDC::ColTypeR())) %>%      # END bind_rows   suppressWarnings(classes = \"warning\") # End suppressWarnings — due to col_types"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"match-database_id","dir":"Articles","previous_headings":"2.0 Data preparation > 2.4 Additional datasets","what":"2.6 Match database_id","title":"BeeBDC vignette","text":"prior runs ’d like match database_ids current run, may use script try match database_ids prior runs. Read prior run choice. function attempt find database_ids prior runs. Save dataset.","code":"priorRun <- BeeBDC::fileFinder(path = DataPath,                           file = \"01_prefilter_database_9Aug22.csv\") %>%     readr::read_csv(file = ., col_types = BeeBDC::ColTypeR()) db_standardized <- BeeBDC::idMatchR(   currentData = db_standardized,   priorData = priorRun,     # First matches will be given preference over later ones   matchBy = tibble::lst(c(\"gbifID\", \"dataSource\"),                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\", \"decimalLatitude\",                           \"decimalLongitude\"),                         c(\"occurrenceID\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         c(\"recordId\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         c(\"id\", \"dataSource\",\"decimalLatitude\",\"decimalLongitude\"),                         # Because INHS was entered as it's own dataset but is now included in the GBIF    download...                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\",                           \"decimalLatitude\",\"decimalLongitude\")),     # You can exclude datasets from prior by matching their prefixs — before first underscore:   excludeDataset = c(\"ASP\", \"BMin\", \"BMont\", \"CAES\", \"EaCO\", \"Ecd\", \"EcoS\",                      \"Gai\", \"KP\", \"EPEL\", \"CAES\", \"EaCO\", \"FSCA\", \"SMC\", \"Lic\", \"Arm\",                      \"VicWam\"))   # Remove redundant files rm(priorRun) db_standardized %>%     readr::write_excel_csv(.,                      paste(OutPath_Intermediate, \"00_prefilter_database.csv\",                            sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"initial-flags","dir":"Articles","previous_headings":"","what":"3.0 Initial flags","title":"BeeBDC vignette","text":"Read data back needed. OutPath_Intermediate (directories) created saved global environment dirMaker(). Normally, use full dataset, read . , sake vignette, use combination two example datasets. example datasets can useful testing functions ’re ever feeling bit confused overwhelmed! details bdc package, please see tutorial.","code":"if(!exists(\"db_standardized\")){   db_standardized <- readr::read_csv(paste(OutPath_Intermediate, \"00_prefilter_database.csv\",                                     sep = \"/\"), col_types = BeeBDC::ColTypeR())} data(\"bees3sp\", package = \"BeeBDC\") data(\"beesRaw\", package = \"BeeBDC\") db_standardized <- dplyr::bind_rows(beesRaw,                                        # Only keep a subset of columns from bees3sp                              bees3sp %>% dplyr::select(tidyselect::all_of(colnames(beesRaw)), countryCode))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"sciname","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.1 SciName","title":"BeeBDC vignette","text":"Flag occurrences without scientificName provided.","code":"check_pf <- bdc::bdc_scientificName_empty(data = db_standardized, sci_name = \"scientificName\") ##  ## bdc_scientificName_empty: ## Flagged 0 records. ## One column was added to the database. # now that this is saved, remove it to save space in memory rm(db_standardized)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"misscoords","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.2 MissCoords","title":"BeeBDC vignette","text":"Flag occurrences missing decimalLatitude decimalLongitude.","code":"check_pf <- bdc::bdc_coordinates_empty(data = check_pf, lat = \"decimalLatitude\",     lon = \"decimalLongitude\") ##  ## bdc_coordinates_empty: ## Flagged 42 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"outofrange","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.3 OutOfRange","title":"BeeBDC vignette","text":"Flag occurrences Earth (outside -180 180 -90 90 degrees).","code":"check_pf <- bdc::bdc_coordinates_outOfRange(data = check_pf, lat = \"decimalLatitude\",     lon = \"decimalLongitude\") ##  ## bdc_coordinates_outOfRange: ## Flagged 0 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"source","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.4 Source","title":"BeeBDC vignette","text":"Flag occurrences don’t match basisOfRecord types .","code":"check_pf <- bdc::bdc_basisOfRecords_notStandard(   data = check_pf,   basisOfRecord = \"basisOfRecord\",   names_to_keep = c(     # Keep all plus some at the bottom.     \"Event\",     \"HUMAN_OBSERVATION\",     \"HumanObservation\",     \"LIVING_SPECIMEN\",     \"LivingSpecimen\",     \"MACHINE_OBSERVATION\",     \"MachineObservation\",     \"MATERIAL_SAMPLE\",     \"O\",     \"Occurrence\",     \"MaterialSample\",     \"OBSERVATION\",     \"Preserved Specimen\",     \"PRESERVED_SPECIMEN\",     \"preservedspecimen Specimen\",     \"Preservedspecimen\",     \"PreservedSpecimen\",     \"preservedspecimen\",     \"S\",     \"Specimen\",     \"Taxon\",     \"UNKNOWN\",     \"\",     NA,     \"NA\",     \"LITERATURE\",      \"None\", \"Pinned Specimen\", \"Voucher reared\", \"Emerged specimen\"   )) ##  ## bdc_basisOfRecords_notStandard: ## Flagged 1 of the following specific nature: ##  MATERIAL_CITATION  ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"countryname","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.5 CountryName","title":"BeeBDC vignette","text":"Try harmonise country names.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--prepare-dataset","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"a. prepare dataset","title":"BeeBDC vignette","text":"Fix country names based common problems extract ISO2 codes occurrences.","code":"check_pf_noNa <- BeeBDC::countryNameCleanR(   data = check_pf,     # Create a Tibble of common issues in country names and their replacements   commonProblems = dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',                                               'United States','U.S.A','MX','CA','Bras.','Braz.',                                               'Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                                   fix = c('United States of America','United States of America',                                           'United States of America','United States of America',                                           'United States of America','United States of America',                                           'United States of America','Mexico','Canada','Brazil',                                           'Brazil','Brazil','Northern Mariana Islands','PUERTO.RICO'))   ) ##  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--run-function","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"b. run function","title":"BeeBDC vignette","text":"Get country name coordinates using wrapper around jbd_country_from_coordinates() function. dataset much larger used design bdc, made can analyse data smaller pieces. Additionally, like functions BeeBDC, implemented parallel operations (using mc.cores = #cores stepSize = #rowsPerOperation); see ‘?jbd_CfC_chunker()’ details. NOTE: actual run use scale = “large”","code":"suppressWarnings(   countryOutput <- BeeBDC::jbd_CfC_chunker(data = check_pf_noNa,                                    lat = \"decimalLatitude\",                                    lon = \"decimalLongitude\",                                    country = \"country\",                                     # How many rows to process at a time                                    stepSize = 1000000,                                     # Start row                                    chunkStart = 1,                                    path = OutPath_Intermediate,                                     # Normally, please use scale = \"large\"                                    scale = \"medium\",                                    mc.cores = 1),   classes = \"warning\") ##  - Starting parallel operation. Unlike the serial operation (mc.cores = 1) , a parallel operation will not provide running feedback. Please be patient  as this function may take some time to complete. Each chunk will be run on  a seperate thread so also be aware of RAM usage. ##  - We have updated the country names of 39 occurrences that previously had no country name assigned."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--re-merge","dir":"Articles","previous_headings":"3.0 Initial flags > 3.5 CountryName","what":"c. re-merge","title":"BeeBDC vignette","text":"Join datasets. Save dataset. Read needed. Remove interim datasets.","code":"check_pf <- dplyr::left_join(check_pf, countryOutput, by = \"database_id\", suffix = c(\"\",     \"CO\")) %>%     # Take the new country name if the original is NA dplyr::mutate(country = dplyr::if_else(is.na(country), countryCO, country)) %>%     # Remove duplicates if they arose from left_join! dplyr::distinct() check_pf %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"01_prefilter_database.csv\",         sep = \"/\")) if (!exists(\"check_pf\")) {     check_pf <- readr::read_csv(paste(DataPath, \"Output\", \"Intermediate\", \"01_prefilter_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) } rm(check_pf_noNa, countryOutput)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"standardconames","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.6 StandardCoNames","title":"BeeBDC vignette","text":"Run function, standardises country names adds ISO2 codes, needed.","code":"# Standardise country names and add ISO2 codes if needed check_pf <- bdc::bdc_country_standardized(   # Remove the countryCode and country_suggested columns to avoid an error with      # where two \"countryCode\" and \"country_suggested\" columns exist (i.e. if the dataset has been       # run before)   data = check_pf %>% dplyr::select(!tidyselect::any_of(c(\"countryCode\", \"country_suggested\"))),   country = \"country\" )  ## Loading auxiliary data: country names ## Standardizing country names ## country found: Argentina ## country found: Australia ## country found: Belgium ## country found: Brazil ## country found: Canada ## country found: Colombia ## country found: Costa Rica ## country found: Ecuador ## country found: Estonia ## country found: Finland ## country found: France ## country found: Germany ## country found: Ireland ## country found: Mexico ## country found: Norway ## country found: South Africa ## country found: Sweden ## country found: Switzerland ## country found: United Kingdom ## country found: United States of America ##  ## bdc_country_standardized: ## The country names of 141 records were standardized. ## Two columns ('country_suggested' and 'countryCode') were added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"transpcoords","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.7 TranspCoords","title":"BeeBDC vignette","text":"Flag correct records decimalLatitude decimalLongitude appear transposed. created chunked version bdc::bdc_coordinates_transposed() RAM-heavy using large bee dataset. Like many ‘jbd_…’ functions improvements - e.g., parallel running. NOTE: Usually use scale = “large”, requires rnaturalearthhires Get quick summary number transposed records. Save dataset. Read data needed.","code":"check_pf <- BeeBDC::jbd_Ctrans_chunker(   # bdc_coordinates_transposed inputs   data = check_pf,   id = \"database_id\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   countryCode = \"countryCode\",   border_buffer = 0.2, # in decimal degrees (~22 km at the equator)   save_outputs = TRUE,   sci_names = \"scientificName\",   # chunker inputs   stepSize = 1000000,  # How many rows to process at a time   chunkStart = 1,  # Start row   append = FALSE,  # If FALSE it may overwrite existing dataset   progressiveSave = FALSE,     # In a normal run, please use scale = \"large\"   scale = \"medium\",   path = OutPath_Check,   mc.cores = 1 )  ##  - Running chunker with: ## stepSize = 1,000,000 ## chunkStart = 1 ## chunkEnd = 1,000,000 ## append = FALSE ##  - Starting chunk 1... ## From 1 to 1,000,000 ##  - Finished chunk 1 of 1. Total records examined: 205 table(check_pf$coordinates_transposed, useNA = \"always\") check_pf %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"01_prefilter_database.csv\",         sep = \"/\")) if (!exists(\"check_pf\")) {     check_pf <- readr::read_csv(paste(OutPath_Intermediate, \"01_prefilter_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) }"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"coord-country","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.8 Coord-country","title":"BeeBDC vignette","text":"Collect country names country_suggested column. rebuilt bdc function flag occurrences coordinates inconsistent provided country name. Save dataset.","code":"check_pf <- BeeBDC::jbd_coordCountryInconsistent(data = check_pf, lon = \"decimalLongitude\",     lat = \"decimalLatitude\", scale = 50, pointBuffer = 0.01) ##  - Downloading naturalearth map... ## Spherical geometry (s2) switched off ##  - Extracting initial country names without buffer... ##  - Buffering naturalearth map by pointBuffer... ## dist is assumed to be in decimal degrees (arc_degrees). ##  - Extracting FAILED country names WITH buffer... ##  ## jbd_coordinates_country_inconsistent: ## Flagged 2 records. ## The column, '.coordinates_country_inconsistent', was added to the database. ##  - Completed in 0.79 secs check_pf %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"01_prefilter_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"georefissue","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.9 GeoRefIssue","title":"BeeBDC vignette","text":"function identifies records whose coordinates can potentially extracted locality information, must manually checked later. Remove spent data.","code":"xyFromLocality <- bdc::bdc_coordinates_from_locality(data = check_pf, locality = \"locality\",     lon = \"decimalLongitude\", lat = \"decimalLatitude\", save_outputs = FALSE) ##  ## bdc_coordinates_from_locality  ## Found 38 records missing or with invalid coordinates but with potentially useful information on locality. # Save the resultant data xyFromLocality %>%     readr::write_excel_csv(paste(OutPath_Check, \"01_coordinates_from_locality.csv\",         sep = \"/\")) rm(xyFromLocality)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-absent","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.10 Flag Absent","title":"BeeBDC vignette","text":"Flag records marked “absent”.","code":"check_pf <- BeeBDC::flagAbsent(data = check_pf, PresAbs = \"occurrenceStatus\") ## \\.occurrenceAbsent: ##  Flagged 8 absent records: ##  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-license","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.11 flag License","title":"BeeBDC vignette","text":"Flag records may used according license information.","code":"check_pf <- BeeBDC::flagLicense(data = check_pf,                     strings_to_restrict = \"all\",                     # DON'T flag if in the following dataSource(s)                     excludeDataSource = NULL) ## \\.unLicensed: ##  Flagged 0 records that may NOT be used. ##  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"gbif-issue","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.12 GBIF issue","title":"BeeBDC vignette","text":"Flag select issues flagged GBIF.","code":"check_pf <- BeeBDC::GBIFissues(data = check_pf, issueColumn = \"issue\", GBIFflags = c(\"COORDINATE_INVALID\",     \"ZERO_COORDINATE\")) ##  - jbd_GBIFissues: ## Flagged 0  ##   The .GBIFflags column was added to the database."},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--save-flags","dir":"Articles","previous_headings":"3.0 Initial flags > 3.13 Flag Reports","what":"a. Save flags","title":"BeeBDC vignette","text":"Save flags far. function make sure keep copy everything flagged now. updated throughout script can accessed end, wary moving files around manually. However, data also still maintained main running file, optional fail-safe. Update .summary column","code":"flagFile <- BeeBDC::flagRecorder(   data = check_pf,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(),  \".csv\"),     # These are the columns that will be kept along with the flags   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),     # TRUE if you want to find a file from a previous part of the script to append to   append = FALSE) check_pf <- BeeBDC::summaryFun(   data = check_pf,     # Don't filter these columns (or NULL)   dontFilterThese = NULL,     # Remove the filtering columns?   removeFilterColumns = FALSE,     # Filter to ONLY cleaned data?   filterClean = FALSE) ##  - We will flag all columns starting with '.' ##  - summaryFun: ## Flagged 52  ##   The .summary column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"c--reporting","dir":"Articles","previous_headings":"3.0 Initial flags > 3.13 Flag Reports","what":"c. Reporting","title":"BeeBDC vignette","text":"Use bdc generate reports.","code":"(report <- bdc::bdc_create_report(data = check_pf, database_id = \"database_id\", workflow_step = \"prefilter\",     save_report = TRUE))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save","dir":"Articles","previous_headings":"3.0 Initial flags","what":"3.14 Save","title":"BeeBDC vignette","text":"Save intermediate dataset.","code":"check_pf %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"01_prefilter_output.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"taxonomy","dir":"Articles","previous_headings":"","what":"4.0 Taxonomy","title":"BeeBDC vignette","text":"information corresponding bdc functions used section, see tutorial. Read filtered dataset rename 3.x dataset 4.0. Remove names_clean already exists (.e. run following functions dataset ).","code":"if (!exists(\"check_pf\")) {     database <- readr::read_csv(paste(OutPath_Intermediate, \"01_prefilter_output.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) } else {     # OR rename and remove     database <- check_pf     # Remove spent dataset     rm(check_pf) } database <- database %>%     dplyr::select(!tidyselect::any_of(\"names_clean\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"prep-data-names","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.1 Prep data names","title":"BeeBDC vignette","text":"step cleans database’s scientificName column. ! MAC: might need install gnparser terminal — brew brew tap gnames/gn brew install gnparser Attention:  can difficult Windows install. Ensure recent version R, R Studio, R packages. Also, check package ‘rgnparser’ installed correctly. still can get code work, may download latest version ‘gnparser’ . may need manually install edit systems environmental variable PATH locate ‘gnparser.exe’. See . Keep .uncer_terms names_clean columns. Merge names complete dataset.","code":"parse_names <- bdc::bdc_clean_names(sci_names = database$scientificName, save_outputs = FALSE) ## The latest gnparser version is v1.7.4 ## gnparser has been installed to /home/runner/bin ##  ## >> Family names prepended to scientific names were flagged and removed from 0 records. ## >> Terms denoting taxonomic uncertainty were flagged and removed from 0 records. ## >> Other issues, capitalizing the first letter of the generic name, replacing empty names by NA, and     removing extra spaces, were flagged and corrected or removed from 1 records. ## >> Infraspecific terms were flagged and removed from 0 records. parse_names <- parse_names %>%     dplyr::select(.uncer_terms, names_clean) database <- dplyr::bind_cols(database) rm(parse_names)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"harmonise-taxonomy","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.2 Harmonise taxonomy","title":"BeeBDC vignette","text":"Download custom taxonomy file BeeBDC package Discover Life website. Attention:  version 1.1.0, BeeBDC now new function can download taxonomies using taxadb package transform BeeBDC format. function, BeeBDC::taxadbToBeeBDC(), allows user choose desired provider (e.g., “gbif”, “itis”…), version, taxon name rank, save taxonomy readable csv . example bee genus Apis: Harmonise names occurrence tibble. flags occurrences without matched name matches names correct name according Discover Life. can also use multiple cores achieve . See ‘?harmoniseR()’ details. don’t need file … Save harmonised file.","code":"taxonomyFile <- BeeBDC::beesTaxonomy() # load in the small test dataset i nthe background system.file(\"extdata\", \"testTaxonomy.rda\", package = \"BeeBDC\") |>     load() # Rename the file taxonomyFile <- testTaxonomy rm(testTaxonomy) ApisTaxonomy <- BeeBDC::taxadbToBeeBDC(   name = \"Apis\",   rank = \"Genus\",   provider = \"gbif\",   version = \"22.12\",   outPath = getwd(),   fileName = \"ApisTaxonomy.csv\"   ) database <- BeeBDC::harmoniseR(path = DataPath, #The path to a folder that the output can be saved                        taxonomy = taxonomyFile, # The formatted taxonomy file                        data = database,                        mc.cores = 1) ##  - Formatting taxonomy for matching... ## The names_clean column was not found and will be temporarily copied from scientificName ##  ##  - Harmonise the occurrence data with unambiguous names... ##  ##  - Attempting to harmonise the occurrence data with ambiguous names... ##  - Formatting merged datasets... ## Removing the names_clean column... ##  - We matched valid names to 201 of 205 occurrence records. This leaves a total of 4 unmatched occurrence records. ##  ## harmoniseR: ## 4 ## records were flagged. ## The column, '.invalidName' was added to the database. ##  - We updated the following columns: scientificName, species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, and scientificNameAuthorship. The previous scientificName column was converted to verbatimScientificName ##  - Completed in 0.54 secs rm(taxonomyFile) database %>%     readr::write_excel_csv(., paste(DataPath, \"Output\", \"Intermediate\", \"02_taxonomy_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags","dir":"Articles","previous_headings":"4.0 Taxonomy","what":"4.3 Save flags","title":"BeeBDC vignette","text":"Save flags far. find -recent flag file append new data . can double-check data number columns ’d like thorough sure data intact.","code":"flagFile <- BeeBDC::flagRecorder(data = database, outPath = paste(OutPath_Report,     sep = \"\"), fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"), idColumns = c(\"database_id\",     \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"), append = TRUE, printSummary = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space","dir":"Articles","previous_headings":"","what":"5.0 Space","title":"BeeBDC vignette","text":"final frontier whatever. Read latest database.","code":"if (!exists(\"database\")) {     database <- readr::read_csv(paste(OutPath_Intermediate, \"02_taxonomy_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) }"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"coordinate-precision","dir":"Articles","previous_headings":"5.0 Space","what":"5.1 Coordinate precision","title":"BeeBDC vignette","text":"function identifies records coordinate precision specified number decimal places. example, precision coordinate 1 decimal place 11.132 km equator, .e., scale large city. major difference bdc BeeBDC functions jbd_coordinates_precision() flag occurrences latitude longitude rounded (opposed one ). Coordinates one, two, three decimal places present precision ~11.1 km, ~1.1 km, ~111 m equator, respectively. Remove spent dataset. Save resulting file.","code":"check_space <- BeeBDC::jbd_coordinates_precision(data = database, lon = \"decimalLongitude\",     lat = \"decimalLatitude\", ndec = 2  # number of decimals to be tested ) ## jbd_coordinates_precision: ## Flagged 61 records ## The '.rou' column was added to the database. rm(database) check_space %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"03_space_inter_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"common-spatial-issues","dir":"Articles","previous_headings":"5.0 Space","what":"5.2 Common spatial issues","title":"BeeBDC vignette","text":"run occurrences clean_coordinates() spatially ‘valid’. Next, flag common spatial issues using functions package CoordinateCleaner. addresses common issues biodiversity datasets. Re-merge datasets. Remove temporary dataset. Save intermediate dataset.","code":"tempSpace <- check_space %>%     dplyr::filter(!.coordinates_empty == FALSE) %>%     dplyr::filter(!.coordinates_outOfRange == FALSE) tempSpace <-   CoordinateCleaner::clean_coordinates(     x =  tempSpace,     lon = \"decimalLongitude\",     lat = \"decimalLatitude\",     species = \"scientificName\",     countries = NULL, # Tests if coords are from x country. This is not needed.     tests = c(       \"capitals\",     # records within 0.5 km of capitals centroids       \"centroids\",    # records within 1 km around country and province centroids       \"equal\",      # records with equal coordinates       \"gbif\",         # records within 1 km of GBIF headquarters. (says 1 degree in package, but code says 1000 m)       \"institutions\", # records within 100m of zoo and herbaria       \"zeros\"       # records with coordinates 0,0       # \"seas\"        # Not flagged as this should be flagged by coordinate country inconsistent     ),     capitals_rad = 1000,     centroids_rad = 500,     centroids_detail = \"both\", # test both country and province centroids     inst_rad = 100, # remove zoo and herbaria within 100m     range_rad = 0,     zeros_rad = 0.5,     capitals_ref = NULL,     centroids_ref = NULL,     country_ref = NULL,     country_refcol = \"countryCode\",     inst_ref = NULL,     range_ref = NULL,     # seas_scale = 50,     value = \"spatialvalid\" # result of tests are appended in separate columns   ) %>%       # Remove duplicate .summary column that can be replaced later and turn into a tibble   dplyr::select(!tidyselect::starts_with(\".summary\")) %>%   dplyr::tibble() check_space <- tempSpace %>%     # Re-bind with the records that were removed earlier dplyr::bind_rows(check_space %>%     dplyr::filter(.coordinates_empty == FALSE | .coordinates_outOfRange == FALSE)) rm(tempSpace) check_space %>%     readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_inter_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"diagonal-grid","dir":"Articles","previous_headings":"5.0 Space","what":"5.3 Diagonal + grid","title":"BeeBDC vignette","text":"Finds sequential numbers fill-errors lat long, groups ‘groupingColumns’. accomplished using sliding window length determined minRepeats. coordinates precision ‘ndec’ (number decimals decimal degree format) examined. Note, function RAM-intensive use multiple threads approached caution depending dataset. However, option provided. Spatial gridding rasterisation: Select records X occurrences. Run gridding analysis find datasets might gridded. Integrate results main dataset. Save gridded_datasets file later examination. Now remove file.","code":"check_space <- BeeBDC::diagonAlley(   data = check_space,   # The minimum number of repeats needed to find a sequence in for flagging   minRepeats = 6,   ndec = 3,   groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),   mc.cores = 1) ## Removing rounded coordinates with BeeBDC::jbd_coordinates_precision... ## jbd_coordinates_precision: ## Removed 68 records. ##  - Merging results and adding the .sequential column... ##  ## diagonAlley: ## Flagged 0 records ## The .sequential column was added to the database. ##  - Completed in 0.03 secs griddingDF <- check_space %>%     # Exclude NA lat and lon values tidyr::drop_na(c(\"decimalLatitude\", \"decimalLongitude\")) %>%     # Group by the dataset name dplyr::group_by(datasetName) %>%     # Remove rows that aren't unique for lat and long dplyr::distinct(decimalLongitude, decimalLatitude, .keep_all = TRUE) %>%     # Find the groups with 4 or more occurrence records dplyr::filter(dplyr::n() >= 4) %>%     dplyr::ungroup() gridded_datasets <- CoordinateCleaner::cd_round(x = griddingDF, lon = \"decimalLongitude\",     lat = \"decimalLatitude\", ds = \"datasetName\", T1 = 7, min_unique_ds_size = 4,     test = \"both\", value = \"dataset\", graphs = FALSE, verbose = TRUE, reg_out_thresh = 2,     reg_dist_min = 0.1, reg_dist_max = 2) %>%     dplyr::tibble() # The griddingDF is no longer needed. remove it. rm(griddingDF) check_space <- check_space %>%   # Join the datasets   dplyr::left_join(     # Select the columns of interest     dplyr::select(gridded_datasets, dataset, lon.flag, lat.flag, summary),     by = c(\"datasetName\" = \"dataset\")) %>%   # Make new columns with more-consistent naming and change the NA vlaues to = TRUE (not flagged)   dplyr::mutate(.lonFlag = tidyr::replace_na(lon.flag, TRUE),                 .latFlag = tidyr::replace_na(lat.flag, TRUE),                 .gridSummary = tidyr::replace_na(summary, TRUE)) %>%   # Remove old columns   dplyr::select(!c(lon.flag, lat.flag, summary)) gridded_datasets %>%     readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_griddedDatasets.csv\",         sep = \"/\")) rm(gridded_datasets)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"uncertainty","dir":"Articles","previous_headings":"5.0 Space","what":"5.4 Uncertainty","title":"BeeBDC vignette","text":"Flag records exceed coordinateUncertaintyInMeters threshold.","code":"check_space <- BeeBDC::coordUncerFlagR(data = check_space, uncerColumn = \"coordinateUncertaintyInMeters\",     threshold = 1000) ## \\coordUncerFlagR: ##  Flagged 33 geographically uncertain records: ##  The column '.uncertaintyThreshold' was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"country-checklist","dir":"Articles","previous_headings":"5.0 Space","what":"5.5 Country checklist","title":"BeeBDC vignette","text":"step identifies mismatches Discover Life country checklist — beesChecklist — bee species dataset, identifying potential misidentifications, outliers, etc.’ Download country-level checklist.","code":"checklistFile <- BeeBDC::beesChecklist() # load in the small test dataset i nthe background system.file(\"extdata\", \"testChecklist.rda\", package = \"BeeBDC\") |>     load() # Rename the file taxonomyFile <- testChecklist rm(testChecklist) check_space <- BeeBDC::countryOutlieRs(checklist = checklistFile,                         data = check_space,                         keepAdjacentCountry = TRUE,                         pointBuffer = 0.05,                           # Scale of map to return, one of 110, 50, 10 OR 'small', 'medium', 'large'                           # Smaller numbers will result in much longer calculation times.                            # We have not attempted a scale of 10.                         scale = 50,                         mc.cores = 1) ## Error: object 'checklistFile' not found # A list of failed species-country combinations and their numbers can be output # here check_space %>%     dplyr::filter(.countryOutlier == FALSE) %>%     dplyr::select(database_id, scientificName, country) %>%     dplyr::group_by(scientificName) %>%     dplyr::mutate(count_scientificName = n()) %>%     dplyr::distinct(scientificName, country, .keep_all = TRUE) %>%     readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_failedCountryChecklist.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"map-spatial-errors","dir":"Articles","previous_headings":"5.0 Space","what":"5.6 Map spatial errors","title":"BeeBDC vignette","text":"Assemble maps potential spatial errors outliers, either one flag time using .summary column. First, need rebuild .summary column. Rebuild .summary column. Use col_to_map order map ONE spatial flag time map .summary column flags.","code":"check_space <- BeeBDC::summaryFun(data = check_space, dontFilterThese = NULL, removeFilterColumns = FALSE,     filterClean = FALSE) check_space %>%   dplyr::filter(.summary == FALSE) %>% # map only records flagged as FALSE   bdc::bdc_quickmap(     data = .,     lon = \"decimalLongitude\",     lat = \"decimalLatitude\",     col_to_map = \".summary\",     size = 0.9   )"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space-report","dir":"Articles","previous_headings":"5.0 Space","what":"5.7 Space report","title":"BeeBDC vignette","text":"Create space report using bdc.","code":"(report <- bdc::bdc_create_report(data = dplyr::tibble(check_space %>%     dplyr::select(!.uncer_terms)), database_id = \"database_id\", workflow_step = \"space\",     save_report = TRUE))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"space-figures","dir":"Articles","previous_headings":"5.0 Space","what":"5.8 Space figures","title":"BeeBDC vignette","text":"Create figures spatial data filtering results. examining figures, options : .cap = Records around country capital centroid .cen = Records around country province centroids .dbl = Duplicated coordinates per species .equ = Identical coordinates .otl = Geographical outliers .gbf = Records around GBIF headquarters .inst = Records around biodiversity institutions .rou = Rounded (probably imprecise) coordinates .urb = Records within urban areas — (Likely relevant bees.) Save interim dataset.","code":"(figures <- BeeBDC::jbd_create_figures(data = dplyr::tibble(check_space %>%     dplyr::select(!.uncer_terms)), path = DataPath, database_id = \"database_id\",     workflow_step = \"space\", save_figures = TRUE)) You can examine these figures, for example, by running:        figures$.rou check_space %>%     readr::write_excel_csv(paste(OutPath_Intermediate, \"03_space_inter_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-1","dir":"Articles","previous_headings":"5.0 Space","what":"5.9 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(data = check_space, outPath = paste(OutPath_Report, sep = \"\"),     fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"), idColumns = c(\"database_id\",         \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"), append = TRUE, printSummary = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-1","dir":"Articles","previous_headings":"5.0 Space","what":"5.10 Save","title":"BeeBDC vignette","text":"Save intermediate dataset.","code":"check_space %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"03_space_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time","dir":"Articles","previous_headings":"","what":"6.0 Time","title":"BeeBDC vignette","text":"Read last database, needed. can plot histogram dates .  Filter silly dates don’t make sense.","code":"if (!exists(\"check_space\")) {     check_time <- readr::read_csv(paste(OutPath_Intermediate, \"03_space_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) } else {     check_time <- check_space     # Remove the spent file     rm(check_space) } hist(lubridate::ymd_hms(check_time$eventDate, truncated = 5), breaks = 20, main = \"Histogram of eventDates\") check_time$year <- ifelse(check_time$year > lubridate::year(Sys.Date()) | check_time$year <     1600, NA, check_time$year) check_time$month <- ifelse(check_time$month > 12 | check_time$month < 1, NA, check_time$month) check_time$day <- ifelse(check_time$day > 31 | check_time$day < 1, NA, check_time$day)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"recover-dates","dir":"Articles","previous_headings":"6.0 Time","what":"6.1 Recover dates","title":"BeeBDC vignette","text":"dateFindR() function search columns order find rescue dates may made correct columns. update eventDate, day, month, year columns data ) missing b) located one searched columns.","code":"check_time <- BeeBDC::dateFindR(data = check_time,                         # Years above this are removed (from the recovered dates only)                         maxYear = lubridate::year(Sys.Date()),                         # Years below this are removed (from the recovered dates only)                         minYear = 1700) ##  - Preparing data... ##  - Extracting dates from year, month, day columns... ##  - Extracting dates from fieldNotes, locationRemarks, and verbatimEventDate columns in unambiguous ymd, dmy, mdy, and my formats... ##  - Extracting year from fieldNotes, locationRemarks, and verbatimEventDate columns in ambiguous formats... ##  - Formating and combining the new data.. ##  - Merging all data, nearly there... ##  - Finished.  ## We now have 1 more full eventDate cells than in the input data. ## We modified dates in  ## 174 occurrences. ##  - As it stands, there are 174 complete eventDates and 31 missing dates. ##  - There are also 175 complete year occurrences to filter from. This is up from an initial count of 174 At this rate, you will stand to lose 30 occurrences on the basis of missing year - Operation time: 0.57842755317688 secs"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"no-eventdate","dir":"Articles","previous_headings":"6.0 Time","what":"6.2 No eventDate","title":"BeeBDC vignette","text":"Flag records simply lack collection date. :(","code":"check_time <- bdc::bdc_eventDate_empty(data = check_time, eventDate = \"eventDate\") ##  ## bdc_eventDate_empty: ## Flagged 31 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"old-records","dir":"Articles","previous_headings":"6.0 Time","what":"6.3 Old records","title":"BeeBDC vignette","text":"flag records prior date selected. 1970 frequently chosen SDM work. may need filter old records , think critically use. chosen 1950 lower extreme.","code":"check_time <- bdc::bdc_year_outOfRange(data = check_time, eventDate = \"year\", year_threshold = 1950) ##  ## bdc_year_outOfRange: ## Flagged 21 records. ## One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time-report","dir":"Articles","previous_headings":"6.0 Time","what":"6.4 Time report","title":"BeeBDC vignette","text":"time, just time pertaining precise occurrence records. Update .summary column.","code":"check_time <- BeeBDC::summaryFun(   data = check_time,   # Don't filter these columns (or NULL)   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\"),   # Remove the filtering columns?   removeFilterColumns = FALSE,   # Filter to ONLY cleaned data?   filterClean = FALSE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms ##  - summaryFun: ## Flagged 115  ##   The .summary column was added to the database. (report <- bdc::bdc_create_report(data = check_time, database_id = \"database_id\",     workflow_step = \"time\", save_report = FALSE))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"time-figures","dir":"Articles","previous_headings":"6.0 Time","what":"6.5 Time figures","title":"BeeBDC vignette","text":"Create time results figures. can check figures using… Save time-revised data intermediate folder.","code":"figures <- BeeBDC::jbd_create_figures(data = check_time, path = DataPath, database_id = \"database_id\",     workflow_step = \"time\", save_figures = TRUE) figures$year check_time %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"04_time_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-2","dir":"Articles","previous_headings":"6.0 Time","what":"6.6 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(data = check_time, outPath = paste(OutPath_Report, sep = \"\"),     fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"), idColumns = c(\"database_id\",         \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"), append = TRUE, printSummary = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"de-duplication","dir":"Articles","previous_headings":"","what":"7.0 De-duplication","title":"BeeBDC vignette","text":"dataset can re-read already exist.","code":"if (!exists(\"check_time\")) {     check_time <- readr::read_csv(paste(OutPath_Intermediate, \"04_time_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) }"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"deduplicate","dir":"Articles","previous_headings":"7.0 De-duplication","what":"7.1 deDuplicate","title":"BeeBDC vignette","text":"FLAG duplicates . input columns can hacked de-duplicate wish. function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns. encourage see ‘?dupeSummary()’ details function quite modifiable user needs. Save dataset intermediate folder.","code":"check_time <- BeeBDC::dupeSummary(   data = check_time,   path = OutPath_Report,    # options are \"ID\",\"collectionInfo\", or \"both\"   duplicatedBy = \"collectionInfo\",      # The columns to generate completeness info from (and to sort by completness)   completeness_cols = c(\"decimalLatitude\",  \"decimalLongitude\",                         \"scientificName\", \"eventDate\"),    # The columns to ADDITIONALLY consider when finding duplicates in collectionInfo   collectionCols = c(\"decimalLatitude\", \"decimalLongitude\", \"scientificName\", \"eventDate\",                       \"recordedBy\"),     # The columns to combine, one-by-one with the collectionCols   collectInfoColumns = c(\"catalogNumber\", \"otherCatalogNumbers\"),     # Custom comparisons — as a list of columns to compare      # RAW custom comparisons do not use the character and number thresholds   CustomComparisonsRAW = dplyr::lst(c(\"catalogNumber\", \"institutionCode\", \"scientificName\")),      # Other custom comparisons use the character and number thresholds   CustomComparisons = dplyr::lst(c(\"gbifID\", \"scientificName\"),                                   c(\"occurrenceID\", \"scientificName\"),                                   c(\"recordId\", \"scientificName\"),                                   c(\"id\", \"scientificName\")),    # The order in which you want to KEEP duplicated based on data source    # try unique(check_time$dataSource)   sourceOrder = c(\"CAES\", \"Gai\", \"Ecd\",\"BMont\", \"BMin\", \"EPEL\", \"ASP\", \"KP\", \"EcoS\", \"EaCO\",                   \"FSCA\", \"Bal\", \"SMC\", \"Lic\", \"Arm\",                   \"USGS\", \"ALA\", \"VicWam\", \"GBIF\",\"SCAN\",\"iDigBio\"),     # Paige ordering is done using the database_id prefix, not the dataSource prefix.   prefixOrder = c(\"Paige\", \"Dorey\"),     # Set the complexity threshold for id letter and number length      # minimum number of characters when WITH the numberThreshold   characterThreshold = 2,      # minimum number of numbers when WITH the characterThreshold   numberThreshold = 3,      # Minimum number of numbers WITHOUT any characters   numberOnlyThreshold = 5 ) %>% # END dupeSummary   dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) ##  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. ## This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. ##  - Updating the .summary column to sort by... ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold, .unLicensed ##  - summaryFun: ## Flagged 91  ##   The .summary column was added to the database. ##  - Working on CustomComparisonsRAW duplicates... ##  ## Completed iteration 1 of 1: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## catalogNumber, institutionCode, scientificName ##  - Working on CustomComparisons duplicates... ##  ## Completed iteration 1 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## gbifID, scientificName ##  ## Completed iteration 2 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## occurrenceID, scientificName ##  ## Completed iteration 3 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## recordId, scientificName ##  ## Completed iteration 4 of 4: ##  - Identified 0 duplicate records and kept 0 unique records using the column(s):  ## id, scientificName ##  - Working on collectionInfo duplicates... ##  ## Completed iteration 1 of 2: ##  - Identified 0 duplicate records and kept 0 unique records using the columns:  ## decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and catalogNumber ##  ## Completed iteration 2 of 2: ##  - Identified 0 duplicate records and kept 0 unique records using the columns:  ## decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and otherCatalogNumbers ##  - Clustering duplicate pairs... ## Duplicate pairs clustered. There are 0 duplicates across 0 kept duplicates. ##  - Ordering prefixs... ##  - Ordering data by 1. dataSource, 2. completeness and 3. .summary column... ##  - Find and FIRST duplicate to keep and assign other associated duplicates to that one (i.e., across multiple tests a 'kept duplicate', could otherwise be removed)... ##  - Duplicates have been saved in the file and location: /tmp/RtmpxEUPYm/Data_acquisition_workflow/Output/ReportduplicateRun_collectionInfo_2025-06-19.csv ##  - Across the entire dataset, there are now 0 duplicates from a total of 205 occurrences. ##  - Completed in 0.28 secs check_time %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"04_2_dup_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-flags-3","dir":"Articles","previous_headings":"7.0 De-duplication","what":"7.2 Save flags","title":"BeeBDC vignette","text":"Save flags far.","code":"BeeBDC::flagRecorder(data = check_time, outPath = paste(OutPath_Report, sep = \"\"),     fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"), idColumns = c(\"database_id\",         \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"), append = TRUE, printSummary = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-filtering","dir":"Articles","previous_headings":"","what":"8.0 Data filtering","title":"BeeBDC vignette","text":"dataset can re-read already exist.","code":"if (!exists(\"check_time\")) {     check_time <- readr::read_csv(paste(OutPath_Intermediate, \"04_2_dup_database.csv\",         sep = \"/\"), col_types = ColTypeR()) }"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"rm-outliers","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.1 rm Outliers","title":"BeeBDC vignette","text":"Read -recent duplicates file (generated dupeSummary()) order identify duplicates expert outliers. Identify outliers get list database_ids. require source outlier files provided BeeBDC paper. files can modified include outliers.","code":"if (!exists(\"duplicates\")) {     duplicates <- BeeBDC::fileFinder(path = DataPath, fileName = \"duplicateRun_\") %>%         readr::read_csv() } ##  - Dates found in file name(s). Finding most-recent file from file name... ##  - Found the following file(s):  ##  /tmp/RtmpxEUPYm/Data_acquisition_workflow/Output/Report/duplicateRun_collectionInfo_2025-06-19.csv ## Rows: 0 Columns: 19 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \",\" ## chr (19): group, database_id, database_id_keep, dupColumn_s, decimalLatitude... ##  ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. check_time <- BeeBDC::manualOutlierFindeR(   data = check_time,   DataPath = DataPath,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"^All_outliers_ANB_14March.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   # A .csv with manual outlier records that are too close to otherwise TRUE records   NearTRUE = \"nearTRUE.csv\",   duplicates = duplicates)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"save-uncleaned","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.2 Save uncleaned","title":"BeeBDC vignette","text":"Save uncleaned dataset.","code":"# Make sure that the .summary column is updated check_time <- BeeBDC::summaryFun(data = check_time, dontFilterThese = c(\".gridSummary\",     \".lonFlag\", \".latFlag\", \".uncer_terms\", \".uncertaintyThreshold\"), removeFilterColumns = FALSE,     filterClean = FALSE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 91  ##   The .summary column was added to the database. # Save the uncleaned dataset check_time %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"05_unCleaned_database.csv\",         sep = \"/\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"filter","dir":"Articles","previous_headings":"8.0 Data filtering","what":"8.3 Filter","title":"BeeBDC vignette","text":"Now clean dataset extra columns failed rows save .","code":"cleanData <- BeeBDC::summaryFun(   data = check_time,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",                       \".uncertaintyThreshold\"),   # Remove the filtering columns?   removeFilterColumns = TRUE,   # Filter to ONLY cleaned data?   filterClean = TRUE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 91  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column. # Save this CLEANED dataset cleanData %>%     readr::write_excel_csv(., paste(OutPath_Intermediate, \"05_cleaned_database.csv\",         sep = \"/\"))"},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"duplicate-chorddiagrams","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.1 Duplicate chordDiagrams","title":"BeeBDC vignette","text":"Install BiocManager ComplexHeatmap missed start. Read recent file flagged duplicates, ’s already environment. Choose global figure parameters. Create chordDiagram. can leave many values , show defaults. [internally] duplicates current test dataset, BeeBDC throw informative error. However, show full output figure bee dataset . ![Full chord diagram Dorey et al. 2023]","code":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\", repos = \"http://cran.us.r-project.org\") BiocManager::install(\"ComplexHeatmap\") if (!exists(\"duplicates\")) {     duplicates <- BeeBDC::fileFinder(path = DataPath, fileName = \"duplicateRun_\") %>%         readr::read_csv() } par(mar = c(2, 2, 2, 2)/2, mfrow = c(1, 1)) BeeBDC::chordDiagramR(   # The duplicate data from the dupeSummary function output     dupeData = duplicates,   outPath = OutPath_Figures,   fileName = \"ChordDiagram.pdf\",   # These can be modified to help fit the final pdf that's exported.   width = 9,   height = 7.5,   bg = \"white\",   # How few distinct dataSources should a group have to be listed as \"other\"   smallGrpThreshold = 3,   title = \"Duplicated record sources\",   # The default list of colour palettes to choose from usign the paleteer package   palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",                 \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",                \"cartography::purple.pal\", \"cartography::brown.pal\"),   canvas.ylim = c(-1.0,1.0),    canvas.xlim = c(-0.6, 0.25),   text.col = \"black\",   legendX = grid::unit(6, \"mm\"),   legendY = grid::unit(18, \"mm\"),   legendJustify = c(\"left\", \"bottom\"),   niceFacing = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"duplicate-histogram","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.2 Duplicate histogram","title":"BeeBDC vignette","text":"Read uncleaned dataset, ’s already present. Create plot two bar graphs. One shows absolute number duplicate records data source, shows proportion records duplicated within data source. (‘dataSource’ simplified text first underscore).","code":"if (!exists(\"check_time\")) {     beeData <- readr::read_csv(paste(OutPath_Intermediate, \"05_unCleaned_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) } else {     beeData <- check_time     rm(check_time) } BeeBDC::dupePlotR(   data = beeData,   # The outPath to save the plot as   outPath = OutPath_Figures,   fileName = \"duplicatePlot.pdf\",   # Colours in order: duplicate, kept duplicate, unique   dupeColours = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"),   # Plot size and height   base_height = 7, base_width = 7,   legend.position = c(0.85, 0.8),   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", Ecd = \"Ecd\",   returnPlot = TRUE )"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flags-by-source","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.3 Flags by source","title":"BeeBDC vignette","text":"Create compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE. (dataSource simplified text first underscore.)","code":"BeeBDC::plotFlagSummary(   data = beeData,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"FlagsPlot_\", Sys.Date(),\".pdf\"),   outPath = paste0(OutPath_Figures),   width = 15, height = 9,     # OPTIONAL:       #   # Filter to a single species       #       speciesName = \"Holcopasites heliopsis\",       #         # column to look in       #       nameColumn = \"species\",       #        # Save the filtered data       #       saveFiltered = TRUE,       #   # Filter column to display on map       #       filterColumn = \".summary\",       #       plotMap = TRUE,       #   # amount to jitter points if desired, e.g. 0.25 or NULL       #       jitterValue = NULL,       #        # Map opacity value for points between 0 and 1       #   mapAlpha = 1,       #        # If a user wants to output the table used to make the figure, change this to TRUE       #   saveTable = FALSE,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'BMont' = \"BMont\", 'BMin' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\", VicWam = \"VicWam\",   returnPlot = TRUE ) ##  - Preparing data to plot... ##  - Building plot..."},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"maps","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.4 Maps","title":"BeeBDC vignette","text":"Import CLEANED dataset (can change option).","code":"if (!exists(\"cleanData\")) {     cleanData <- readr::read_csv(paste(OutPath_Intermediate, \"05_cleaned_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR()) }"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"a--summary-maps","dir":"Articles","previous_headings":"9.0 Figures and tables > 9.4 Maps","what":"a. Summary maps","title":"BeeBDC vignette","text":"Draw global summary map occurrence species number country.","code":"BeeBDC::summaryMaps(data = cleanData, width = 10, height = 10, class_n = 3, class_Style = \"fisher\",     fileName = \"CountryMaps_fisher.pdf\", outPath = OutPath_Figures, returnPlot = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"b--interactive-maps","dir":"Articles","previous_headings":"9.0 Figures and tables > 9.4 Maps","what":"b. Interactive maps","title":"BeeBDC vignette","text":"Uses occurrence data (preferably uncleaned order show pass/fail points) outputs interactive .html maps, can opened browser, specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can updated first running summaryFun() choose columns want highlighted. function also highlight occurrences flagged expert-identified country outliers separately. function can categorical variable fed ‘speciesColumn’, users may choose another column interest map; however, maps made using large categories can slow produce unwieldy view.","code":"BeeBDC::interactiveMapR(    # occurrence data   data = beeData,    # Directory where to save files   outPath = paste0(OutPath_Figures, \"interactiveMaps\", sep = \"/\"),   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",     # Occurrence dataset column with species names   speciesColumn = \"scientificName\",     # Which species to map — a character vector of names or \"ALL\"     # Note: \"ALL\" is defined AFTER filtering for country   speciesList = \"ALL\",   countryList = NULL, # study area     # Point jitter to see stacked points — jitters an amount in decimal degrees   jitterValue = 0.01 )"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"data-providers","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.5 Data providers","title":"BeeBDC vignette","text":"Read clean data ’s already environment. function attempt find build table data providers contributed input data, especially using ‘institutionCode’ column. also search variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions (perhaps lesser degree).","code":"if (!exists(\"cleanData\")) {     cleanData <- readr::read_csv(paste(OutPath_Intermediate, \"05_cleaned_database.csv\",         sep = \"/\"), col_types = BeeBDC::ColTypeR(), locale = readr::locale(encoding = \"UTF-8\")) } # Note, if outPath = NULL then no file will be saved dataProvTable <- BeeBDC::dataProvTables(data = cleanData, runBeeDataChecks = TRUE,     outPath = NULL, fileName = \"dataProvTable.csv\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/BeeBDC_main.html","id":"flag-summary","dir":"Articles","previous_headings":"9.0 Figures and tables","what":"9.6 Flag summary","title":"BeeBDC vignette","text":"function flagSummaryTable() takes flagged dataset returns total number fails (FALSE) per flag (columns starting “.”) per species. Users may define column group summary. intended work scientificName column, users may select grouping column (e.g., country).","code":"# Note, if outPath = NULL then no file will be saved summaryTable <- BeeBDC::flagSummaryTable(data = beeData, column = \"scientificName\",     outPath = NULL, fileName = \"flagTable.csv\") ##  - We will flag all columns starting with '.' ##  - summaryFun: ## Flagged 111  ##   The .summary column was added to the database. ## The percentages of species impacted by each flag in your analysis are as follows:  ##   .coordinates_empty = 26.19% ##   .coordinates_outOfRange = 0% ##   .basisOfRecords_notStandard = 1.19% ##   .coordinates_country_inconsistent = 1.19% ##   .occurrenceAbsent = 8.33% ##   .unLicensed = 0% ##   .GBIFflags = 0% ##   .rou = 32.14% ##   .sequential = 0% ##   .uncertaintyThreshold = 15.48% ##   .eventDate_empty = 15.48% ##   .year_outOfRange = 16.67% ##   .duplicates = 0%"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"section","dir":"Articles","previous_headings":"","what":"Basic workflow","title":"Basic workflow","text":"workflow meant basic example workflow user might take flagged version () occurrence dataset filter specific taxa countries, re-apply flagging functions, re-filter data, make maps based data.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"working-directory","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.1 Working directory","title":"Basic workflow","text":"Choose path root folder folders can found. first time run BeeBDC, want use renv package manage packages, can install renv… initialise renv project. already initialised project, can instead just activate .","code":"RootPath <- paste0(\"/your/path/here\") # Create the working directory in the RootPath if it doesn't exist already if (!dir.exists(paste0(RootPath, \"/Data_acquisition_workflow\"))) {     dir.create(paste0(RootPath, \"/Data_acquisition_workflow\"), recursive = TRUE) } # Set the working directory setwd(paste0(RootPath, \"/Data_acquisition_workflow\")) install.packages(\"renv\", repos = \"http://cran.us.r-project.org\") renv::init(project = paste0(RootPath,\"/Data_acquisition_workflow\")) renv::activate(project = paste0(RootPath, \"/Data_acquisition_workflow\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"install-packages-if-needed","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.2 Install packages (if needed)","title":"Basic workflow","text":"may need install gdal computer. can done Mac using Homebrew terminal command “brew install gdal”. start , need install BiocManager, devtools, ComplexHeatmap, rnaturalearthhires install fully use BeeBDC. Now install BeeBDC. Snapshot renv environment. Set directories used BeeBDC. directories include data, figures, reports, etc. saved. RDoc needs path RELATIVE RootPath; .e., file path two diverge.","code":"if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\", repos = \"http://cran.us.r-project.org\")  BiocManager::install(\"ComplexHeatmap\") # Install remotes if needed if (!require(\"remotes\", quietly = TRUE)) install.packages(\"remotes\", repos = \"http://cran.us.r-project.org\") # Download and then load rnaturalearthhires remotes::install_github(\"ropensci/rnaturalearthhires\") install.packages(\"rnaturalearthhires\", repos = \"https://ropensci.r-universe.dev\",     type = \"source\") library(rnaturalearthhires) install.packages(\"BeeBDC\") library(BeeBDC) renv::snapshot(project = paste0(RootPath, \"/Data_acquisition_workflow\"), prompt = FALSE) ## The following package(s) will be updated in the lockfile: ##  ## # RSPM ----------------------------------------------------------------------- ## - renv   [* -> 1.1.4] ##  ## The version of R recorded in the lockfile will be updated: ## - R      [* -> 4.5.1] ##  ## - Lockfile written to \"/tmp/Rtmp3kP9OG/Data_acquisition_workflow/renv.lock\". BeeBDC::dirMaker(RootPath = RootPath, RDoc = \"vignettes/BeeBDC_main.Rmd\") %>%     # Add paths created by this function to the environment() list2env(envir = parent.env(environment()))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"load-packages","dir":"Articles","previous_headings":"0.0 Script preparation","what":"0.3 Load packages","title":"Basic workflow","text":"Load packages.","code":"lapply(c(\"ComplexHeatmap\", \"magrittr\"), library, character.only = TRUE) ## Loading required package: grid ##  ## Attaching package: 'grid' ## The following object is masked from 'package:terra': ##  ##     depth ## ======================================== ## ComplexHeatmap version 2.24.0 ## Bioconductor page: http://bioconductor.org/packages/ComplexHeatmap/ ## Github page: https://github.com/jokergoo/ComplexHeatmap ## Documentation: http://jokergoo.github.io/ComplexHeatmap-reference ##  ## If you use it in published research, please cite either one: ## - Gu, Z. Complex Heatmap Visualization. iMeta 2022. ## - Gu, Z. Complex heatmaps reveal patterns and correlations in multidimensional  ##     genomic data. Bioinformatics 2016. ##  ##  ## The new InteractiveComplexHeatmap package can directly export static  ## complex heatmaps into an interactive Shiny app with zero effort. Have a try! ##  ## This message can be suppressed by: ##   suppressPackageStartupMessages(library(ComplexHeatmap)) ## ======================================== ##  ## Attaching package: 'ComplexHeatmap' ## The following object is masked from 'package:terra': ##  ##     draw ## The following object is masked from 'package:R.utils': ##  ##     draw"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"taxon-example","dir":"Articles","previous_headings":"","what":"2.0 Taxon example","title":"Basic workflow","text":"want filter dataset particular taxon interest, can quite easily using dplyr tidyverse group packages. filter selected bee genus, case Anthophorini…","code":"# Load some package data — the taxonomy and a flagged example dataset Download # the full beesTaxonomy file taxonomyFile <- BeeBDC::beesTaxonomy() # load in the small test dataset in the background system.file(\"extdata\", \"testTaxonomy.rda\", package = \"BeeBDC\") |>     load() # Rename the file taxonomyFile <- testTaxonomy rm(testTaxonomy) # Load the example beesFlagged dataset beesFlagged <- BeeBDC::beesFlagged  selectedGenera <- taxonomyFile %>%     # Select only tribe anthophorini (for example) dplyr::filter(tolower(tribe) == tolower(\"anthophorini\")) %>%     distinct(genus)  # Filter the data taxonData <- beesFlagged %>%     dplyr::filter(genus %in% selectedGenera$genus) # View the data taxonData ## # A tibble: 2 × 124 ##   database_id  scientificName family subfamily genus subgenus subspecies species ##   <chr>        <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   ## 1 Dorey_data_… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… ## 2 Dorey_data_… Deltoptila el… Apidae Apinae    Delt… NA       NA         Deltop… ## # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, ## #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, ## #   identificationQualifier <lgl>, higherClassification <chr>, ## #   identificationReferences <lgl>, typeStatus <chr>, ## #   previousIdentifications <chr>, verbatimIdentification <chr>, ## #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, ## #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"country-example","dir":"Articles","previous_headings":"","what":"3.0 Country example","title":"Basic workflow","text":"Similarly can filter countries interest. Keep mind, sometimes country column may hold records fall country, , coordinates, entered incorrectly.","code":"# Select your study area studyArea <- c(\"Canada\", \"United states\", \"Mexico\", \"Guatemala\") # Filter the data to that area countryData <- beesFlagged %>%     dplyr::filter(country %in% studyArea) # View the data countryData ## # A tibble: 49 × 124 ##    database_id scientificName family subfamily genus subgenus subspecies species ##    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   ##  1 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… ##  2 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… ##  3 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… ##  4 Dorey_data… Svastra duplo… Apidae Apinae    Svas… NA       NA         Svastr… ##  5 Dorey_data… Agapostemon f… Halic… Halictin… Agap… NA       NA         Agapos… ##  6 Dorey_data… Melissodes tr… Apidae Apinae    Meli… NA       NA         Meliss… ##  7 Dorey_data… Osmia pumila … Megac… Megachil… Osmia NA       NA         Osmia … ##  8 Dorey_data… Perdita bisho… Andre… Panurgin… Perd… NA       NA         Perdit… ##  9 Dorey_data… Melissodes lu… Apidae Apinae    Meli… NA       NA         Meliss… ## 10 Paige_data… Melecta thora… Apidae Apinae    Mele… NA       NA         Melect… ## # ℹ 39 more rows ## # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, ## #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, ## #   identificationQualifier <lgl>, higherClassification <chr>, ## #   identificationReferences <lgl>, typeStatus <chr>, ## #   previousIdentifications <chr>, verbatimIdentification <chr>, ## #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …"},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"simple-filter","dir":"Articles","previous_headings":"4.0 Filtering example","what":"4.1 Simple filter","title":"Basic workflow","text":"BeeBDC package provides simple function can re-build .summary column based filtering columns present dataset (starting “.”). can also choose filters want implement using dontFilterThese argument. example, also removing filtering columns output dataset (removeFilterColumns = TRUE) filtering completely clean occurrences (filterClean = TRUE). latter, keeping .summary == TRUE.","code":"filteredData <-    BeeBDC::summaryFun(data = beesFlagged,    # Choose the columns to NOT filter (or NULL to filter all columns)    dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",                       \".uncertaintyThreshold\"),     # In the output, do you want to REMOVE all filtering columns (TRUE), or keep them (FALSE)    removeFilterColumns = TRUE,    # In the output, do you want to only keep clean data according to your filtering (TRUE),     # Or keep all data and simply update the .summary column (FALSE)   filterClean = TRUE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 74  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column."},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"uncertainty-threshold","dir":"Articles","previous_headings":"4.0 Filtering example","what":"4.2 Uncertainty threshold","title":"Basic workflow","text":"may also want change .uncertaintyThreshold chosen somewhat strict default 1 km dataset. , instead flag 10 km (threshold = 10000 [m]). Additionally, use magrittr package pipe (%>%) feed outputs directly summaryFun() filter data one action!","code":"filteredData <- beesFlagged %>%   # Remove any exiting .uncertaintyThreshold column   dplyr::select(!tidyselect::any_of(\".uncertaintyThreshold\")) %>%     # Chose the coordinate uncertainty to filter to...   BeeBDC::coordUncerFlagR(data = .,                   uncerColumn = \"coordinateUncertaintyInMeters\",                     # 10 km here                   threshold = 10000) %>%     # Now re-do the .summary column and filter the data using this new value   BeeBDC::summaryFun(   data = .,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\"),   removeFilterColumns = TRUE,   filterClean = TRUE) ## \\coordUncerFlagR: ##  Flagged 3 geographically uncertain records: ##  The column '.uncertaintyThreshold' was added to the database. ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms ##  - summaryFun: ## Flagged 75  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column."},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"a--bdc_year_outofrange","dir":"Articles","previous_headings":"4.0 Filtering example > 4.2 Date filter","what":"a. bdc_year_outOfRange","title":"Basic workflow","text":"Another column users likely want pay close attention .year_outOfRange column set 1950 dataset. case, bdc provides function users can change year_threshold argument , case, 1970. , use summaryFun() get results one go.","code":"filteredData <- beesFlagged %>%     # Remove any exisitng .year_outOfRange column dplyr::select(!\".year_outOfRange\") %>%     # Chose the minimum year to filter to... bdc::bdc_year_outOfRange(data = ., eventDate = \"year\", year_threshold = 1970) %>%     # Now re-do the .summary column and filter the data using this new value BeeBDC::summaryFun(data = ., dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\",     \".uncer_terms\", \".uncertaintyThreshold\"), removeFilterColumns = TRUE, filterClean = TRUE) ##  ## bdc_year_outOfRange: ## Flagged 23 records. ## One column was added to the database. ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 76  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column."},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"b--year-range","dir":"Articles","previous_headings":"4.0 Filtering example > 4.2 Date filter","what":"b. year range","title":"Basic workflow","text":", ’re interested particular time period, dplyr comes rescue straight forward filtering within year range. Users may choose number filtering steps form main workflow include summaryFun(), just use pipes ‘%>%’ function use ‘.’ data input feed data aoutput function proceeding one.","code":"filteredData <-    # The input dataset   beesFlagged %>%   # Chose the year range...   dplyr::filter(year > 1950 & year < 1970) %>%   # Now re-do the .summary column and filter the data using this new value   BeeBDC::summaryFun(     # Select the input dataset to filter     data = .,     # Choose the columns to NOT filter (or NULL to filter all columns)     dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",                         \".uncertaintyThreshold\"),     # In the output, do you want to REMOVE all filtering columns (TRUE), or keep them (FALSE)     removeFilterColumns = TRUE,     # In the output, do you want to only keep clean data according to your filtering (TRUE),     # Or keep all data and simply update the .summary column (FALSE)     filterClean = TRUE) ##  - We will NOT flag the following columns. However, they will remain in the data file. ## .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold ##  - summaryFun: ## Flagged 8  ##   The .summary column was added to the database. ##  - REMOVED all occurrences that were FALSE for the 'summary' column."},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"summary-figures","dir":"Articles","previous_headings":"","what":"5. Summary figures","title":"Basic workflow","text":"Now, wanted rebuild figures, say ’ve added filtered data, can use processes.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"duplicate-chorddiagrams","dir":"Articles","previous_headings":"5. Summary figures","what":"5.1 Duplicate chordDiagrams","title":"Basic workflow","text":"chordDiagramR() function useful relies two great packages, circlize ComplexHeatmap. Unfortunately, latter available CRAN must downloaded using BiocManager. don’t actually example duplicates dataset package, ’ll magic one behind scences! , set parameters figure borders run data chordDiagramR().","code":"if (!require(\"BiocManager\", quietly = TRUE)) {     install.packages(\"BiocManager\") } BiocManager::install(\"ComplexHeatmap\", force = TRUE) renv::snapshot() duplicates <- fileFinder(path = \"PATH TO A FOLDER CONTAINING THE duplicateRun_ — could be supp. materials folder\",     fileName = \"duplicateRun_\") %>%     readr::read_csv() %>%     # Select only the stingless bee data dplyr::filter(database_id %in% stinglessData$database_id | database_id_match %in%     stinglessData$database_id) # Choose the global figure parameters   par(mar = c(2, 2, 2, 2)/2, mfrow = c(1,1))  # Create the chorDiagram. You can leave many of the below values out but we show here # the defaults  BeeBDC::chordDiagramR(   # The duplicate data from the dupeSummary function output     dupeData = duplicates,   outPath = OutPath_Figures,   fileName = \"ChordDiagram.pdf\",   # These can be modified to help fit the final pdf that's exported.   width = 9,   height = 7.5,   bg = \"white\",   # How few distinct dataSources should a group have to be listed as \"other\"   smallGrpThreshold = 3,   title = \"Duplicated record sources\",   # The default list of colour palettes to choose from usign the paleteer package   palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",                 \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",                \"cartography::purple.pal\", \"cartography::brown.pal\"),   canvas.ylim = c(-1.0,1.0),    canvas.xlim = c(-0.6, 0.25),   text.col = \"black\",   legendX = grid::unit(6, \"mm\"),   legendY = grid::unit(18, \"mm\"),   legendJustify = c(\"left\", \"bottom\"),   niceFacing = TRUE)"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"duplicate-histogram","dir":"Articles","previous_headings":"5. Summary figures","what":"5.2 Duplicate histogram","title":"Basic workflow","text":"example, use one example datasets show works. use beesFlagged, filtered larger dataset contains duplicates larger dataset. print plot R, need specify returnPlot = TRUE, otherwise save disk","code":"data(\"beesFlagged\", package = \"BeeBDC\")  # Create a figure shoring the total number of duplicates, kept duplicates, and unique # records for each datasource (simplified to the text before the first underscore) and # the proportion of the above for each data source BeeBDC::dupePlotR(   data = beesFlagged,   # The outPath to save the plot as   outPath = tempdir(),   fileName = \"Fig3_duplicatePlot.pdf\",   # Colours in order: duplicate, kept duplicate, unique   dupeColours = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"),   # Plot size and height   base_height = 7, base_width = 7,   legend.position = c(0.85, 0.8),   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\",   returnPlot = TRUE )"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"flags-by-source","dir":"Articles","previous_headings":"5. Summary figures","what":"5.3 Flags by source","title":"Basic workflow","text":"plotFlagSummary() function one important quickly summarising checking data flags worked together correctly. can good starting point error-checking. also see plotFlagSummary() can filter particular species also output quick point maps species.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"a--all-taxa-in-dataset","dir":"Articles","previous_headings":"5. Summary figures > 5.3 Flags by source","what":"a. all taxa in dataset","title":"Basic workflow","text":"###### b. Single sp. summary #### fact, lets build one single-species example using data omnipresent Apis mellifera.","code":"# Visualise all flags for each dataSource (simplified to the text before the first underscore) BeeBDC::plotFlagSummary(   data = beesFlagged,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"Fig4_FlagsPlot_\", Sys.Date(),\".pdf\"),   outPath = tempdir(),   width = 15, height = 9,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\",   returnPlot = TRUE ) ##  - Preparing data to plot... ##  - Building plot... # Visualise all flags for each dataSource (simplified to the text before the first underscore)   # A clever user might also realise the potential to summarise and produce outputs in other columns BeeBDC::plotFlagSummary(   # WARNING: alternate path if wanting to produce figures for the selected taxonData (2.0 above)   # Select only the taxonData data   data = beesFlagged,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"FlagsPlot_Amell\", Sys.Date(),\".pdf\"),   outPath = tempdir(),   width = 15, height = 9,   # OPTIONAL:          #  # Filter to species            speciesName = \"Apis mellifera Linnaeus, 1758\",              # column to look in            nameColumn = \"scientificName\",            # Save the filtered data            saveFiltered = FALSE,      # Filter column to display on map            filterColumn = \".summary\",            plotMap = TRUE,        # amount to jitter points if desired, e.g. 0.25 or NULL      jitterValue = NULL,        # Map opacity value for points between 0 and 1      mapAlpha = 1,   returnPlot = TRUE,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'B. Mont.' = \"BMont\", 'B. Minkley' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\" ) ##  - Filtering to selected species... ##  - Selected species has 8 occurrences. ##  - Preparing data to plot... ##  - Building plot..."},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"maps","dir":"Articles","previous_headings":"5. Summary figures","what":"5.4 Maps","title":"Basic workflow","text":"can also make overall summary maps country level using summaryMaps(). get error breaks unique, reduce class_n.","code":"BeeBDC::summaryMaps(data = beesFlagged, width = 10, height = 10, class_n = 3, class_Style = \"jenks\",     outPath = tempdir(), fileName = \"CountryMaps_jenks.pdf\", returnPlot = TRUE) ## Spherical geometry (s2) switched off ##  - Extracting country data from points... ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ## Extraction complete. ##  - Buffering naturalearth map by pointBuffer... ## dist is assumed to be in decimal degrees (arc_degrees). ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar ## although coordinates are longitude/latitude, st_intersects assumes that they ## are planar"},{"path":"https://jbdorey.github.io/BeeBDC/articles/basic_workflow.html","id":"save-data","dir":"Articles","previous_headings":"","what":"6.0 Save data","title":"Basic workflow","text":"","code":"mapData %>%     readr::write_excel_csv(paste0(DataPath, \"/Output/Intermediate/\", \"cleanTaxon_\",         Sys.Date(), \".csv\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"section","dir":"Articles","previous_headings":"","what":"Species richness estimation","title":"Species richness estimation","text":"basic workflow feeding species occurrence data, group’s taxonomy, group’s country checklist BeeBDC order produce species richness estimates. functions also generic wrappers around SpadeR iNEXT functions can used abundance data. functions grown original publication.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"working-directory","dir":"Articles","previous_headings":"Script preparation","what":"Working directory","title":"Species richness estimation","text":"Choose path root folder folders can found.","code":"RootPath <- paste0(\"/your/path/here\") # Create the working directory in the RootPath if it doesn't exist already if (!dir.exists(paste0(RootPath, \"/Data_acquisition_workflow\"))) {     dir.create(paste0(RootPath, \"/Data_acquisition_workflow\"), recursive = TRUE) } # Set the working directory setwd(paste0(RootPath, \"/Data_acquisition_workflow\"))"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"install-packages-if-needed","dir":"Articles","previous_headings":"Script preparation","what":"Install packages (if needed)","title":"Species richness estimation","text":"may need install packages using workflow. particular, SpadeR iNEXT required. prompt download first time run functions, however, let’s install now.","code":"install.packages(\"SpadeR\") install.packages(\"iNEXT\")"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"parallel-estimations","dir":"Articles","previous_headings":"","what":"Parallel estimations","title":"Species richness estimation","text":"can start looking relatively simple iNEXT SpadeR wrapper functions can take usual inputs functions host packages. (See iNEXT::iNEXT() SpadeR::ChaoSpecies() info.) functions can take data run multiple sites/countries/whatever level want throw run parallel. greatly simplifies code needed run also makes implementation MUCH faster!","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"inextwrapper","dir":"Articles","previous_headings":"Parallel estimations","what":"iNEXTwrapper","title":"Species richness estimation","text":"BeeBDC::iNEXTwrapper() parallelizes iNEXT::iNEXT(), estimates species richness patterns extrapolating interpolating Hill numbers. large kinda equates estimating richness rarefaction. can start reading example dataset 1,488 scientificName-country_suggested combinations across four countries; Fiji, Uganda, Vietnam, Zambia. Next, let’s look usually use iNEXT… first transforming (simple example) occurrence dataset right format running function. can also view output function running output_iNEXT$AsyEst implementation BeeBDC::iNEXTwrapper() also relatively simple; including implementation running parallel (Note: Windows machines can’t use R’s parallel functions). can modify input data work function leave inputs iNEXTwrapper defaults change saw fit. key variable change mc.cores however many threads ’d liek use computer!","code":"beesCountrySubset <- BeeBDC::beesCountrySubset # Transform the data transformedAbundance <- beesCountrySubset %>%     dplyr::group_by(scientificName, country_suggested) %>%     dplyr::count() %>%     dplyr::select(scientificName, country_suggested, n) %>%     tidyr::pivot_wider(names_from = country_suggested, values_from = n, values_fill = 0) %>%     # Create the rownames tibble::column_to_rownames(\"scientificName\") %>%     dplyr::tibble() %>%     as.data.frame() # Run iNEXT output_iNEXT <- iNEXT::iNEXT(transformedAbundance, datatype = \"abundance\") # Transform data data_nextWrapper <- beesCountrySubset %>%     dplyr::group_by(scientificName, country_suggested) %>%     dplyr::count()  # Calculate iNEXT with the wrapper function output_iNEXTwrapper <- BeeBDC::iNEXTwrapper(data = data_nextWrapper, variableColumn = \"country_suggested\",     valueColumn = \"n\", q = 0, datatype = \"abundance\", conf = 0.95, se = TRUE, nboot = 50,     size = NULL, endpoint = NULL, knots = 40, mc.cores = 1) ##  - Outputs can be found in a list with two tibbles called 'DataInfo' and 'AsyEst' and a list of iNext outputs per groupVariable in iNextEst'."},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"chaowrapper","dir":"Articles","previous_headings":"Parallel estimations","what":"ChaoWrapper","title":"Species richness estimation","text":"BeeBDC::ChaoWrapper() parallelizes SpadeR::ChaoSpecies(), estimates species richness using various non-parametric estimators. primary one tend use iChao. Let’s use example dataset first run SpadeR function. Let’s view output function running output_iChao$Species_table. , ’ll able see actually quite species richness estimators available . implementation parallel wrapper also quite simple BeeBDC::ChaoWrapper(). number cores can also changed using mc.cores argument. Note, case, can run sites (countries) ! View output output_iChaowrapper$diversityTable.","code":"# Transform data data_iChao <- beesCountrySubset %>%     dplyr::group_by(scientificName, country_suggested) %>%     dplyr::count() %>%     dplyr::select(scientificName, country_suggested, n) %>%     tidyr::pivot_wider(names_from = country_suggested, values_from = n, values_fill = 0) %>%     # Create the rownames tibble::column_to_rownames(\"scientificName\") %>%     dplyr::tibble()  # Run ChaoSpecies for the country Fiji output_iChao <- SpadeR::ChaoSpecies(data_iChao$Fiji, datatype = \"abundance\") # Run the wrapper function output_iChaowrapper <- BeeBDC::ChaoWrapper(data = data_iChao, datatype = \"abundance\",     k = 10, conf = 0.95, mc.cores = 1) ##  - Outputs can be found in a list with two tibbles called 'basicTable' and 'richnessTable'."},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"visualising","dir":"Articles","previous_headings":"Parallel estimations","what":"Visualising","title":"Species richness estimation","text":"easy simple use wrapper functions. However, complexity output data types can actually little bit confusing work . Especially want visualise data. , also provide function, BeeBDC::ggRichnessWrapper() display results wrapper functions site. functino save plot visualises data (), also outputs summary estimates. Note Fiji’s diversity seems reaching asymptote, remaining country’s species richnesses still climbing. Vietnam particular huge amount uncertainty iChao estimates (green) reaching 60 species! knew really small dataset (fact chose test dataset small), goes show data inadequate may get great answer. plus side, 95% confidence intervals overlap. can see, functions moving towards simplifying quick mass-estimation species richness across sites countries! idea behind improvements. , take also attempting sample known taxa otherwise missing datasets!","code":"plot_summary <- BeeBDC::ggRichnessWrapper(iNEXT_in = output_iNEXTwrapper, iChao_in = output_iChaowrapper,     nrow = 2, ncol = 2, labels = NULL, fileName = \"speciesRichnessPlots\", outPath = tempdir(),     base_width = 8.3, base_height = 11.7, dpi = 300) ## Loading required namespace: cowplot ## Error in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"NULL\" ## Error: object 'plot_summary' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"estimating-richness-from-the-known-unknowns","dir":"Articles","previous_headings":"","what":"Estimating richness from the known unknowns","title":"Species richness estimation","text":"Seems like bit odd title, ? Well, many taxa country-level checklists. Even insect taxa can well represented global country-level checklists; example, ants, butterflies, dragonflies, bees. vertebrates situation even better. Country-level global checklists often incorporate knowledge isn’t contianed species occurrence datasets , perhaps, can take advantage .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"preparing-the-inputs","dir":"Articles","previous_headings":"Estimating richness from the known unknowns","what":"Preparing the inputs","title":"Species richness estimation","text":"bee species richness estimates paper, 4,819 species (total ~21,000 species) occurrence records globally. run species richness estimates using just occurrences , wanted incorporate knowledge estimates. , found samples sizes -recent literature 497 species generated curve (also generated curve using global- country-level occurrence datasets found former match literature curve well). can extract formula curve use randomly generate data missing species. curves can built using data; see section 1.6 R code bee species richness estimates paper, uses ggplot2 mosaic’s fitModel function generate curve function goes BeeBDC::diversityPrepR() . Let’s dig … start , make R object using occurrence data (beesCountrySubset), taxonomy (BeeBDC::beesTaxonomy() BeeBDC::taxadbToBeeBDC()), country checklist(BeeBDC::beesChecklist() manually-made checklist countries rNaturalEarth_name column species validName column; latter must match remaining data — see BeeBDC::HarmoniseR()). Feel free explore input files output list files modifying pay attention match column names. Note well curveFunction one generated Literature curve .","code":"# Generate the R file estimateData <- BeeBDC::diversityPrepR(   data = beesCountrySubset,     # Download the bee taxonomy. Download other taxonomies using BeeBDC::taxadbToBeeBDC()   taxonomyFile = BeeBDC::beesTaxonomy(),     # Download the bee country checklist. See notes above about making a checklist for other taxa   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\" ) ## Error: 'diversityPrepR' is not an exported object from 'namespace:BeeBDC'"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"making-estimates","dir":"Articles","previous_headings":"Estimating richness from the known unknowns","what":"Making estimates","title":"Species richness estimation","text":"output file code used feed BeeBDC::richnessEstimator() function repeatedly sample provided curve estimate species richness (user-defined number times) country (site), continental, global level. function can also run parallel run whatever scale user asks . globalSamples, continentSamples, countrySamples set zero, run. set >0, estimated many times. Let’s run estimates country (site) level ten times , drawing sample sizes non-occurrence species time (capped maximum sample size country). can look median outputs analysis estimates$Summary. , can look outputs iteration together estimates$SiteOutput.","code":"estimates <- BeeBDC::richnessEstimateR(   data = estimateData,   sampleSize = 10000,   globalSamples = 0,   continentSamples = 0,   countrySamples = 10,     # Increase the number of cores to use R's parallel package and speed estimates up.   mc.cores = 1,     # Directory where to save files   outPath = tempdir(),   fileName = \"Sampled.pdf\" ) ## Error: object 'estimateData' not found ## Error: object 'estimates' not found ## Error: object 'estimates' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"visualising-estimates","dir":"Articles","previous_headings":"Estimating richness from the known unknowns","what":"Visualising estimates","title":"Species richness estimation","text":"course, values super helpful papers topics. similarly, can easily make useful visualisations! many ways plot analyse kinds data. rest leave ! , ideas, feel free check original publication workflow well original R workflow .","code":"# To build the manual legend, make a small fake dataset legendData <- dplyr::tibble(name = c(\"yes\",\"yes\"),                                               statistic = c(\"iChao\", \"iNEXT\") %>%                                                 factor(levels = c(\"iChao\", \"iNEXT\")),                                               est = c(1,1)) # Build a legend manually violinLegend <- ggplot2::ggplot(legendData, ggplot2::aes(x = name, y = est)) +    ggplot2::geom_point(data = legendData, ggplot2::aes(y=est, x = name, colour = \"red\")) +     scale_color_manual(labels = c('Observed'), values = c('grey30'))  +    ggplot2::geom_bar(aes(fill = statistic, y = est), position = position_dodge(0.90),                        stat = \"identity\") +    ggplot2::scale_fill_manual(name = \"Statistic\",                               labels = c(\"iChao\", \"iNEXT\"),                               values = c(\"iChao\" = \"#55AD9B\", \"iNEXT\" = \"#FD9B63\")) +    ggplot2::theme_classic() +    theme(legend.title = element_blank(), legend.position = 'right',           legend.margin = margin(0, 0, 0, 0), legend.spacing.y = unit(0, \"pt\")) +    ggplot2::guides(fill = ggplot2::guide_legend(ncol = 1, byrow = TRUE, reverse = TRUE, order = 1))  # plot the countries  violinPlot <- ggplot2::ggplot(estimates$SiteOutput, ggplot2::aes(x = name, y = est)) +     ggplot2::geom_violin(position=\"dodge\", alpha=0.5, ggplot2::aes(fill=Name,                                                                    y=`95%Lower`, x=variable),                          colour =  NA) +    ggplot2::geom_violin(position=\"dodge\", alpha=0.5, ggplot2::aes(fill=Name, y=`95%Upper`,                                                                   x=variable), colour =  NA) +    ggplot2::geom_violin(position=\"dodge\", alpha=1, ggplot2::aes(fill=Name, y=Estimate,                                                                  x=variable), colour =  \"black\") +    ggplot2::scale_fill_manual(values=c(\"#55AD9B\", \"#FD9B63\")) +     ggplot2::geom_point(data = estimates$SiteOutput %>%                           dplyr::distinct(variable, Observed) %>%                            tidyr::drop_na(),                          ggplot2::aes(x = variable, y = Observed), col = \"grey40\") +   ggplot2::theme_classic() +    ggplot2::xlab(\"Continent\") +    ggplot2::ylab(\"Species estimate\") +   guides(fill=guide_legend(title=\"Statistic\")) +   ggplot2::theme_classic() +   ggplot2::theme(legend.position = \"none\",                   axis.text.x = ggplot2::element_text(angle = 60, vjust = 1, hjust=1)) +   ggplot2::xlab(c( \"\")) + ggplot2::ylab(c(\"Species\"))  +   ggplot2::annotation_custom(cowplot::ggdraw(cowplot::get_legend(violinLegend)) %>%                                ggplot2::ggplotGrob(), xmin = 1, xmax = 1,                                 ymin = 350, ymax = 500) ## Error: object 'estimates' not found ## Tip: You can wrap the entire ggplot2 chunk of code in brackets () to print at the same time  # Save the plot cowplot::save_plot(filename = paste0(tempdir(), \"/violinPlot.pdf\"),                    plot = violinPlot,                    base_width = 10,                    base_height = 7) ## Error: object 'violinPlot' not found"},{"path":"https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html","id":"read-more","dir":"Articles","previous_headings":"","what":"Read more","title":"Species richness estimation","text":"can read implementation work original citation: Dorey J. B., Gilpin, .-M., Johnson, N., Esquerre, D., Hughes, . C., Ascher, J. S., & Orr, M. C. (review). many bee species ? quantitative global estimate. Nature Communications","code":""},{"path":"https://jbdorey.github.io/BeeBDC/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James B. Dorey. Author, maintainer, copyright holder. Robert L. O'Reilly. Author. Silas Bossert. Author. Erica E. Fischer. Author.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Dorey, J. B., Fischer, E. E., Chesshire, P. R., Bolaños, . N., O’reilly, R. L., Bossert, S., Collins, S. M., Lichtenberg, E. M., Tucker, E., Smith-Pardo, ., Falcon-Brindis, ., Guevara, D. ., Ribeiro, B. R., De Pedro, D., Hung, J. K.-L., Parys, K. ., McCabe, L.M., Rogan, M. S., Minckley, R. L., Velzco, S. J. E., Griswold, T., Zarrillo, T. ., Jetz, W., Sica, Y., Orr, M. C., Guzman, L. M., Ascher, J., Hughes, . C. & Cobb, N. S. Accepted. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific data. doi: <https://doi.org/10.1101/2023.06.30.547152> Dorey, J. B., O'Reilly, R. L., Bossert, S., Fischer, E. E. (2023). BeeBDC: occurrence data cleaning package. R package version 1.3.0. url: <https://github.com/jbdorey/BeeBDC>","code":"@Article{,   title = {A globally synthesised and flagged bee occurrence dataset and cleaning workflow},   author = {{Dorey, James B [aut],Fischer, Erica E [aut],Chesshire, Paige R [aut],Bolaños, Angela N [aut],O’Reilly, Robert L [aut],Bossert, Silas [aut],Collins, Shannon M [aut],Lichtenberg, Elinor M [aut],Tucker, Erika [aut],Smith-Pardo, Allan [aut],Falcon-Brindis, Armando [aut],Guevara, Diego A [aut],Ribeiro, Bruno R [aut],de Pedro, Diego [aut],Hung, James Keng-Lou [aut],Parys, Katherine A [aut],McCabe Lindsie M [aut],Rogan, Matthew S [aut],Minckley, Robert L [aut],Velzco, Santiago J E [aut],Griswold, Terry [aut],Zarrillo, Tracy A [aut],Jetz, Walter [aut],Sica, Yanina [aut],Orr, Michael C [aut],Guzman, Laura Melissa [aut],Ascher, John [aut],Hughes, Alice C [aut],Cobb, Neil S [aut]}},   journal = {Scientific Data},   year = {2023},   doi = {10.1101/2023.06.30.547152}, } @Manual{,   title = {BeeBDC: an occurrence data cleaning package},   author = {{Dorey, James B. [aut],O’Reilly, Robert L. [aut],Bossert, Silas [aut],Fischer, Erica E. [aut]}},   year = {2023},   note = {R package version 1.3.0},   url = {https://github.com/jbdorey/BeeBDC}, }"},{"path":[]},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"overview","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Overview","title":"Occurrence Data Cleaning","text":"consistent implementation biodiversity data continues challenge researchers. present BeeBDC package provides novel updated functions flagging, cleaning, visualising occurrence datasets. functions mostly general regards taxon; however, also provide functions data specific use bee occurrence data; specifically due input data. build upon functions conventions fantastic R packages, especially bdc CoordinateCleaner, also removing many dependencies sp-related packages. Hence, package name Bee Biodiversity Data Cleaning (BeeBDC). provide full workflow uses BeeBDC, bdc, CoordinateCleaner clean occurrence data Articles page encourage users read also cite primary publication. parallelised implementation iChao iNEXT species richness estimations, cite primary publication.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"structure-of-beebdc","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Structure of BeeBDC","title":"Occurrence Data Cleaning","text":"BeeBDC toolkit organized using conventions similar bdc CoordinateCleaner. Like bdc package, provide suggested workflow . functions can mostly run order, exceptions mentioned throughout documentation. Additionally, many functions require database_id column generated early BeeBDC bdc workflows. running large datasets (e.g., global bee occurrence dataset) may require machine minimum amount RAM (~32 GB). However, try provide work-arounds, especially alowing functions broken consumable chunks. Paper DOI - https://doi.org/10.1101/2023.06.30.547152; Package GitHub - https://github.com/jbdorey/BeeBDC/","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"installation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Installation","title":"Occurrence Data Cleaning","text":"can install BeeBDC CRAN GitHub. Two optional packages can also downloaded prior starting workflow, desired. , essential. packages BiocManager devtools may also required download two extra packages. first package, rnaturalearthhires, data package allows usage higher-resolution country maps useful multiple BeeBDC functions. second package, ComplexHeatmap, used one BeeBDC function (chordDiagramR()) less critical. either packages called, user prompted install . However, latter may try restart R session. first time use terra sf new computer may need install dependencies. Try install terra sf packages first come back doesn’t work. Windows, need first install Rtools get C++ compiler R can use. need recent version Rtools42 (rtools42-5355-5357). macOS, can use MacPorts Homebrew. MacPorts can sudo port install R-terra Homebrew, need first install GDAL: brew install pkg-config brew install gdal Followed (note additional configuration argument needed Homebrew) Load package :","code":"# Install BeeBDC from CRAN install.packages(\"BeeBDC\")    # Or using the development version from GitHub (keeping in mind this may not be as stable) remotes::install_github(\"https://github.com/jbdorey/BeeBDC.git\", user=\"jbdorey\",                            # To use the development version use \"devel\"; otherwise choose \"main\"                         ref = \"devel\", force = TRUE) # These two packages may need to be installed in order to install the actual required packages      # below. if (!require(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\") if (!require(\"devtools\", quietly = TRUE))     install.packages(\"devtools\")    # Install ComplexHeatmap and rnaturalearthhires devtools::install_github(\"ropensci/rnaturalearthhires\") BiocManager::install(\"ComplexHeatmap\") # Install terra install.packages(\"terra\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")   # install sf install.packages(\"sf\", type = \"source\", configure.args = \"--with-proj-lib=$(brew --prefix)/lib/\")  library(terra) library(sf) library(BeeBDC)"},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_1-data-merge","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"1. Data merge","title":"Occurrence Data Cleaning","text":"Integrate merge different datasets major data repositories - GBIF, SCAN, iDigBio, USGS, ALA. atlasDownloader() Downloads ALA data creates new file path put data. function can also request downloads atlases (see ). However, send download email must rest point. repoMerge() Locates data GBIF, ALA, iDigBio, SCAN within directory reads along eml metadata. repoFinder() Find GBIF, ALA, iDigBio, SCAN files directory. importOccurrences() Looks imports -recent version occurrence data created BeeBDC::repoMerge() function. USGS_formatter() function finds, imports, formats, creates metadata USGS dataset. formattedCombiner() Merges Darwin Core version USGS dataset created using BeeBDC::USGS_formatter() main dataset. dataSaver() Used end 1.x example workflow order save occurrence dataset associated eml metadata.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_2-data-preperation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"2. Data preperation","title":"Occurrence Data Cleaning","text":"reading formatting major minor [bee] occurrence repositories well data modifications. section mostly, entirely, related bee occurrence data. fileFinder() function can used find files within user-defined directory based user-provided character string. PaigeIntegrater() Replaces publicly available data data manually cleaned error-corrected use paper Chesshire, P. R., Fischer, E. E., Dowdy, N. J., Griswold, T., Hughes, . C., Orr, M. J., . . . McCabe, L. M. (Press). Completeness analysis 3000 United States bee species identifies persistent data gaps. Ecography. readr_BeeBDC() Read variety data files specific certain smaller data providers. internal readr function dataset one functions called readr_BeeBDC. functions internal, displayed documentation readr_BeeBDC clarity. idMatchR() function attempts match database_ids prior bdc BeeBDC run order keep column somewhat consistent iterations. However, records contain sufficient information work flawlessly.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_3-initial-flags","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"3. Initial flags","title":"Occurrence Data Cleaning","text":"Flagging carpentry several, mostly general, data issues. See bdc’s pre-filter related functions. countryNameCleanR() basic function user manually fix country name inconsistencies. jbd_CfC_chunker() BeeBDC::jbd_country_from_coordinates() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_country_from_coordinates(). jbd_Ctrans_chunker() BeeBDC::jbd_coordinates_transposed() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_coordinates_transposed(). functions preferably use countryCode column generated bdc::bdc_country_standardized(). jbd_coordCountryInconsistent() Compares stated country name occurrence record record’s coordinates using rnaturalearth data. prefix, jbd_ meant distinguish function original bdc::bdc_coordinates_country_inconsistent(). functions preferably use countryCode country_suggested columns generated bdc::bdc_country_standardized(); please run dataset prior running function. flagAbsent() Flags occurrences “ABSENT” occurrenceStatus (user-specified) column. GBIFissues() function flag records subject user-specified vector GBIF issues. flagRecorder() function used save flag data occurrence data run BeeBDC script. read append existing files, asked . flags also saved occurrence file automatically.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_4-taxonomy","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"4. Taxonomy","title":"Occurrence Data Cleaning","text":"Harmonisation scientific names taxonomy downloaded taxadb, provided Discover Life website’s taxonomic reference, custom taxonomy. taxadbToBeeBDC() Uses taxadb download species taxonomy sources transforms BeeBDC format can exported .csv R enviornment fed directly BeeBDC::harmoniseR(). means taxonomy taxon can used. See also BeeBDC::beesTaxonomy() best global bee taxonomy. harmoniseR() Uses Discover Life taxonomy harmonise bee occurrences flag match checklist. function hijacked service taxa user matched format beesTaxonomy file. BeeBDC::harmoniseR() prefers use names_clean columns generated bdc::bdc_clean_names(). required, may find better results running function dataset first.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_5-space","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"5. Space","title":"Occurrence Data Cleaning","text":"Flagging erroneous, suspicious, low-precision geographic coordinates. jbd_coordinates_precision() function flags occurrences latitude longitude values rounded. contrasts original function, bdc::bdc_coordinates_precision() flag occurrences one latitude longitude rounded. BeeBDC approach saves occurrences may terminal zeros rounded one coordinate column. diagonAlley() simple function looks potential latitude longitude fill-errors identifying consecutive occurrences coordinates regular intervals. accomplished using sliding window length determined minRepeats. coordUncerFlagR() use function, user must choose column, probably “coordinateUncertaintyInMeters” threshold occurrences flagged geographic uncertainty. countryOutlieRs() function flags country-level outliers using checklist provided package. additional context column names, see beesChecklist. continentOutlieRs() function flags continent-level outliers using checklist provided package. function works much countryOutlieRs(), lower resolution. additional context column names, see beesChecklist. jbd_create_figures() Creates figures (.e., bar plots, maps, histograms) reporting results data quality tests implemented bdc BeeBDC packages. Works like bdc::bdc_create_figures(), allows user specify save path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_6-time","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"6. Time","title":"Occurrence Data Cleaning","text":"Flagging , whenever possible, correction inconsistent collection date. dateFindR() function made search columns dates add eventDate column. function searches columns locality, fieldNotes, locationRemarks, verbatimEventDate relevant information.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_7-de-duplication","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"7. De-duplication","title":"Occurrence Data Cleaning","text":"dupeSummary() function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_8-filtering","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"8. Filtering","title":"Occurrence Data Cleaning","text":"manualOutlierFindeR() Uses expert-identified outliers source spreadsheets may edited users. function also use duplicates file made using BeeBDC::dupeSummary() identify duplicates expert-identified outliers flag well. function add flagging column called .expertOutlier records FALSE expert outliers. summaryFun() Using flag columns (column names starting “.”), function either creates updates .summary flag column FALSE flag columns FALSE. Columns can excluded removed creating .summary column. Additionally, occurrence dataset can filtered .summary = TRUE end function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_9-figures-and-tables","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"9. Figures and tables","title":"Occurrence Data Cleaning","text":"chordDiagramR() function outputs figure shows relative size direction occurrence points duplicated data providers, , SCAN, GBIF, ALA, etc. function requires outputs generated BeeBDC::dupeSummary(). dupePlotR() Creates plot two bar graphs. One shows absolute number duplicate records data source shows proportion records duplicated within data source. function requires dataset run BeeBDC::dupeSummary(). plotFlagSummary() Creates compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE. function requires dataset run filtering functions - can display logical columns starting “.”. summaryMaps() Builds output figure shows number species number occurrences per country. Breaks data classes visualisation. Users may filter data taxa interest produce figures interest. interactiveMapR() Uses occurrence data (preferably uncleaned) outputs interactive .html maps can opened browser specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can modified first running BeeBDC::summaryFun() set columns want highlighted. can also highlight occurrences flagged expert-identified country outliers. dataProvTables() function attempt find build table data providers contributed input data, especially using ‘institutionCode’ column. also look variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions. flagSummaryTable() Takes flagged dataset returns total number fails (FALSE) per flag (columns starting “.”) per species. Users may define column group summary . intended work scientificName column, users may select grouping column (e.g., country).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_10-species-richness-estimation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"10. Species richness estimation","title":"Occurrence Data Cleaning","text":"diversityPrepR() Takes occurrence dataset along taxonomy checklist order produce file ’s ready passed BeeBDC::richnessEstimateR() function order estimate species richness using iChao (non-parametric species richness; BeeBDC::ChaoWrapper()) iNEXT (hill numbers; BeeBDC::iNEXTwrapper()) countries, continents, entire globe. richnessEstimateR() Takes output dataset BeeBDC::diversityPrepR() estimate species richness using iChao (non-parametric species richness; BeeBDC::ChaoWrapper()) iNEXT (hill numbers; BeeBDC::iNEXTwrapper()) countries, continents, /entire globe. parallel functionality. iNEXTwrapper() wrapper iNEXT::iNEXT() interpolate extrapolate Hill numbers order q (rarify species richness). wrapper ability estimate species richness multiple sites (countries) using multiple cores. ChaoWrapper() wrapper SpadeR::ChaoSpecies() non-parametrically estimate species richness. wrapper ability estimate species richness multiple sites (countries) using multiple cores .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"id_11-datasets","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"11. Datasets","title":"Occurrence Data Cleaning","text":"provide two full datasets downloadable using two functions beesTaxonomy() Downloads taxonomic information bees world. Source taxonomy listed “source” mostly derived Discover Life website. data sourced BeeBDC article’s Figshare. Please see also BeeBDC::taxadbToBeeBDC() download taxonomy (taxa bees). beesChecklist() Download table contains taxonomic country information bees world based data collated Discover Life. data sourced BeeBDC article’s Figshare. provide five test datasets available BeeBDC BeeBDC::bees3sp test dataset includes 105 random occurrence records three bee species. included species : “Agapostemon tyleri Cockerell, 1917”, “Centris rhodopus Cockerell, 1897”, “Perdita octomaculata (Say, 1824)”. BeeBDC::beesRaw small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR(). BeeBDC::beesFlagged small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR(). BeeBDC::beesCountrySubset small bee occurrence dataset columns “scientificName” “country_suggested” data four countries, Fiji, Uganda, Vietnam, Zambia. test dataset species richness functions. also two small test datasets beesTaxonomy beesChecklist system files package filtered include species occur bees3sp, beesRaw, beesFlagged. accessible follows used internally tests.","code":"# Access the test taxonomy file system.file(\"extdata\", \"testTaxonomy.rda\", package=\"BeeBDC\") |> load()   # View the file View(testTaxonomy)   # Access the test checklist file system.file(\"extdata\", \"testChecklist.rda\", package=\"BeeBDC\") |> load()   # View the file View(testChecklist)"},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"package-website","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Package website","title":"Occurrence Data Cleaning","text":"See BeeBDC package website (https://jbdorey.github.io/BeeBDC/reference/index.html) detailed explanation module.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"getting-help","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Getting help","title":"Occurrence Data Cleaning","text":"encounter clear bug, please file issue . questions suggestion, flick us email (jdorey@uow.edu.au).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/index.html","id":"citation","dir":"","previous_headings":"BeeBDC: an occurrence data cleaning package","what":"Citation","title":"Occurrence Data Cleaning","text":"Figshare live data link: https://doi.org/10.25451/flinders.21709757 Species richness citation: Dorey J. B., Gilpin, .-M., Johnson, N., Esquerre, D., Hughes, . C., Ascher, J. S., & Orr, M. C. (review). many bee species ? quantitative global estimate. Nature Communications Package citation: Dorey, J. B., O’Reilly, R. L., Bossert, S. & Fischer, E. (2023). BeeBDC: occurrence data cleaning package. R package version 1.3.0. url: https://github.com/jbdorey/BeeBDC Discover Life citation (use bee taxonomy checklist): Ascher, J.S. & Pickering, J. (2020) Discover Life bee species guide world checklist (Hymenoptera: Apoidea: Anthophila). https://www.discoverlife.org/mp/20q?guide=Apoidea_species package data sets created support, part, iDigBees project","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the bee taxonomy and country checklist — BeeBDCQuery","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"simple function return information particular species, including name validity country occurrences.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"","code":"BeeBDCQuery(   beeName = NULL,   searchChecklist = TRUE,   printAllSynonyms = FALSE,   beesChecklist = NULL,   beesTaxonomy = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"beeName Character character vector. single several bee species names search beesTaxonomy beesChecklist tables. searchChecklist Logical. TRUE (default), search country checklist species. printAllSynonyms Logical. TRUE, synonyms printed entered name. default = FALSE. beesChecklist tibble. bee checklist file BeeBDC. NULL beesChecklist() called internally download file. Default = NULL. beesTaxonomy tibble. bee taxonomy file BeeBDC. NULL beesTaxonomy() called internally download file. Default = NULL.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"Returns list elements 'taxonomyReport' 'SynonymReport'. searchChecklist TRUE, 'checklistReport' also returned.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/BeeBDCQuery.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the bee taxonomy and country checklist — BeeBDCQuery","text":"","code":"# For the sake of these examples, we will use the example taxonomy and checklist   system.file(\"extdata\", \"testTaxonomy.rda\", package=\"BeeBDC\") |> load()   system.file(\"extdata\", \"testChecklist.rda\", package=\"BeeBDC\") |> load()    # Single entry example testQuery <- BeeBDCQuery(   beeName = \"Lasioglossum bicingulatum\",   searchChecklist = TRUE,   printAllSynonyms = TRUE,   beesTaxonomy = testTaxonomy,   beesChecklist = testChecklist) #> Starting taxonomy report... #> Lasioglossum bicingulatum is an accpeted name with the taxon id number 31378. #>  - 'Lasioglossum bicingulatum' has the synonyms:  #> Starting checklist report... #>  - Lasioglossum bicingulatum (Smith, 1853) is reportedly found in:  #> Australia #> The output will be returned as a list with the elements: 'taxonomyReport', 'SynonymReport', and 'checklistReport'.  #> These can be accessed using 'output'$taxonomyReport, 'output'$SynonymReport, 'output'$checklistReport, or 'output'$failedReport.    # Multiple entry example testQuery <- BeeBDCQuery(   beeName = c(\"Lasioglossum bicingulatum\", \"Nomada flavopicta\",   \"Lasioglossum fijiense (Perkins and Cheesman, 1928)\"),   searchChecklist = TRUE,   printAllSynonyms = TRUE,   beesTaxonomy = testTaxonomy,   beesChecklist = testChecklist) #> Starting taxonomy report... #> Lasioglossum bicingulatum is an accpeted name with the taxon id number 31378. #> Nomada flavopicta is an accpeted name with the taxon id number 17033. #>  - 'Lasioglossum bicingulatum' has the synonyms:  #>  - 'Nomada flavopicta' has the synonyms:  #> Starting checklist report... #>  - Lasioglossum bicingulatum (Smith, 1853) is reportedly found in:  #> Australia #>  - Nomada flavopicta (Kirby, 1802) is reportedly found in:  #> Austria, Azerbaijan, Belarus, Brussels, Bulgaria, Croatia, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Greece, Guernsey, Hungary, Iran, Italy, Jersey, Kazakhstan, Kyrgyzstan, Latvia, Liechtenstein, Lithuania, Luxembourg, Netherlands, Norway, Poland, Romania, Russian Federation, Slovakia, Slovenia, Spain, Sweden, Switzerland, Tajikistan, Turkey, Ukraine, Uzbekistan, United Kingdom #> The output will be returned as a list with the elements: 'taxonomyReport', 'SynonymReport', and 'checklistReport'.  #> These can be accessed using 'output'$taxonomyReport, 'output'$SynonymReport, 'output'$checklistReport, or 'output'$failedReport.        # Example way to examine a report from the output list   testQuery$checklistReport #> # A tibble: 41 × 23 #>    validName     DiscoverLife_name rNaturalEarth_name shortName DiscoverLife_ISO #>    <chr>         <chr>             <chr>              <chr>     <chr>            #>  1 Lasioglossum… Australia         Australia          Australia AS               #>  2 Nomada flavo… Austria           Austria            Austria   AU               #>  3 Nomada flavo… Azerbaijan        Azerbaijan         Azerbaij… AJ               #>  4 Nomada flavo… Belarus           Belarus            Belarus   BO               #>  5 Nomada flavo… Belgium           Brussels           Belgium   BE               #>  6 Nomada flavo… Bulgaria          Bulgaria           Bulgaria  BU               #>  7 Nomada flavo… Croatia           Croatia            Croatia   HR               #>  8 Nomada flavo… Czechia           Czech Republic     Czechia   EZ               #>  9 Nomada flavo… Denmark           Denmark            Denmark   DA               #> 10 Nomada flavo… Estonia           Estonia            Estonia   EN               #> # ℹ 31 more rows #> # ℹ 18 more variables: `Alpha-2` <chr>, `Alpha-3` <chr>, official <chr>, #> #   Source <chr>, matchCertainty <chr>, canonical <chr>, #> #   canonical_withFlags <chr>, family <chr>, subfamily <chr>, genus <chr>, #> #   subgenus <lgl>, specificEpithet <chr>, species <chr>, infraspecies <chr>, #> #   scientificNameAuthorship <chr>, taxon_rank <chr>, #> #   infraspecificEpithet <chr>, Notes <chr>"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ChaoWrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","title":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","text":"ChaoSpecies: Estimation species richness single community based five types data: Type (1) abundance data (datatype=\"abundance\"), Type (1A) abundance-frequency counts (datatype=\"abundance_freq_count\"), Type (2) incidence-frequency data (datatype = \"incidence_freq\"), Type (2A) incidence-frequency counts (datatype=\"incidence_freq_count\"), Type (2B) incidence-raw data (datatype=\"incidence_raw\"); see SpadeR-package details data input formats.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ChaoWrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","text":"","code":"ChaoWrapper(   data = NULL,   datatype = \"abundance\",   k = 10,   conf = 0.95,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ChaoWrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","text":"data data frame tibble. data frame containing \"abundance\"-type data per variable (population, country, species...) columns. datatype Character. type input data, \"abundance\", \"abundance_freq_count\", \"incidence_freq\", \"incidence_freq_count\" \"incidence_raw\". far tested \"abundance\" data. Default = \"abundace\". k Numeric. cut-point (default = 10), separates species \"abundant\" \"rare\" groups abundance data estimator ACE; separates species \"frequent\" \"infrequent\" groups incidence data estimator ICE. Default = 10. conf Numeric. positive number equal less 1 specifying level confidence interval. Default = 0.95. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ChaoWrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","text":"Returns list containing two tibbles. first tibble concatenates outputs basic data rare species information columns per input variable (column). second tibble concatenates various species richness estimates, input variables chunks rows. Additionally console output list variables (columns) lacked sufficient data analysed.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/ChaoWrapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel estimation of species richness in a community using iChao — ChaoWrapper","text":"","code":"if (FALSE) { # \\dontrun{   # Read in some example data and use [BeeBDC::richnessPrepR()] to create the example input data  #' data(beesCountrySubset)  estimateDataExample <- BeeBDC::richnessPrepR(   data = beesCountrySubset,   # Download the taxonomy   taxonomyFile = BeeBDC::beesTaxonomy(),   # Download the checklist   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\",   limitGlobal = NULL,   outPath = tempdir() )    # Transform the data for input inputTestData <- estimateDataExample$site_speciesCounts %>%   dplyr::select(scientificName, country_suggested, n) %>%   tidyr::pivot_wider(names_from = country_suggested,                      values_from = n,                      values_fill = 0) %>%   # Create the rownames tibble::column_to_rownames(\"scientificName\") %>%   dplyr::tibble()  iChaoOut <- ChaoWrapper( data = inputTestData, datatype = \"abundance\", k = 10, conf = 0.95, mc.cores = 1) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets up column names and types — ColTypeR","title":"Sets up column names and types — ColTypeR","text":"function uses readr::cols_only() assign column name type data (e.g., readr::col_character(), readr::col_integer()). see default columns simply run ColTypeR(). intended use readr::read_csv(). Columns present included resulting tibble unless specified using ....","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets up column names and types — ColTypeR","text":"","code":"ColTypeR(..., standardFormat = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets up column names and types — ColTypeR","text":"... Additional arguments. can specified addition ones default function.  example: newCharacterColumn = readr::col_character(), newNumericColumn = readr::col_integer(), newLogicalColumn = readr::col_logical() standardFormat Character. taxa may standard format data. Presently, bees encoded \"bee\". Default = NULL.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets up column names and types — ColTypeR","text":"Returns object class col_spec. See readr::.col_spec() additional context explication.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sets up column names and types — ColTypeR","text":"using bee standard —  Clos, B. D., Seltmann, K. C., Turley, N. E., Maffei, C., Tucker, E. M., Lane, . G., Levenson, H. K., & Woodard, H. S. (2025). Improving standardization wild bee occurrence data: towards formal wild bee data standard. Authorea. doi: https://doi.org/10.22541/au.173862402.22787949/v2","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ColTypeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets up column names and types — ColTypeR","text":"","code":"# You can simply return the below for default values   library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union BeeBDC::ColTypeR()  #> cols_only( #>   database_id = col_character(), #>   scientificName = col_character(), #>   family = col_character(), #>   subfamily = col_character(), #>   genus = col_character(), #>   subgenus = col_character(), #>   subspecies = col_character(), #>   species = col_character(), #>   specificEpithet = col_character(), #>   infraspecificEpithet = col_character(), #>   acceptedNameUsage = col_character(), #>   taxonRank = col_character(), #>   scientificNameAuthorship = col_character(), #>   identificationQualifier = col_character(), #>   higherClassification = col_character(), #>   identificationReferences = col_character(), #>   typeStatus = col_character(), #>   previousIdentifications = col_character(), #>   verbatimIdentification = col_character(), #>   identifiedBy = col_character(), #>   dateIdentified = col_character(), #>   decimalLatitude = col_double(), #>   decimalLongitude = col_double(), #>   verbatimLatitude = col_character(), #>   verbatimLongitude = col_character(), #>   verbatimElevation = col_character(), #>   stateProvince = col_character(), #>   country = col_character(), #>   continent = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   locality = col_character(), #>   island = col_character(), #>   county = col_character(), #>   municipality = col_character(), #>   countryCode = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   license = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   issue = col_character(), #>   eventDate = col_character(), #>   eventTime = col_character(), #>   startDayOfYear = col_integer(), #>   endDayOfYear = col_integer(), #>   day = col_integer(), #>   month = col_integer(), #>   year = col_integer(), #>   basisOfRecord = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   type = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   recordNumber = col_character(), #>   recordedBy = col_character(), #>   eventID = col_character(), #>   Location = col_character(), #>   samplingProtocol = col_character(), #>   samplingEffort = col_character(), #>   fieldNumber = col_character(), #>   individualCount = col_double(), #>   organismQuantity = col_double(), #>   coordinatePrecision = col_double(), #>   coordinateUncertaintyInMeters = col_double(), #>   spatiallyValid = col_logical(), #>   catalogNumber = col_character(), #>   gbifID = col_character(), #>   datasetID = col_character(), #>   institutionCode = col_character(), #>   datasetName = col_character(), #>   otherCatalogNumbers = col_character(), #>   occurrenceID = col_character(), #>   taxonKey = col_character(), #>   coreid = col_character(), #>   recordId = col_character(), #>   collectionID = col_character(), #>   associatedSequences = col_character(), #>   institutionID = col_character(), #>   verbatimScientificName = col_character(), #>   verbatimEventDate = col_character(), #>   associatedTaxa = col_character(), #>   associatedOrganisms = col_character(), #>   fieldNotes = col_character(), #>   sex = col_character(), #>   rights = col_character(), #>   rightsHolder = col_character(), #>   accessRights = col_character(), #>   dctermsLicense = col_character(), #>   dctermsType = col_character(), #>   dctermsAccessRights = col_character(), #>   associatedReferences = col_character(), #>   bibliographicCitation = col_character(), #>   dctermsBibliographicCitation = col_character(), #>   references = col_character(), #>   flags = col_character(), #>   informationWithheld = col_character(), #>   isDuplicateOf = col_character(), #>   hasCoordinate = col_logical(), #>   hasGeospatialIssues = col_logical(), #>   assertions = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceYear = col_datetime(format = \"\"), #>   id = col_character(), #>   duplicateStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   associatedOccurrences = col_character(), #>   locationRemarks = col_character(), #>   dataSource = col_character(), #>   dataBase_scientificName = col_character(), #>   .rou = col_logical(), #>   .val = col_logical(), #>   .equ = col_logical(), #>   .zer = col_logical(), #>   .cap = col_logical(), #>   .cen = col_logical(), #>   .sea = col_logical(), #>   .otl = col_logical(), #>   .gbf = col_logical(), #>   .inst = col_logical(), #>   .dpl = col_logical(), #>   .summary = col_logical(), #>   names_clean = col_character(), #>   verbatim_scientificName = col_character(), #>   .uncer_terms = col_logical(), #>   .eventDate_empty = col_logical(), #>   .year_outOfRange = col_logical(), #>   .duplicates = col_logical(), #>   .lonFlag = col_logical(), #>   .latFlag = col_logical(), #>   .gridSummary = col_logical(), #>   .basisOfRecords_notStandard = col_logical(), #>   .scientificName_empty = col_logical(), #>   .coordinates_empty = col_logical(), #>   .coordinates_outOfRange = col_logical(), #>   coordinates_transposed = col_logical(), #>   country_suggested = col_character(), #>   .countryOutlier = col_logical(), #>   countryMatch = col_character(), #>   .expertOutlier = col_logical(), #>   .occurrenceAbsent = col_logical(), #>   .coordinates_country_inconsistent = col_logical(), #>   .unLicensed = col_logical(), #>   .invalidName = col_logical(), #>   .sequential = col_logical(), #>   idContinuity = col_logical(), #>   .uncertaintyThreshold = col_logical(), #>   .GBIFflags = col_logical(), #>   finalLatitude = col_double(), #>   finalLongitude = col_double(), #>   Source = col_character() #> )    # To add new columns you can write ColTypeR(newCharacterColumn = readr::col_character(),           newNumericColumn = readr::col_integer(),           newLogicalColumn = readr::col_logical())  #> cols_only( #>   database_id = col_character(), #>   scientificName = col_character(), #>   family = col_character(), #>   subfamily = col_character(), #>   genus = col_character(), #>   subgenus = col_character(), #>   subspecies = col_character(), #>   species = col_character(), #>   specificEpithet = col_character(), #>   infraspecificEpithet = col_character(), #>   acceptedNameUsage = col_character(), #>   taxonRank = col_character(), #>   scientificNameAuthorship = col_character(), #>   identificationQualifier = col_character(), #>   higherClassification = col_character(), #>   identificationReferences = col_character(), #>   typeStatus = col_character(), #>   previousIdentifications = col_character(), #>   verbatimIdentification = col_character(), #>   identifiedBy = col_character(), #>   dateIdentified = col_character(), #>   decimalLatitude = col_double(), #>   decimalLongitude = col_double(), #>   verbatimLatitude = col_character(), #>   verbatimLongitude = col_character(), #>   verbatimElevation = col_character(), #>   stateProvince = col_character(), #>   country = col_character(), #>   continent = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   locality = col_character(), #>   island = col_character(), #>   county = col_character(), #>   municipality = col_character(), #>   countryCode = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level0Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Gid = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   level1Name = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   license = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   issue = col_character(), #>   eventDate = col_character(), #>   eventTime = col_character(), #>   startDayOfYear = col_integer(), #>   endDayOfYear = col_integer(), #>   day = col_integer(), #>   month = col_integer(), #>   year = col_integer(), #>   basisOfRecord = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   type = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   recordNumber = col_character(), #>   recordedBy = col_character(), #>   eventID = col_character(), #>   Location = col_character(), #>   samplingProtocol = col_character(), #>   samplingEffort = col_character(), #>   fieldNumber = col_character(), #>   individualCount = col_double(), #>   organismQuantity = col_double(), #>   coordinatePrecision = col_double(), #>   coordinateUncertaintyInMeters = col_double(), #>   spatiallyValid = col_logical(), #>   catalogNumber = col_character(), #>   gbifID = col_character(), #>   datasetID = col_character(), #>   institutionCode = col_character(), #>   datasetName = col_character(), #>   otherCatalogNumbers = col_character(), #>   occurrenceID = col_character(), #>   taxonKey = col_character(), #>   coreid = col_character(), #>   recordId = col_character(), #>   collectionID = col_character(), #>   associatedSequences = col_character(), #>   institutionID = col_character(), #>   verbatimScientificName = col_character(), #>   verbatimEventDate = col_character(), #>   associatedTaxa = col_character(), #>   associatedOrganisms = col_character(), #>   fieldNotes = col_character(), #>   sex = col_character(), #>   rights = col_character(), #>   rightsHolder = col_character(), #>   accessRights = col_character(), #>   dctermsLicense = col_character(), #>   dctermsType = col_character(), #>   dctermsAccessRights = col_character(), #>   associatedReferences = col_character(), #>   bibliographicCitation = col_character(), #>   dctermsBibliographicCitation = col_character(), #>   references = col_character(), #>   flags = col_character(), #>   informationWithheld = col_character(), #>   isDuplicateOf = col_character(), #>   hasCoordinate = col_logical(), #>   hasGeospatialIssues = col_logical(), #>   assertions = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   occurrenceYear = col_datetime(format = \"\"), #>   id = col_character(), #>   duplicateStatus = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), #>   associatedOccurrences = col_character(), #>   locationRemarks = col_character(), #>   dataSource = col_character(), #>   dataBase_scientificName = col_character(), #>   .rou = col_logical(), #>   .val = col_logical(), #>   .equ = col_logical(), #>   .zer = col_logical(), #>   .cap = col_logical(), #>   .cen = col_logical(), #>   .sea = col_logical(), #>   .otl = col_logical(), #>   .gbf = col_logical(), #>   .inst = col_logical(), #>   .dpl = col_logical(), #>   .summary = col_logical(), #>   names_clean = col_character(), #>   verbatim_scientificName = col_character(), #>   .uncer_terms = col_logical(), #>   .eventDate_empty = col_logical(), #>   .year_outOfRange = col_logical(), #>   .duplicates = col_logical(), #>   .lonFlag = col_logical(), #>   .latFlag = col_logical(), #>   .gridSummary = col_logical(), #>   .basisOfRecords_notStandard = col_logical(), #>   .scientificName_empty = col_logical(), #>   .coordinates_empty = col_logical(), #>   .coordinates_outOfRange = col_logical(), #>   coordinates_transposed = col_logical(), #>   country_suggested = col_character(), #>   .countryOutlier = col_logical(), #>   countryMatch = col_character(), #>   .expertOutlier = col_logical(), #>   .occurrenceAbsent = col_logical(), #>   .coordinates_country_inconsistent = col_logical(), #>   .unLicensed = col_logical(), #>   .invalidName = col_logical(), #>   .sequential = col_logical(), #>   idContinuity = col_logical(), #>   .uncertaintyThreshold = col_logical(), #>   .GBIFflags = col_logical(), #>   finalLatitude = col_double(), #>   finalLongitude = col_double(), #>   Source = col_character(), #>   newCharacterColumn = col_character(), #>   newNumericColumn = col_integer(), #>   newLogicalColumn = col_logical() #> )  # Try reading in one of the test datasets as an example: beesFlagged %>% dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) #> # A tibble: 100 × 124 #>    database_id scientificName family subfamily genus subgenus subspecies species #>    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #>  1 Dorey_data… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #>  2 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #>  3 Dorey_data… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #>  4 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #>  5 Dorey_data… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #>  6 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #>  7 Dorey_data… Megachile api… Megac… Megachil… Mega… NA       NA         Megach… #>  8 Dorey_data… Trigona dalla… Apidae Apinae    Trig… NA       NA         Trigon… #>  9 Dorey_data… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… #> 10 Dorey_data… Lasioglossum … Halic… Halictin… Lasi… NA       NA         Lasiog… #> # ℹ 90 more rows #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …   # OR beesRaw %>% dplyr::as_tibble(col_types = BeeBDC::ColTypeR()) #> # A tibble: 100 × 90 #>    database_id scientificName family subfamily genus subgenus subspecies species #>    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #>  1 Dorey_data… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #>  2 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #>  3 Dorey_data… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #>  4 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #>  5 Dorey_data… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #>  6 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #>  7 Dorey_data… Megachile api… Megac… Megachil… Mega… NA       NA         Megach… #>  8 Dorey_data… Trigona dalla… Apidae Apinae    Trig… NA       NA         Trigon… #>  9 Dorey_data… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… #> 10 Dorey_data… Lasioglossum … Halic… Halictin… Lasi… NA       NA         Lasiog… #> # ℹ 90 more rows #> # ℹ 82 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …    # OR, using the bee standard format from:    beesRaw %>% dplyr::as_tibble(col_types = BeeBDC::ColTypeR(standardFormat = \"bee\")) #> # A tibble: 100 × 90 #>    database_id scientificName family subfamily genus subgenus subspecies species #>    <chr>       <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #>  1 Dorey_data… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #>  2 Dorey_data… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #>  3 Dorey_data… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #>  4 Dorey_data… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #>  5 Dorey_data… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #>  6 Paige_data… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #>  7 Dorey_data… Megachile api… Megac… Megachil… Mega… NA       NA         Megach… #>  8 Dorey_data… Trigona dalla… Apidae Apinae    Trig… NA       NA         Trigon… #>  9 Dorey_data… Habropoda mis… Apidae Apinae    Habr… NA       NA         Habrop… #> 10 Dorey_data… Lasioglossum … Halic… Halictin… Lasi… NA       NA         Lasiog… #> # ℹ 90 more rows #> # ℹ 82 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags records with GBIF issues — GBIFissues","title":"Flags records with GBIF issues — GBIFissues","text":"function flag records subject user-specified vector GBIF issues.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags records with GBIF issues — GBIFissues","text":"","code":"GBIFissues(data = NULL, issueColumn = \"issue\", GBIFflags = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags records with GBIF issues — GBIFissues","text":"data data frame tibble. Occurrence records input. issueColumn Character. column look GBIF issues. Default = \"issue\". GBIFflags Character vector. GBIF issues flag. Users may choose vector issues flag use pre-set vector vectors, including c(\"allDates\", \"allMetadata\", \"allObservations\", \"allSpatial\", \"allTaxo\", \"\"). Default = c(\"COORDINATE_INVALID\", \"PRESUMED_NEGATED_LONGITUDE\", \"PRESUMED_NEGATED_LATITUDE\", \"COUNTRY_COORDINATE_MISMATCH\", \"ZERO_COORDINATE\")","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags records with GBIF issues — GBIFissues","text":"Returns data new column, \".GBIFflags\", FALSE = records provided GBIFflags.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/GBIFissues.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags records with GBIF issues — GBIFissues","text":"","code":"# Import the example data data(beesRaw) # Run the function beesRaw_Out <- GBIFissues(data = beesRaw,     issueColumn = \"issue\",     GBIFflags = c(\"COORDINATE_INVALID\", \"ZERO_COORDINATE\"))  #>  - jbd_GBIFissues: #> Flagged 0  #>   The .GBIFflags column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":null,"dir":"Reference","previous_headings":"","what":"Harmonise taxonomy of occurrence data — harmoniseR","title":"Harmonise taxonomy of occurrence data — harmoniseR","text":"Uses BeeBDC-formatted taxonomy data harmonise occurrence records flag match taxonomy harmoniseR() prefers use names_clean columns generated bdc::bdc_clean_names(). required, may find better results running function dataset first. possible download taxonomy file taxa using taxadbToBeeBDC() can download taxonomies ITIS, GBIF, . also match format beesTaxonomy() file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harmonise taxonomy of occurrence data — harmoniseR","text":"","code":"harmoniseR(   data = NULL,   path = NULL,   taxonomy = BeeBDC::beesTaxonomy(),   speciesColumn = \"scientificName\",   rm_names_clean = TRUE,   checkVerbatim = FALSE,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harmonise taxonomy of occurrence data — harmoniseR","text":"data data frame tibble. Occurrence records input. path directory character. path folder output can saved. taxonomy data frame tibble. taxonomy file use. Default = beesTaxonomy(); taxa see first taxadbToBeeBDC(). speciesColumn Character. name column containing species names. Default = \"scientificName\". rm_names_clean Logical. TRUE names_clean column removed end function help reduce confusion column later. Default = TRUE checkVerbatim Logical. TRUE verbatimScientificName checked well species matches. matching done harmoniseR failed name columns. NOTE: column first run bdc::bdc_clean_names. Default = FALSE stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harmonise taxonomy of occurrence data — harmoniseR","text":"occurrences returned update taxonomy columns, including: scientificName, species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, scientificNameAuthorship. new column, .invalidName, also added FALSE occurrence's name match supplied taxonomy.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/HarmoniseR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harmonise taxonomy of occurrence data — harmoniseR","text":"","code":"# load in the test dataset system.file(\"extdata\", \"testTaxonomy.rda\", package=\"BeeBDC\") |> load()  # See also ?BeeBDC::taxadbToBeeBDC()  beesRaw_out <- BeeBDC::harmoniseR(   #The path to a folder that the output can be saved path = tempdir(), # The formatted taxonomy file taxonomy = testTaxonomy,  data = BeeBDC::beesFlagged, speciesColumn = \"scientificName\") #>  - Formatting taxonomy for matching... #>  #>  - Harmonise the occurrence data with unambiguous names... #>  #>  - Attempting to harmonise the occurrence data with ambiguous names... #>  - Formatting merged datasets... #> Removing the names_clean column... #>  - We matched valid names to 96 of 100 occurrence records. This leaves a total of 4 unmatched occurrence records. #>  #> harmoniseR: #> 4 #> records were flagged. #> The column, '.invalidName' was added to the database. #>  #>  - We updated the following columns: scientificName, species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, and scientificNameAuthorship. The previous scientificName column was converted to verbatimScientificName #>  - Completed in 0.22 secs table(beesRaw_out$.invalidName, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>     4    96     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"Replaces publicly available data data manually cleaned error-corrected use paper Chesshire, P. R., Fischer, E. E., Dowdy, N. J., Griswold, T., Hughes, . C., Orr, M. J., . . . McCabe, L. M. (Press). Completeness analysis 3000 United States bee species identifies persistent data gaps. Ecography.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"","code":"PaigeIntegrater(db_standardized = NULL, PaigeNAm = NULL, columnStrings = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"db_standardized data frame tibble. Occurrence records input. PaigeNAm data frame tibble. Paige Chesshire dataset. columnStrings list character vectors. vector set columns used iteratively match public dataset Paige dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"Returns db_standardized (input occurrence records) Paige Chesshire data integrated.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/PaigeIntegrater.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrate manually-cleaned data from Paige Chesshire — PaigeIntegrater","text":"","code":"if (FALSE) { # \\dontrun{ library(dplyr) # set the DataPath to tempdir for this example DataPath <- tempdir() # Integrate Paige Chesshire's cleaned dataset. PaigeNAm <- readr::read_csv(paste(DataPath, \"Paige_data\", \"NorAmer_highQual_only_ALLfamilies.csv\",                                  sep = \"/\"), col_types = ColTypeR()) %>%  # Change the column name from Source to dataSource to match the rest of the data.  dplyr::rename(dataSource = Source) %>%  # add a NEW database_id column  dplyr::mutate(    database_id = paste0(\"Paige_data_\", 1:nrow(.)),    .before = scientificName)   # Set up the list of character vectors to iteratively check for matches with public data. columnList <- list(  c(\"decimalLatitude\", \"decimalLongitude\",     \"recordNumber\", \"recordedBy\", \"individualCount\", \"samplingProtocol\",    \"associatedTaxa\", \"sex\", \"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",    \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 1  c(\"catalogNumber\", \"institutionCode\", \"otherCatalogNumbers\",    \"recordId\", \"occurrenceID\", \"collectionID\"), # Iteration 2  c(\"decimalLatitude\", \"decimalLongitude\",     \"recordedBy\", \"genus\", \"specificEpithet\"), # Iteration 3  c(\"id\", \"decimalLatitude\", \"decimalLongitude\"), # Iteration 4  c(\"recordedBy\", \"genus\", \"specificEpithet\", \"locality\"), # Iteration 5  c(\"recordedBy\", \"institutionCode\", \"genus\",     \"specificEpithet\",\"locality\"),# Iteration 6  c(\"occurrenceID\",\"decimalLatitude\", \"decimalLongitude\"), # Iteration 7  c(\"catalogNumber\",\"decimalLatitude\", \"decimalLongitude\"), # Iteration 8  c(\"catalogNumber\", \"locality\") # Iteration 9 )   # Merge Paige's data with downloaded data db_standardized <- BeeBDC::PaigeIntegrater(  db_standardized = db_standardized,  PaigeNAm = PaigeNAm,  columnStrings = columnList) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Find, import, and format USGS data to Darwin Core — USGS_formatter","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"function finds, imports, formats, creates metadata USGS dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"","code":"USGS_formatter(path, pubDate)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"path character path directory contains USGS data, found using fileFinder(). function look \"USGS_DRO_flat\". pubDate Character. publication date dataset update metadata citation.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"Returns list occurrence data, \"USGS_data\", EML data, \"EML_attributes\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/USGS_formatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find, import, and format USGS data to Darwin Core — USGS_formatter","text":"","code":"if (FALSE) { # \\dontrun{ USGS_data <- USGS_formatter(path = DataPath, pubDate = \"19-11-2022\") } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"Downloads ALA data creates new file path put data. function can also request downloads atlases (see: http://galah.ala.org.au/articles/choosing_an_atlas.html). However, send download email must rest point.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"","code":"atlasDownloader(   path,   userEmail = NULL,   ALA_taxon,   DL_reason = 4,   atlas = \"ALA\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"path character directory. path folder download stored. userEmail character string. email used associated user’s ALA account; user must make ALA account download data. ALA_taxon character string. taxon download ALA. Uses galah::galah_identify() DL_reason Numeric. reason data download according galah::galah_config() atlas Character. atlas download occurrence data - see https://galah.ala.org.au/R/articles/choosing_an_atlas.html details. Note: default \"ALA\" probably atlas work seamlessly rest workflow. However, different atlases can still downloaded doi sent email.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"Completes ALA data download saves data path provided.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/atlasDownloader.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download occurrence data from the Atlas of Living Australia (ALA) — atlasDownloader","text":"","code":"if (FALSE) { # \\dontrun{ atlasDownloader(path = DataPath,                userEmail = \"InsertYourEmail\",                ALA_taxon = \"Apiformes\",                DL_reason = 4)                } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":null,"dir":"Reference","previous_headings":"","what":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"test dataset includes 105 random occurrence records three bee species. included species : \"Agapostemon tyleri Cockerell, 1917\", \"Centris rhodopus Cockerell, 1897\", \"Perdita octomaculata (Say, 1824)\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"","code":"data(\"bees3sp\", package = \"BeeBDC\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full scientific name subspecies name — ALA column specificEpithet species name (specific epithet) infraspecificEpithet subspecies name (intraspecific epithet) acceptedNameUsage full scientific name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName column. scientificNameAuthorship authorship information scientificName column formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts identification. higherClassification list (concatenated separated) taxon names terminating rank immediately superior taxon referenced taxon record. identificationReferences list (concatenated separated) references (e.g. publications, global unique identifier, URI, etc.) used identification occurrence. typeStatus list (concatenated separated) nomenclatural types (e.g. type status, typified scientific name, publication) applied occurrence. previousIdentifications list (concatenated separated) previous assignments names occurrence. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date occurrence identified belonging taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center location. Positive values north Equator, negative values south , valid values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center location. Positive values east Greenwich Meridian, negative values west . Valid values lie -180 180, inclusive. stateProvince name next smaller administrative region country (e.g. state, province, canton, department, region, etc.) location occurrence found. continent name continent location occurrence found. locality specific description place occurrence found. island name island near location occurrence found, applicable. county full, unabbreviated name next smaller administrative region stateProvince (e.g. county, shire, department, etc.) location occurrence found. municipality full, unabbreviated name next smaller administrative region county (e.g. city, municipality, etc.) location occurrence found. use term nearby named place contain actual location occurrence. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate time interval Event occurred. occurrences, time interval event recorded. eventTime time interval Event occurred. day integer day month Event occurred. occurrences, day event recorded. month integer month Event occurred. occurrences, month event recorded. year four-digit year Event occurred, according Common Era Calendar. occurrences, year event recorded. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit location occurrence found. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) percentage biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatimScientificName Scientific name recorded specimen label, necessarily valid. verbatimEventDate verbatim original representation date time information event. occurrences, date-time event recorded noted collector. associatedTaxa list (concatenated separated) identifiers names taxa associations occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations occurrence . fieldNotes One () indicator existence , (b) reference (publication, URI), (c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf code another occerrence specimen. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers occurrence records associations occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name .scientificName_empty Flag produced bdc::bdc_scientificName_empty() FALSE == scientific name provided TRUE means text column. .coordinates_empty Flag produced bdc::bdc_coordinates_empty() FALSE == coordinates provided. .coordinates_outOfRange Flag column produced bdc::bdc_coordinates_outOfRange() FALSE == coordinates represent point Earth. say, function identifies records --range coordinates (-90 90 latitude; -180 180 longitude). .basisOfRecords_notStandard Flag produced bdc::bdc_basisOfRecords_notStandard() FALSE == occurrence basisOfRecord defined acceptable user. country_suggested country name suggested bdc::bdc_country_standardized() function. countryCode country code suggested bdc::bdc_country_standardized() function. coordinates_transposed column indicating coordinates identified transposed function jbd_Ctrans_chunker() FALSE == transposed. .coordinates_country_inconsistent flag generated jbd_coordCountryInconsistent() FALSE == occurrence country name coordinates match. .occurrenceAbsent flag generated flagAbsent() FALSE == occurrences marked \"ABSENT\" \"occurrenceStatus\" column .unLicensed flag generated flagLicense() FALSE == occurrences protected restrictive license. .GBIFflags flag generated GBIFissues() FALSE == occurrence user-specified GBIF issues flag. .uncer_terms flag generated bdc::bdc_clean_names() FALSE == presence taxonomic uncertainty terms. names_clean column made bdc::bdc_clean_names() indicating cleaned scientificName .invalidName flag generated harmoniseR() FALSE == occurrences whose scientificName match Discover Life taxonomy. .rou flag generated CoordinateCleaner::clean_coordinates() FALSE == rounded (probably imprecise) coordinates. .val flag generated CoordinateCleaner::clean_coordinates() FALSE == invalid coordinates. .equ flag generated CoordinateCleaner::clean_coordinates() FALSE == equal coordinates (e.g., 0.1, 0.1). .zer flag generated CoordinateCleaner::clean_coordinates() FALSE == zeros coordinates .cap flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country capital centroid. .cen flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country province centroids. .gbf flag generated CoordinateCleaner::clean_coordinates() FALSE == records around GBIF headquarters. .inst flag generated CoordinateCleaner::clean_coordinates() FALSE == records around biodiversity institutions. .sequential flag generated diagonAlley() FALSE == records possibly result fill-errors sequence. .lonFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding longitude column within dataset. .latFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding latitude column within dataset. .gridSummary flag generated CoordinateCleaner::cd_round() FALSE == potential gridding either longitude latitude columns within dataset. .uncertaintyThreshold flag generated coordUncerFlagR() FALSE == occurrences pass user-specified threshold \"coordinateUncertaintyInMeters\" column. countryMatch column made countryOutlieRs(). Summarises occurrence-level result: species known occur country (noMatch), known bordering country (neighbour), known occur country (exact). .countryOutlier flag generated countryOutlieRs() FALSE == occurrences occur country concurs Discover Life country checklist adjacent country. .sea flag generated countryOutlieRs() FALSE == occurrences ocean. .summary flag generated summaryFun() FALSE == occurrences flagged FALSE .flag columns. example excludes flags \".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\" columns. .eventDate_empty flag generated bdc::bdc_eventDate_empty() FALSE == occurrences eventDate provided. .year_outOfRange flag column generated bdc::bdc_year_outOfRange() FALSE == occurrences older threshold date. case bee dataset used package, lower threshold 1950 .duplicates flag generated dupeSummary() FALSE == occurrences identified duplicates. associated kept duplicate (.duplictes == TRUE) duplicate clusters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"small bee occurrence dataset flags generated BeeBDC can used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"data set created generating random subset 105 rows full BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/bees3sp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A flagged dataset of 105 random bee occurrence records from the three species — bees3sp","text":"","code":"bees3sp <- BeeBDC::bees3sp head(bees3sp) #> # A tibble: 6 × 124 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <lgl>    <lgl>      <chr>   #> 1 Dorey_data_… Agapostemon t… Halic… Halictin… Agap… NA       NA         Agapos… #> 2 Dorey_data_… Agapostemon t… Halic… Halictin… Agap… NA       NA         Agapos… #> 3 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 4 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 5 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> 6 Dorey_data_… Centris rhodo… Apidae Apinae    Cent… NA       NA         Centri… #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <lgl>, #> #   acceptedNameUsage <chr>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <lgl>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a country-level checklist of bees from Discover Life — beesChecklist","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"Download table contains taxonomic country information bees world based data collated Discover Life. data sourced BeeBDC article's Figshare. Note sometimes download might work without restarting R. case, alternatively download dataset URL read using base::readRDS(\"filePath.Rda\"). See beesTaxonomy() context.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"","code":"beesChecklist(   URL =     \"https://figshare.com/ndownloader/files/42320598?private_link=bce1f92848c2ced313ee\",   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"URL character vector FigShare location dataset. default -recent version. ... Extra variables can passed utils::download.file()","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"downloaded beesChecklist.Rda file outPath tibble returned environment. **Column details ** validName valid scientificName occur scientificName column. DiscoverLife_name full country name occurs Discover Life. rNaturalEarth_name Country name rnaturalearth's name_long. shortName short version country name. DiscoverLife_ISO ISO country name occurs Discover Life. Alpha-2 Alpha-2 rnaturalearth. Alpha-3 Alpha-3 rnaturalearth. official Official country name = \"yes\" Discover Life name = \"\". Source text strign denoting source author name-country pair. matchCertainty Quality name's match Discover Life checklist. canonical valid species name without scientificNameAuthority. canonical_withFlags validName without scientificNameAuthority Discover Life flags. family Bee family. subfamily Bee subfamily. genus Bee genus. subgenus Bee subgenus. infraspecies Bee infraSpecificEpithet. species Bee specificEpithet. scientificNameAuthorship Bee scientificNameAuthorship. taxon_rank Rank taxon name. Notes Discover Life country name notes.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"dataset created using Discover Life checklist taxonomy. Dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data. checklist data mostly compiled Discover Life data, www.discoverlife.org: ASCHER, J. S. & PICKERING, J. 2020. Discover Life bee species guide world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesChecklist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a country-level checklist of bees from Discover Life — beesChecklist","text":"","code":"if (FALSE) { # \\dontrun{ beesChecklist <- BeeBDC::beesChecklist() } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesCountrySubset.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple scientificName and country_suggested test dataset — beesCountrySubset","title":"A simple scientificName and country_suggested test dataset — beesCountrySubset","text":"small bee occurrence dataset 1,488 scientificName-country_suggested combinations across four countries; Fiji, Uganda, Vietnam, Zambia.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesCountrySubset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple scientificName and country_suggested test dataset — beesCountrySubset","text":"","code":"data(\"beesCountrySubset\", package = \"BeeBDC\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesCountrySubset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A simple scientificName and country_suggested test dataset — beesCountrySubset","text":"object class \"tibble\" scientificName Full scientificName shown DiscoverLife country_suggested country name suggested bdc::bdc_country_standardized() function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesCountrySubset.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A simple scientificName and country_suggested test dataset — beesCountrySubset","text":"data set created writing paper: Dorey, J.B., (upcoming) many bee species ? quantitative global estimate. Journal","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesCountrySubset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A simple scientificName and country_suggested test dataset — beesCountrySubset","text":"","code":"beesCountrySubset <- BeeBDC::beesCountrySubset head(beesCountrySubset) #> # A tibble: 6 × 2 #>   scientificName                     country_suggested #>   <chr>                              <chr>             #> 1 Xylocopa flavorufa (De Geer, 1778) Zambia            #> 2 Xylocopa flavorufa (De Geer, 1778) Zambia            #> 3 Xylocopa flavorufa (De Geer, 1778) Zambia            #> 4 Xylocopa flavorufa (De Geer, 1778) Uganda            #> 5 Apis mellifera Linnaeus, 1758      Zambia            #> 6 Apis mellifera Linnaeus, 1758      Uganda"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":null,"dir":"Reference","previous_headings":"","what":"A flagged dataset of 100 random bee occurrence records — beesFlagged","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"","code":"data(\"beesFlagged\", package = \"BeeBDC\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full name subspecies name — ALA column specificEpithet species name infraspecificEpithet subspecies name acceptedNameUsage full name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName. scientificNameAuthorship authorship information scientificName formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts Identification. higherClassification list (concatenated separated) taxa names terminating rank immediately superior taxon referenced taxon record.) identificationReferences list (concatenated separated) references (publication, global unique identifier, URI) used Identification. typeStatus list (concatenated separated) nomenclatural types (type status, typified scientific name, publication) applied subject. previousIdentifications list (concatenated separated) previous assignments names Organism. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date subject determined representing Taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values north Equator, negative values south . Legal values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values east Greenwich Meridian, negative values west . Legal values lie -180 180, inclusive. stateProvince name next smaller administrative region country (state, province, canton, department, region, etc.) Location occurs. continent name continent Location occurs. locality specific description place. island name island near Location occurs. county full, unabbreviated name next smaller administrative region stateProvince (county, shire, department, etc.) Location occurs. municipality full, unabbreviated name next smaller administrative region county (city, municipality, etc.) Location occurs. use term nearby named place contain actual location. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate date-time interval Event occurred. occurrences, date-time event recorded. suitable time geological context. eventTime time interval Event occurred. day integer day month Event occurred. month integer month Event occurred. year four-digit year Event occurred, according Common Era Calendar. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit Location occurs. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) percentage biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatim_scientificName verbatim (originally-provided) scientific name verbatimEventDate verbatim original representation date time information Event. associatedTaxa list (concatenated separated) identifiers names taxa associations Occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations Organism . fieldNotes One ) indicator existence , b) reference (publication, URI), c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf Additional information exists, shared given record. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers Occurrence records associations Occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name .scientificName_empty Flag produced bdc::bdc_scientificName_empty() FALSE == scientific name provided TRUE means text column. .coordinates_empty Flag produced bdc::bdc_coordinates_empty() FALSE == coordinates provided. .coordinates_outOfRange Flag produced bdc::bdc_coordinates_outOfRange() FALSE == point earth. function identifies records --range coordinates (-90 90 latitude; -180 180 longitude). .basisOfRecords_notStandard Flag produced bdc::bdc_basisOfRecords_notStandard() FALSE == occurrence basisOfRecord defined acceptable user. country_suggested country name suggested bdc::bdc_country_standardized() function. countryCode country code suggested bdc::bdc_country_standardized() function. coordinates_transposed column indicating coordinates tansposed jbd_Ctrans_chunker() FALSE == transposed. .coordinates_country_inconsistent flag generated jbd_coordCountryInconsistent() FALSE == occurrence country name coordinates match. .occurrenceAbsent flag generated flagAbsent() FALSE == occurrences marked \"ABSENT\" \"occurrenceStatus\" column .unLicensed flag generated flagLicense() FALSE == occurrences protected restrictive license. .GBIFflags flag generated GBIFissues() FALSE == occurrence user-specified GBIF issues flag. .uncer_terms flag generated bdc::bdc_clean_names() FALSE == presence taxonomic uncertainty terms. names_clean column made bdc::bdc_clean_names() indicating cleaned scientificName .invalidName flag generated harmoniseR() FALSE == occurrences whose scientificName match Discover Life taxonomy. .rou flag generated CoordinateCleaner::clean_coordinates() FALSE == rounded (probably imprecise) coordinates. .val flag generated CoordinateCleaner::clean_coordinates() FALSE == invalid coordinates. .equ flag generated CoordinateCleaner::clean_coordinates() FALSE == equal coordinates (e.g., 0.1, 0.1). .zer flag generated CoordinateCleaner::clean_coordinates() FALSE == zeros coordinates .cap flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country capital centroid. .cen flag generated CoordinateCleaner::clean_coordinates() FALSE == records around country province centroids. .gbf flag generated CoordinateCleaner::clean_coordinates() FALSE == records around GBIF headquarters. .inst flag generated CoordinateCleaner::clean_coordinates() FALSE == records around biodiversity institutions. .sequential flag generated diagonAlley() FALSE == records possibly result fill-errors sequence. .lonFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding longitude column within dataset. .latFlag flag generated CoordinateCleaner::cd_round() FALSE == potential gridding latitude column within dataset. .gridSummary flag generated CoordinateCleaner::cd_round() FALSE == potential gridding either longitude latitude columns within dataset. .uncertaintyThreshold flag generated coordUncerFlagR() FALSE == occurrences pass user-specified threshold \"coordinateUncertaintyInMeters\" column. countryMatch column made countryOutlieRs(). Summarises occurrence-level result: species known occur country (noMatch), known bordering country (neighbour), known occur country (exact). .countryOutlier flag generated countryOutlieRs() FALSE == occurrences occur country concurs Discover Life country checklist adjacent country. .sea flag generated countryOutlieRs() FALSE == occurrences ocean. .summary flag generated summaryFun() FALSE == occurrences flagged FALSE .flag columns. example excludes flags \".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\" columns. .eventDate_empty flag generated bdc::bdc_eventDate_empty() FALSE == occurrences eventDate provided. .year_outOfRange flag generated bdc::bdc_year_outOfRange() FALSE == occurrences older threshold date. case 1950. .duplicates flag generated dupeSummary() FALSE == occurrences identified duplicates. associated kept duplicate (.duplictes == TRUE) duplicate clusters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"data set created generating random subset 100 rows full BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesFlagged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A flagged dataset of 100 random bee occurrence records — beesFlagged","text":"","code":"beesFlagged <- BeeBDC::beesFlagged head(beesFlagged) #> # A tibble: 6 × 124 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #> 1 Dorey_data_… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #> 2 Dorey_data_… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #> 3 Dorey_data_… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #> 4 Dorey_data_… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #> 5 Dorey_data_… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #> 6 Paige_data_… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #> # ℹ 116 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":null,"dir":"Reference","previous_headings":"","what":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"small bee occurrence dataset flags generated BeeBDC used run example script test functions. data types, see ColTypeR().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"","code":"data(\"beesRaw\", package = \"BeeBDC\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"object class \"tibble\" database_id Occurrence code generated bdc BeeBDC scientificName Full scientificName shown DiscoverLife family Family name subfamily Subfamily name genus Genus name subgenus Subgenus name subspecies Full name subspecies name — ALA column specificEpithet species name infraspecificEpithet subspecies name acceptedNameUsage full name, authorship date information known, currently valid (zoological) accepted (botanical) taxon. taxonRank taxonomic rank specific name scientificName. scientificNameAuthorship authorship information scientificName formatted according conventions applicable nomenclaturalCode. identificationQualifier brief phrase standard term (\"cf.\", \"aff.\") express determiner's doubts Identification. higherClassification list (concatenated separated) taxa names terminating rank immediately superior taxon referenced taxon record.) identificationReferences list (concatenated separated) references (publication, global unique identifier, URI) used Identification. typeStatus list (concatenated separated) nomenclatural types (type status, typified scientific name, publication) applied subject. previousIdentifications list (concatenated separated) previous assignments names Organism. verbatimIdentification term meant allow capture unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. term meant used addition scientificName (identificationQualifier etc.), instead . identifiedBy list (concatenated separated) names people, groups, organizations assigned Taxon subject. dateIdentified date subject determined representing Taxon. decimalLatitude geographic latitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values north Equator, negative values south . Legal values lie -90 90, inclusive. decimalLongitude geographic longitude (decimal degrees, using spatial reference system given geodeticDatum) geographic center Location. Positive values east Greenwich Meridian, negative values west . Legal values lie -180 180, inclusive. stateProvince name next smaller administrative region country (state, province, canton, department, region, etc.) Location occurs. continent name continent Location occurs. locality specific description place. island name island near Location occurs. county full, unabbreviated name next smaller administrative region stateProvince (county, shire, department, etc.) Location occurs. municipality full, unabbreviated name next smaller administrative region county (city, municipality, etc.) Location occurs. use term nearby named place contain actual location. license legal document giving official permission something resource. issue GBIF-defined issue. eventDate date-time interval Event occurred. occurrences, date-time event recorded. suitable time geological context. eventTime time interval Event occurred. day integer day month Event occurred. month integer month Event occurred. year four-digit year Event occurred, according Common Era Calendar. basisOfRecord specific nature data record. Recommended best practice use standard label one Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation country name country major administrative unit Location occurs. type nature genre resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text. occurrenceStatus statement presence absence Taxon Location. present, absent. recordNumber identifier given Occurrence time recorded. Often serves link field notes Occurrence record, specimen collector's number. recordedBy list (concatenated separated) names people, groups, organizations responsible recording original Occurrence. primary collector observer, especially one applies personal identifier (recordNumber), listed first. eventID identifier set information associated Event (something occurs place time). May global unique identifier identifier specific data set. Location spatial region named place. samplingProtocol names , references , descriptions methods protocols used Event. Examples\tUV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins space: faecal stains reveal location emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001. samplingEffort amount effort expended Event. Examples\t40 trap-nights, 10 observer-hours, 10 km foot, 30 km car. individualCount number individuals present time Occurrence. Integer. organismQuantity number enumeration value quantity organisms. Examples\t27 (organismQuantity) individuals (organismQuantityType). 12.5 (organismQuantity) percentage biomass (organismQuantityType). r (organismQuantity) Braun Blanquet Scale (organismQuantityType). many (organismQuantity) individuals (organismQuantityType). coordinatePrecision decimal representation precision coordinates given decimalLatitude decimalLongitude. coordinateUncertaintyInMeters horizontal distance (meters) given decimalLatitude decimalLongitude describing smallest circle containing whole Location. Leave value empty uncertainty unknown, estimated, applicable (coordinates). Zero valid value term. spatiallyValid Occurrence records ALA can filtered using spatially valid flag. flag combines set tests applied record see reliable spatial data components. catalogNumber identifier (preferably unique) record within data set collection. gbifID identifier assigned GBIF record. datasetID identifier set data. May global unique identifier identifier specific collection institution. institutionCode name (acronym) use institution custody object(s) information referred record. Examples\tMVZ, FMNH, CLO, UCMP. datasetName name identifying data set record derived. otherCatalogNumbers list (concatenated separated) previous alternate fully qualified catalog numbers human-used identifiers Occurrence, whether current data set collection. occurrenceID identifier Occurrence (opposed particular digital record occurrence). absence persistent global unique identifier, construct one combination identifiers record closely make occurrenceID globally unique. taxonKey GBIF-assigned taxon identifier number. collectionID identifier collection dataset record derived. verbatim_scientificName verbatim (originally-provided) scientific name verbatimEventDate verbatim original representation date time information Event. associatedTaxa list (concatenated separated) identifiers names taxa associations Occurrence . associatedOrganisms list (concatenated separated) identifiers Organisms associations Organism . fieldNotes One ) indicator existence , b) reference (publication, URI), c) text notes taken field Event. sex sex biological individual(s) represented Occurrence. rights description usage rights applicable record. rightsHolder person organization owning managing rights resource. accessRights Information can access resource indication security status. associatedReferences list (concatenated separated) identifiers (publication, bibliographic reference, global unique identifier, URI) literature associated Occurrence. bibliographicCitation bibliographic reference resource statement indicating record cited (attributed) used. references related resource referenced, cited, otherwise pointed described resource. informationWithheld Additional information exists, shared given record. isDuplicateOf Additional information exists, shared given record. hasCoordinate Variable indicating presence/absence location coordinates. hasGeospatialIssues Variable indicating validity geospatial data associated record. occurrenceYear Year associated Occurrence. id Variable identifying value Occurrenc. duplicateStatus Variable indicating Occurrence duplicate . associatedOccurrences list (concatenated separated) identifiers Occurrence records associations Occurrence. locationRemarks Comments notes Location. dataSource BeeBDC assigned source data. Often written data formatted BeeBDC::xxx_readr function similar. verbatim_scientificName verbatim (originally-provided) scientific name","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"data set created generating random subset 100 rows full, unfiltered unflagged, BeeBDC dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesRaw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A dataset of 100 random bee occurrence records without flags or filters applied — beesRaw","text":"","code":"beesRaw <- BeeBDC::beesRaw head(beesRaw) #> # A tibble: 6 × 90 #>   database_id  scientificName family subfamily genus subgenus subspecies species #>   <chr>        <chr>          <chr>  <chr>     <chr> <chr>    <lgl>      <chr>   #> 1 Dorey_data_… Pseudoanthidi… Megac… Megachil… Pseu… NA       NA         Pseudo… #> 2 Dorey_data_… Macrotera arc… Andre… Panurgin… Macr… NA       NA         Macrot… #> 3 Dorey_data_… Xanthesma fur… Colle… Euryglos… Xant… NA       NA         Xanthe… #> 4 Dorey_data_… Exomalopsis s… Apidae Apinae    Exom… NA       NA         Exomal… #> 5 Dorey_data_… Osmia bicolor… Megac… Megachil… Osmia NA       NA         Osmia … #> 6 Paige_data_… Augochlorella… Halic… Halictin… Augo… NA       NA         Augoch… #> # ℹ 82 more variables: specificEpithet <chr>, infraspecificEpithet <chr>, #> #   acceptedNameUsage <lgl>, taxonRank <chr>, scientificNameAuthorship <chr>, #> #   identificationQualifier <lgl>, higherClassification <chr>, #> #   identificationReferences <lgl>, typeStatus <chr>, #> #   previousIdentifications <chr>, verbatimIdentification <chr>, #> #   identifiedBy <chr>, dateIdentified <chr>, decimalLatitude <dbl>, #> #   decimalLongitude <dbl>, stateProvince <chr>, continent <chr>, …"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"Downloads taxonomic information bees world. Source taxonomy listed \"source\" mostly derived Discover Life website. data sourced BeeBDC article's Figshare. Note sometimes download might work without restarting R. case, alternatively download dataset URL read using base::readRDS(\"filePath.Rda\").","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"","code":"beesTaxonomy(   URL = \"https://open.flinders.edu.au/ndownloader/files/43331472\",   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"URL character vector FigShare location dataset. default -recent version. ... Extra variables can passed utils::download.file()","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"downloaded beesTaxonomy.Rda file tempdir() tibble returned environment.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"Column details flags Flags comments taxon name. taxonomic_status Taxonomic status. Values \"accepted\" \"synonym\" source Source name. accid id accepted taxon name \"0\" taxonomic_status == accepted. id id number taxon name. kingdom biological kingdom taxon belongs . bees, kingdom == Animalia. phylum biological phylum taxon belongs . bees, phylum == Arthropoda. class biological class taxon belongs . bees, class == Insecta. order biological order taxon belongs . bees, order == Hymenoptera. family family bee species belongs . subfamily subfamily bee species belongs . tribe tribe bee species belongs . subtribe subtribe bee species belongs . validName valid scientific name occur “scientificName” column Darwin Core file. canonical scientificName without scientificNameAuthority. canonical_withFlags scientificName without scientificNameAuthority Discover Life taxonomy flags. genus genus bee species belongs . subgenus subgenus bee species belongs . species specific epithet bee species. infraspecies infraspecific epithet bee addressed. authorship author described bee species. taxon_rank Rank bee taxon addressed entry. notes Additional notes name/taxon.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"dataset created using Discover Life taxonomy. Dataset publication: DOREY, J. B., CHESSHIRE, P. R., BOLAÑOS, . N., O’REILLY, R. L., BOSSERT, S., COLLINS, S. M., LICHTENBERG, E. M., TUCKER, E., SMITH-PARDO, ., FALCON-BRINDIS, ., GUEVARA, D. ., RIBEIRO, B. R., DE PEDRO, D., FISCHER, E., HUNG, J. K.-L., PARYS, K. ., ROGAN, M. S., MINCKLEY, R. L., VELZCO, S. J. E., GRISWOLD, T., ZARRILLO, T. ., SICA, Y., ORR, M. C., GUZMAN, L. M., ASCHER, J., HUGHES, . C. & COBB, N. S. review. globally synthesised flagged bee occurrence dataset cleaning workflow. Scientific Data. taxonomy data mostly compiled Discover Life data, www.discoverlife.org: ASCHER, J. S. & PICKERING, J. 2020. Discover Life bee species guide world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/beesTaxonomy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a nearly complete taxonomy of bees globally — beesTaxonomy","text":"","code":"if (FALSE) { # \\dontrun{ beesTaxonomy <- BeeBDC::beesTaxonomy() } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a chord diagram of duplicate occurrence links — chordDiagramR","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"function outputs figure shows relative size direction occurrence points duplicated data providers, , SCAN, GBIF, ALA, etc. function requires outputs generated dupeSummary().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"","code":"chordDiagramR(   dupeData = NULL,   outPath = NULL,   fileName = NULL,   width = 7,   height = 6,   bg = \"white\",   smallGrpThreshold = 3,   title = \"Duplicated record sources\",   palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",     \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",     \"cartography::purple.pal\", \"cartography::brown.pal\"),   canvas.ylim = c(-1, 1),   canvas.xlim = c(-0.6, 0.25),   text.col = \"black\",   legendX = grid::unit(6, \"mm\"),   legendY = grid::unit(18, \"mm\"),   legendJustify = c(\"left\", \"bottom\"),   niceFacing = TRUE,   self.link = 2 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"dupeData tibble data frame. duplicate file produced dupeSummary(). outPath Character. path directory (folder) output saved. fileName Character. name output file, ending '.pdf'. width Numeric. width figure save (inches). Default = 7. height Numeric. height figure save (inches). Default = 6. bg plot's background colour. Default = \"white\". smallGrpThreshold Numeric. upper threshold sub-dataSources listed \"\". Default = 3. title character string. figure title. Default = \"Duplicated record sources\". palettes vector palettes used. One palette major dataSource \"\" using paletteer package. Default = c(\"cartography::blue.pal\", \"cartography::green.pal\", \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\", \"cartography::purple.pal\", \"cartography::brown.pal\") canvas.ylim Canvas limits circlize::circos.par(). Default = c(-1.0,1.0). canvas.xlim Canvas limits circlize::circos.par(). Default = c(-0.6, 0.25). text.col character string. Text colour legendX x position legends, measured current viewport. Passed ComplexHeatmap::draw(). Default = grid::unit(6, \"mm\"). legendY y position legends, measured current viewport. Passed ComplexHeatmap::draw(). Default = grid::unit(18, \"mm\"). legendJustify character vector declaring justification legends. Passed ComplexHeatmap::draw(). Default = c(\"left\", \"bottom\"). niceFacing TRUE/FALSE. niceFacing option automatically adjusts text facing according positions circle. Passed circlize::highlight.sector(). self.link 1 2 (numeric). Passed circlize::chordDiagram(): self link one sector, 1 means link degenerated 'mountain' width corresponds value connection. 2 means width starting root ending root width corresponds value connection.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"Saves figure provided file path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/chordDiagramR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a chord diagram of duplicate occurrence links — chordDiagramR","text":"","code":"if (FALSE) { # \\dontrun{   # Create a basic example dataset of duplicates to visualise basicData <- dplyr::tribble(                             ~dataSource,    ~dataSource_keep,                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"GBIF_Halictidae\",         \"USGS_data\",                       \"SCAN_Halictidae\",   \"GBIF_Halictidae\",                    \"iDigBio_halictidae\",   \"GBIF_Halictidae\",                    \"iDigBio_halictidae\",   \"SCAN_Halictidae\",                    \"iDigBio_halictidae\",   \"SCAN_Halictidae\",                       \"SCAN_Halictidae\",   \"GBIF_Halictidae\",                        \"iDigBio_apidae\",       \"SCAN_Apidae\",                           \"SCAN_Apidae\",    \"Ecd_Anthophila\",                        \"iDigBio_apidae\",    \"Ecd_Anthophila\",                           \"SCAN_Apidae\",    \"Ecd_Anthophila\",                        \"iDigBio_apidae\",    \"Ecd_Anthophila\",                     \"SCAN_Megachilidae\", \"SCAN_Megachilidae\",                       \"CAES_Anthophila\",   \"CAES_Anthophila\",                       \"CAES_Anthophila\",   \"CAES_Anthophila\"  )    chordDiagramR( dupeData = basicData, outPath = tempdir(), fileName = \"ChordDiagram.pdf\", # These can be modified to help fit the final pdf that's exported. width = 9, height = 7.5, bg = \"white\", # How few distinct dataSources should a group have to be listed as \"other\" smallGrpThreshold = 3, title = \"Duplicated record sources\", # The default list of colour palettes to choose from using the paleteer package palettes = c(\"cartography::blue.pal\", \"cartography::green.pal\",               \"cartography::sand.pal\", \"cartography::orange.pal\", \"cartography::red.pal\",              \"cartography::purple.pal\", \"cartography::brown.pal\"), canvas.ylim = c(-1.0,1.0),  canvas.xlim = c(-0.6, 0.25), text.col = \"black\", legendX = grid::unit(6, \"mm\"), legendY = grid::unit(18, \"mm\"), legendJustify = c(\"left\", \"bottom\"), niceFacing = TRUE)} # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"use function, user must choose column, probably \"coordinateUncertaintyInMeters\" threshold occurrences flagged geographic uncertainty.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"","code":"coordUncerFlagR(   data = NULL,   uncerColumn = \"coordinateUncertaintyInMeters\",   threshold = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"data data frame tibble. Occurrence records input. uncerColumn Character. column flag uncertainty . threshold Numeric. uncertainty threshold. Values equal , greater , threshold flagged.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"input data new column, .uncertaintyThreshold.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/coordUncerFlagR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag occurrences with an uncertainty threshold — coordUncerFlagR","text":"","code":"# Run the function beesRaw_out <- coordUncerFlagR(data = beesRaw,                                uncerColumn = \"coordinateUncertaintyInMeters\",                                threshold = 1000) #> \\coordUncerFlagR: #>  Flagged 15 geographically uncertain records: #>  The column '.uncertaintyThreshold' was added to the database. # View the output table(beesRaw_out$.uncertaintyThreshold, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    15    23    62"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryHarmoniseR.html","id":null,"dir":"Reference","previous_headings":"","what":"Match and harmonise country names — countryHarmoniseR","title":"Match and harmonise country names — countryHarmoniseR","text":"small function useful harmonising country names mathc datasets. relies country names matching one exceptions pre-coded far used internally.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryHarmoniseR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match and harmonise country names — countryHarmoniseR","text":"","code":"countryHarmoniseR(   data = NULL,   countryColumn = NULL,   shorterNames = TRUE,   continentAnalysis = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryHarmoniseR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match and harmonise country names — countryHarmoniseR","text":"data data frame tibble. countryColumn Character. column contains country names harmonised. shorterNames Logical. TRUE, long country names shortened. can helpful writing country names plots long names annoying. continentAnalysis Logical. Set TRUE order match small entities continents; limited use moment.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryHarmoniseR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match and harmonise country names — countryHarmoniseR","text":"Returns original data frame tibble harmonised country names","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryHarmoniseR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Match and harmonise country names — countryHarmoniseR","text":"","code":"# load in the test dataset system.file(\"extdata\", \"testTaxonomy.rda\", package=\"BeeBDC\") |> load() harmonisedCountries <- countryHarmoniseR(   data = testTaxonomy,   countryColumn = \"country_suggested\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix country name issues using a user-input list — countryNameCleanR","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"function basic user manually fix country name inconsistencies.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"","code":"countryNameCleanR(data = NULL, ISO2_table = NULL, commonProblems = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"data data frame tibble. Occurrence records input. ISO2_table data frame tibble columns ISO2 long names country names. Default static version Wikipedia. commonProblems data frame tibble. must two columns: one containing user-identified problem one user-defined fix","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"Returns input data, countries occurring user-supplied problem column (\"commonProblems\") replaced user-supplied fix column","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryNameCleanR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix country name issues using a user-input list — countryNameCleanR","text":"","code":"beesFlagged_out <- countryNameCleanR( data = BeeBDC::beesFlagged, commonProblems = dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',                         'United States','U.S.A','MX','CA','Bras.','Braz.',                         'Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                         fix = c('United States of America','United States of America',                                 'United States of America','United States of America',                                 'United States of America','United States of America',                                 'United States of America','Mexico','Canada','Brazil',                                 'Brazil','Brazil','Northern Mariana Islands','PUERTO.RICO'))) #>  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022."},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag country-level outliers with a provided checklist. — countryOutlieRs","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"function flags country-level outliers using checklist provided package. additional context column names, see beesChecklist().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"","code":"countryOutlieRs(   checklist = NULL,   data = NULL,   keepAdjacentCountry = TRUE,   pointBuffer = NULL,   scale = 50,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"checklist data frame tibble. formatted checklist built based Discover Life website. data data frame tibble. Darwin Core occurrence dataset. keepAdjacentCountry Logical. TRUE, occurrences countries adjacent checklist countries kept. FALSE, flagged. pointBuffer Numeric. buffer around points help align country coastline. provides good way retain points occur right along coast borders maps rnaturalearth scale Numeric. value fed map scale parameter rnaturalearth::ne_countries()'s scale parameter: Scale map return, one 110, 50, 10 'small', 'medium', 'large', smaller numbers higher resolution. WARNING: function tested 110 50. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. cores throw issues, consider setting mc.cores 1. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"input data two new columns, .countryOutlier .sea. three possible values new column: TRUE == passed, FALSE == failed (country ocean), NA == overlap rnaturalearth map.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/countryOutlieRs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag country-level outliers with a provided checklist. — countryOutlieRs","text":"","code":"library(magrittr)   # Load in the test dataset beesRaw <- BeeBDC::beesRaw   # For the sake of this example, use the testChecklist system.file(\"extdata\", \"testChecklist.rda\", package=\"BeeBDC\") |> load()   # For real examples, you might download the beesChecklist from FigShare using    #  [BeeBDC::beesChecklist()]  beesRaw_out <- countryOutlieRs(checklist = testChecklist,                                data = beesRaw %>%                                dplyr::filter(dplyr::row_number() %in% 1:50),                                keepAdjacentCountry = TRUE,                                pointBuffer = 1,                                scale = 50,                                stepSize = 1000000,                                mc.cores = 1) #> Spherical geometry (s2) switched off #>  - Extracting country data from points... #>  - Buffering failed points by pointBuffer... #>  - Prepare the neighbouring country dataset... #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #>  - Compare points with the checklist... #>  - Combining data... #>  - Sorting and removing potentially duplicated buffered points... #>  - Finished.  #> We have matched 25 records to their exact country and 2 to an adjacent country #> We failed to match 0 occurrences to any 'exact' or 'neighbouring' country. #> There are 23 'NA' occurrences for the .countryOutlier column. #>  #> countryOutlieRs: #> Flagged 0  for country outlier and flagged  0  for in the .sea records. #> Three columns were added to the database: #>  1.  The '.countryOutlier' column was added which is a filtering column.  #>  2.  The 'countryMatch' columns indicates exact, neighbour, or noMatch.  #>  3. The '.sea' column was added as a filtering column for points in the ocean.  The '.sea' column includes the user input buffer in its calculation. #>  - Completed in 1.55 secs table(beesRaw_out$.countryOutlier, useNA = \"always\") #>  #> TRUE <NA>  #>   27   23"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a table of data providers for bee occurrence records — dataProvTables","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"function attempt find build table data providers contributed input data, especially using 'institutionCode' column. also look variety columns find data providers using internally set sequence -else statements. Hence, function quite specific bee data, work taxa similar institutions.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"","code":"dataProvTables(   data = NULL,   runBeeDataChecks = FALSE,   outPath = OutPath_Report,   fileName = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"data data frame tibble. Occurrence records input. runBeeDataChecks Logical. TRUE, search columns specific clues determine institution. outPath character path. path directory figure saved. Default = OutPath_Report. fileName Character. name file saved, ending \".csv\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"Returns table data providers, specimen count, species count.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataProvTables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a table of data providers for bee occurrence records — dataProvTables","text":"","code":"data(beesFlagged)  testOut <- dataProvTables( data = beesFlagged, runBeeDataChecks = TRUE, outPath = tempdir(), fileName = \"testFile.csv\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple function to save occurrence AND EML data as a list — dataSaver","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"Used end 1.x example workflow order save occurrence dataset associated eml metadata.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"","code":"dataSaver(   path = NULL,   save_type = NULL,   occurrences = NULL,   eml_files = NULL,   file_prefix = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"path Character. main file path look data . save_type Character. file format save occurrence EML data. Either \"R_file\" \"CSV_file\" occurrences occurrences save data frame tibble. eml_files list EML files. file_prefix Character. prefix resulting output file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"function saves occurrence EML data list save_type = \"R_File\" individual csv files save_type = \"CSV_file\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dataSaver.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple function to save occurrence AND EML data as a list — dataSaver","text":"","code":"if (FALSE) { # \\dontrun{ dataSaver(path = tempdir(),# The main path to look for data in save_type = \"CSV_file\", # \"R_file\" OR \"CSV_file\" occurrences = Complete_data$Data_WebDL, # The existing datasheet eml_files = Complete_data$eml_files, # The existing EML files file_prefix = \"Fin_\") # The prefix for the file name } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":null,"dir":"Reference","previous_headings":"","what":"Find dates in other columns — dateFindR","title":"Find dates in other columns — dateFindR","text":"function made search columns dates add eventDate column. function searches columns locality, fieldNotes, locationRemarks, verbatimEventDate relevant information. Additionally, date ranges eventDate column, translated startDayOfYear endDayOfYear eventDate kept last date, formatted correct format. Ambiguous dates parsed reliably day-month-year month-day-year rounded nearest certainty; month day can identified spelled-month day >12, wil correctly formatted. Year-month-day... -reliable format","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find dates in other columns — dateFindR","text":"","code":"dateFindR(data = NULL, maxYear = lubridate::year(Sys.Date()), minYear = 1700)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find dates in other columns — dateFindR","text":"data data frame tibble. Occurrence records input. maxYear Numeric. maximum year considered reasonable find. Default = lubridate::year(Sys.Date()). minYear Numeric. minimum year considered reasonable find. Default = 1700.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find dates in other columns — dateFindR","text":"function results input occurrence data updated eventDate, year, month, day columns occurrences data ) missing b) located one searched columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dateFindR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find dates in other columns — dateFindR","text":"","code":"# Using the example dataset, you may not find any missing eventDates are rescued (dependent on  # which version of the example dataset the user inputs. beesRaw_out <- dateFindR(data = beesRaw,                          # Years above this are removed (from the recovered dates only)                          maxYear = lubridate::year(Sys.Date()),                          # Years below this are removed (from the recovered dates only)                          minYear = 1700) #>  - Preparing data... #>  - Extracting dates from year, month, day columns... #>  - Extracting dates from fieldNotes, locationRemarks, and verbatimEventDate columns in unambiguous ymd, dmy, mdy, and my formats... #>  - Extracting year from fieldNotes, locationRemarks, and verbatimEventDate columns in ambiguous formats... #>  - Formating and combining the new data.. #>  - Merging all data, nearly there... #>  - Finished.  #> We now have 1 more full eventDate cells than in the input data. #> We modified dates in  #> 89 occurrences. #>  - As it stands, there are 89 complete eventDates and 11 missing dates. #>  - There are also 89 complete year occurrences to filter from. This is up from an initial count of 88 At this rate, you will stand to lose 11 occurrences on the basis of missing year - Operation time: 0.441308259963989 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":null,"dir":"Reference","previous_headings":"","what":"Find fill-down errors — diagonAlley","title":"Find fill-down errors — diagonAlley","text":"simple function looks potential latitude longitude fill-errors identifying consecutive occurrences coordinates regular intervals. accomplished using sliding window length determined minRepeats.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find fill-down errors — diagonAlley","text":"","code":"diagonAlley(   data = NULL,   minRepeats = NULL,   groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),   ndec = 3,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find fill-down errors — diagonAlley","text":"data data frame tibble. Occurrence records input. minRepeats Numeric. minimum number lat lon repeats needed flag record groupingColumns Character. column(s) group analysis search fill-errors within. Default = c(\"eventDate\", \"recordedBy\", \"datasetName\"). ndec Numeric. number decimal places records considered diagonAlley function. fed jbd_coordinates_precision(). Default = 3. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find fill-down errors — diagonAlley","text":"function returns input data new column, .sequential, FALSE = records consecutive latitudes longitudes greater equal user-defined threshold.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find fill-down errors — diagonAlley","text":"sliding window (hence fill-errors) examined within user-defined groupingColumns; columns empty, record excluded.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/diagonAlley.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find fill-down errors — diagonAlley","text":"","code":"# Read in the example data   data(beesRaw)  # Run the function   beesRaw_out <- diagonAlley(     data = beesRaw,     # The minimum number of repeats needed to find a sequence in for flagging     minRepeats = 4,     groupingColumns = c(\"eventDate\", \"recordedBy\", \"datasetName\"),     ndec = 3,     stepSize = 1000000,     mc.cores = 1) #> Removing rounded coordinates with BeeBDC::jbd_coordinates_precision... #> jbd_coordinates_precision: #> Removed 32 records. #> Warning: object 'runningData_LonGrp' not found #>  - Merging results and adding the .sequential column... #>  #> diagonAlley: #> Flagged 0 records #> The .sequential column was added to the database. #>  - Completed in 0.03 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up global directory paths and create folders — dirMaker","title":"Set up global directory paths and create folders — dirMaker","text":"function sets directory saving outputs (.e. data, figures) generated use BeeBDC package, required folders already exist.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up global directory paths and create folders — dirMaker","text":"","code":"dirMaker(   RootPath = RootPath,   ScriptPath = NULL,   DataPath = NULL,   DataSubPath = \"/Data_acquisition_workflow\",   DiscLifePath = NULL,   OutPath = NULL,   OutPathName = \"Output\",   Report = TRUE,   Check = TRUE,   Figures = TRUE,   Intermediate = TRUE,   RDoc = NULL,   useHere = TRUE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up global directory paths and create folders — dirMaker","text":"RootPath character String. RootPath base path project, paths ideally located within RootPath. However, users may specify paths contained RootPath ScriptPath character String. ScriptPath path additional functions like read use BeeBDC. DataPath character string. path folder containing bee occurrence data flagged /cleaned DataSubPath character String. DataPath provided, used DataPath folder name within RootPath. Default \"/Data_acquisition_workflow\" DiscLifePath character String. path folder contains data Ascher Pcikering's Discover Life website. OutPath character String. path folder output data saved. OutPathName character String. name OutPath subfolder located within RootPath. Default \"Output\". Report Logical. TRUE, function creates \"Report\" folder within OutPath-defined folder. Default = TRUE. Check Logical. TRUE, function creates \"Check\" folder within OutPath-defined folder. Default = TRUE. Figures Logical. TRUE, function creates \"Figures\" folder within OutPath-defined folder. Default = TRUE. Intermediate Logical. TRUE, function creates \"Intermediate\" folder within OutPath-defined folder save intermediate datasets. Default = TRUE. RDoc character String. path current script report, relative project root. Passing absolute path raises error. argument used ::i_am() incorrectly setting may result bdc figures saved computer's root directory useHere Logical. TRUE, dirMaker use ::i_am() declare relative path 'RDoc'. aimed preserving functionality bdc saves summary figures tables. Default = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up global directory paths and create folders — dirMaker","text":"Results generation list containing BeeBDC-required directories global environment. function run start session. Additionally, function create BeeBDC-required folders already exist supplied directory","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dirMaker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set up global directory paths and create folders — dirMaker","text":"","code":"# load dplyr   library(dplyr) # Standard/basic usage: RootPath <- tempdir() dirMaker( RootPath = RootPath, # Input the location of the workflow script RELATIVE to the RootPath RDoc = NULL, useHere = FALSE) %>%   # Add paths created by this function to the environment()   list2env(envir = environment())   #>  - We created the /tmp/RtmptRJtSi/BDC_repo/BeeBDC/Rfile. This file needs to have the NewFunctions added to it otherise things won't work. These can be added from our GitHub #>  - We created the /tmp/RtmptRJtSi/Data_acquisition_workflowfile. This file needs to have the occurrence data that you want to use added to it otherise things won't work. Please choose this data or download it from the supp. materials of our paper #> Warning: '/tmp/RtmptRJtSi/BDC_repo/DiscoverLife_Data' already exists #>  - We created the /tmp/RtmptRJtSi/BDC_repo/DiscoverLife_Datafile. This file needs to have the DiscoverLife_Data added to it otherise things won't work. These can be added from our GitHub #> Warning: '/tmp/RtmptRJtSi/Data_acquisition_workflow/Output' already exists #>  - We created the /tmp/RtmptRJtSi/Data_acquisition_workflow/Outputfile. #> <environment: 0x55a622161590>  # Custom OutPathName provided   dirMaker(  RootPath = RootPath,  # Set some custom OutPath info  OutPath = NULL,  OutPathName = \"T2T_Output\",  # Input the location of the workflow script RELATIVE to the RootPath  RDoc = NULL,  useHere = FALSE) %>%    # Add paths created by this function to the environment()    list2env(envir = environment())   #> Warning: '/tmp/RtmptRJtSi/Data_acquisition_workflow/T2T_Output' already exists #>  - We created the /tmp/RtmptRJtSi/Data_acquisition_workflow/T2T_Outputfile. #> <environment: 0x55a621fc5ea8>  # Set the working directory  # Further customisations are also possible dirMaker(   RootPath = RootPath,   ScriptPath = \"...path/Bee_SDM_paper/BDC_repo/BeeBDC/R\",   DiscLifePath = \"...path/BDC_repo/DiscoverLife_Data\",   OutPathName = \"AsianPerspective_Output\",   # Input the location of the workflow script RELATIVE to the RootPath   RDoc = NULL,   useHere = FALSE) %>%   # Add paths created by this function to the environment()   list2env(envir = environment())   #>  - We created the ...path/Bee_SDM_paper/BDC_repo/BeeBDC/Rfile. This file needs to have the NewFunctions added to it otherise things won't work. These can be added from our GitHub #> Warning: '...path/BDC_repo/DiscoverLife_Data' already exists #>  - We created the ...path/BDC_repo/DiscoverLife_Datafile. This file needs to have the DiscoverLife_Data added to it otherise things won't work. These can be added from our GitHub #> Warning: '/tmp/RtmptRJtSi/Data_acquisition_workflow/AsianPerspective_Output' already exists #>  - We created the /tmp/RtmptRJtSi/Data_acquisition_workflow/AsianPerspective_Outputfile. #> <environment: 0x55a621edb5e0>"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a compound bar graph of duplicate data sources — dupePlotR","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"Creates plot two bar graphs. One shows absolute number duplicate records data source shows proportion records duplicated within data source. function requires dataset run dupeSummary().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"","code":"dupePlotR(   data = NULL,   outPath = NULL,   fileName = NULL,   legend.position.inside = c(0.85, 0.8),   base_height = 7,   base_width = 7,   ...,   dupeColours = c(\"#F2D2A2\", \"#B9D6BC\", \"#349B90\"),   returnPlot = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"data data frame tibble. Occurrence records input. outPath Character. path directory (folder) output saved. fileName Character. name output file, ending '.pdf'. legend.position.inside position legend coordinates. Default = c(0.85, 0.8). base_height Numeric. height plot inches. Default = 7. base_width Numeric. width plot inches. Default = 7. ... arguments used change factor levels data sources. dupeColours vector colours levels duplicate, kept duplicate, unique. Default = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"). returnPlot Logical. TRUE, return plot environment. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"Outputs .pdf figure.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupePlotR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a compound bar graph of duplicate data sources — dupePlotR","text":"","code":"# This example will show a warning for the factor levels taht are not present in the specific  # test dataset dupePlotR(   data = beesFlagged,   # The outPath to save the plot as     # Should be something like: #paste0(OutPath_Figures, \"/duplicatePlot_TEST.pdf\"),   outPath = tempdir(),    fileName = \"duplicatePlot_TEST.pdf\",   # Colours in order: duplicate, kept duplicate, unique   dupeColours = c(\"#F2D2A2\",\"#B9D6BC\", \"#349B90\"),   # Plot size and height   base_height = 7, base_width = 7,   legend.position.inside = c(0.85, 0.8),   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'B. Mont.' = \"BMont\", 'B. Minckley' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\", Lic = \"Lic\", Bal = \"Bal\", Arm = \"Arm\"   ) #> Loading required namespace: forcats #> Loading required namespace: cowplot #> Warning: Unknown levels in `f`: CAES, BMont, BMin, Ecd, Gai, EPEL, Lic, Bal, Arm"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifies duplicate occurrence records — dupeSummary","title":"Identifies duplicate occurrence records — dupeSummary","text":"function uses user-specified inputs columns identify duplicate occurrence records. Duplicates identified iteratively tallied , duplicate pairs clustered, sorted end function. function designed work Darwin Core data database_id column, also modifiable work columns.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifies duplicate occurrence records — dupeSummary","text":"","code":"dupeSummary(   data = NULL,   path = NULL,   duplicatedBy = NULL,   completeness_cols = NULL,   idColumns = NULL,   collectionCols = NULL,   collectInfoColumns = NULL,   CustomComparisonsRAW = NULL,   CustomComparisons = NULL,   sourceOrder = NULL,   prefixOrder = NULL,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\",     \".uncertaintyThreshold\", \".unLicensed\"),   characterThreshold = 2,   numberThreshold = 3,   numberOnlyThreshold = 5,   catalogSwitch = TRUE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifies duplicate occurrence records — dupeSummary","text":"data data frame tibble. Occurrence records input. path character path location duplicateRun_ file saved. duplicatedBy character vector. Options c(\"ID\", \"collectionInfo\", \"\"). \"ID\" columns runs series ID-columns defined idColumns. \"collectionInfo\" runs series columns defined collectInfoColumns, checked combination collectionCols. \"\" runs . completeness_cols character vector. set columns used order select duplicates . occurrence, function calculate sum complete.cases(). Within duplicate clusters occurrences greater number completeness_cols filled kept fewer. idColumns character vector. columns checked individually internal duplicates. Intended use ID columns . collectionCols character vector. columns checked combination completeness_cols. collectInfoColumns character vector. columns checked combinatino collectionCols columns. CustomComparisonsRAW list character vectors. Custom comparisons - list columns iteratively compare duplicates. differ CustomComparisons ignore minimum number character thresholds IDs. CustomComparisons list character vectors. Custom comparisons - list columns iteratively compare duplicates. comparisons made character number thresholds accounted ID columns. sourceOrder character vector. order want KEEP duplicated based dataSource column (.e. order prioritize data sources). NOTE: dataSources simplified string prior first \"_\". Hence, \"GBIF_Anthophyla\" becomes \"GBIF.\" prefixOrder character vector. Like sourceOrder, except based database_id prefix, rather dataSource. Additionally, examined prefixOrder != NULL. Default = NULL. dontFilterThese character vector. contain flag columns ignored creation updating .summary column. Passed  summaryFun(). characterThreshold Numeric. complexity threshold ID letter length. minimum number characters need present ADDITION numberThreshold ID number tested duplicates. Ignored CustomComparisonsRAW. columns checked occurrenceID, recordId, id, catalogNumber, otherCatalogNumbers. Default = 2. numberThreshold Numeric. complexity threshold ID number length. minimum number numeric characters need present ADDITION characterThreshold ID number tested duplicates. Ignored CustomComparisonsRAW. columns checked occurrenceID, recordId, id, catalogNumber, otherCatalogNumbers. Default = 3. numberOnlyThreshold Numeric. numberThreshold except characterThreshold ignored. Default = 5. catalogSwitch Logical. TRUE, catalogNumber empty function copy otherCatalogNumbers catalogNumber visa versa. Hence, function attempt matchmore catalog numbers functions can problematic. Default = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifies duplicate occurrence records — dupeSummary","text":"Returns data additional column called .duplicates FALSE occurrences duplicates TRUE occurrences either kept duplicates unique. Also exports .csv user-specified location information duplicate matching. file used functions including manualOutlierFindeR() chordDiagramR()","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/dupeSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifies duplicate occurrence records — dupeSummary","text":"","code":"beesFlagged_out <- dupeSummary( data = BeeBDC::beesFlagged,   # Should start with paste0(DataPath, \"/Output/Report/\"), instead of tempdir(): path = paste0(tempdir(), \"/\"), # options are \"ID\",\"collectionInfo\", or \"both\" duplicatedBy = \"collectionInfo\", # I'm only running ID for the first lot because we might  # recover other info later # The columns to generate completeness info from completeness_cols = c(\"decimalLatitude\",  \"decimalLongitude\",                       \"scientificName\", \"eventDate\"), # idColumns = c(\"gbifID\", \"occurrenceID\", \"recordId\",\"id\"), # The columns to ADDITIONALLY consider when finding duplicates in collectionInfo collectionCols = c(\"decimalLatitude\", \"decimalLongitude\", \"scientificName\", \"eventDate\",                     \"recordedBy\"), # The columns to combine, one-by-one with the collectionCols collectInfoColumns = c(\"catalogNumber\", \"otherCatalogNumbers\"), # Custom comparisons - as a list of columns to compare # RAW custom comparisons do not use the character and number thresholds CustomComparisonsRAW = dplyr::lst(c(\"catalogNumber\", \"institutionCode\", \"scientificName\")), # Other custom comparisons use the character and number thresholds CustomComparisons = dplyr::lst(c(\"gbifID\", \"scientificName\"),                                 c(\"occurrenceID\", \"scientificName\"),                                 c(\"recordId\", \"scientificName\"),                                 c(\"id\", \"scientificName\")), # The order in which you want to KEEP duplicated based on data source # try unique(check_time$dataSource) sourceOrder = c(\"CAES\", \"Gai\", \"Ecd\",\"BMont\", \"BMin\", \"EPEL\", \"ASP\", \"KP\", \"EcoS\", \"EaCO\",                 \"FSCA\", \"Bal\", \"SMC\", \"Lic\", \"Arm\",                 \"USGS\", \"ALA\", \"GBIF\",\"SCAN\",\"iDigBio\"), # !!!!!! BELS > GeoLocate # Set the complexity threshold for id letter and number length # minimum number of characters when WITH the numberThreshold characterThreshold = 2, # minimum number of numbers when WITH the characterThreshold numberThreshold = 3, # Minimum number of numbers WITHOUT any characters numberOnlyThreshold = 5) #> Loading required namespace: igraph #>  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. #> This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. #>  - Updating the .summary column to sort by... #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .uncertaintyThreshold, .unLicensed #>  - summaryFun: #> Flagged 74  #>   The .summary column was added to the database. #>  - Working on CustomComparisonsRAW duplicates... #>  #> Completed iteration 1 of 1: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> catalogNumber, institutionCode, scientificName #>  - Working on CustomComparisons duplicates... #>  #> Completed iteration 1 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> gbifID, scientificName #>  #> Completed iteration 2 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> occurrenceID, scientificName #>  #> Completed iteration 3 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> recordId, scientificName #>  #> Completed iteration 4 of 4: #>  - Identified 0 duplicate records and kept 0 unique records using the column(s):  #> id, scientificName #>  - Working on collectionInfo duplicates... #>  #> Completed iteration 1 of 2: #>  - Identified 0 duplicate records and kept 0 unique records using the columns:  #> decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and catalogNumber #>  #> Completed iteration 2 of 2: #>  - Identified 0 duplicate records and kept 0 unique records using the columns:  #> decimalLatitude, decimalLongitude, scientificName, eventDate, recordedBy, and otherCatalogNumbers #>  - Clustering duplicate pairs... #> Duplicate pairs clustered. There are 0 duplicates across 0 kept duplicates. #>  - Ordering data by 1. dataSource, 2. completeness and 3. .summary column... #>  - Find and FIRST duplicate to keep and assign other associated duplicates to that one (i.e., across multiple tests a 'kept duplicate', could otherwise be removed)... #>  - Duplicates have been saved in the file and location: /tmp/RtmptRJtSi/duplicateRun_collectionInfo_2025-06-19.csv #>  - Across the entire dataset, there are now 0 duplicates from a total of 100 occurrences. #>  - Completed in 0.27 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds files within a directory — fileFinder","title":"Finds files within a directory — fileFinder","text":"function can used find files within user-defined directory based user-provided character string.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds files within a directory — fileFinder","text":"","code":"fileFinder(path, fileName)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds files within a directory — fileFinder","text":"path directory character. directory recursively search. fileName character/regex string. file name find.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds files within a directory — fileFinder","text":"Returns directory -recent file matches provied file Using regex can greatly improve specificity. Using regex can greatly improve specificity. function also write console file found - worthwhile check correct file avoid complications line","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/fileFinder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds files within a directory — fileFinder","text":"","code":"# \\donttest{ # load dplyr library(dplyr)   # Make the RootPath to the tempdir for this example   RootPath <- tempdir()     # Load the example data  data(\"beesRaw\", package = \"BeeBDC\")  # Save and example dataset to the temp dir   readr::write_csv(beesRaw, file = paste0(RootPath, \"/beesRaw.csv\"))   # Now go find it! fileFinder(path = RootPath, fileName = \"beesRaw\") #>  - No dates in file name(s). Finding most-recent from file save time... #>  - Found the following file(s):  #>  /tmp/RtmptRJtSi/beesRaw.csv #> [1] \"/tmp/RtmptRJtSi/beesRaw.csv\" # more specifically the .csv version fileFinder(path = RootPath, fileName = \"beesRaw.csv\") #>  - No dates in file name(s). Finding most-recent from file save time... #>  - Found the following file(s):  #>  /tmp/RtmptRJtSi/beesRaw.csv #> [1] \"/tmp/RtmptRJtSi/beesRaw.csv\" # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags occurrences that are marked as absent — flagAbsent","title":"Flags occurrences that are marked as absent — flagAbsent","text":"Flags occurrences \"ABSENT\" occurrenceStatus (user-specified) column.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags occurrences that are marked as absent — flagAbsent","text":"","code":"flagAbsent(data = NULL, PresAbs = \"occurrenceStatus\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags occurrences that are marked as absent — flagAbsent","text":"data data frame tibble. Occurrence records input. PresAbs Character. column function find \"ABSENT\" \"PRESENT\" records. Default = \"occurrenceStatus\"","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags occurrences that are marked as absent — flagAbsent","text":"input data new column called \".occurrenceAbsent\" FALSE == \"ABSENT\" records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagAbsent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags occurrences that are marked as absent — flagAbsent","text":"","code":"# Bring in the data data(beesRaw)   # Run the function beesRaw_out <- flagAbsent(data = beesRaw, PresAbs = \"occurrenceStatus\") #> \\.occurrenceAbsent: #>  Flagged 8 absent records: #>  One column was added to the database.   # See the result table(beesRaw_out$.occurrenceAbsent, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>     8    92     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag license protected records — flagLicense","title":"Flag license protected records — flagLicense","text":"function search strings indicate record restricted use flag restricted records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag license protected records — flagLicense","text":"","code":"flagLicense(data = NULL, strings_to_restrict = \"all\", excludeDataSource = NULL)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag license protected records — flagLicense","text":"data data frame tibble. Occurrence records input. strings_to_restrict character vector. contain strings used detect protected records. Default =  c(\"Rights Reserved\", \"rights reserved\", \"rights reserved.\", \"ND\", \"public\") excludeDataSource Optional. character vector. vector data sources (dataSource) flagged protected, even . useful private dataset listed  \"rights reserved\" want ignored flag.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flag license protected records — flagLicense","text":"Returns data new column, .unLicensed, FALSE = records protected license.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagLicense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag license protected records — flagLicense","text":"","code":"# Read in the example data data(\"beesRaw\")   # Run the function beesRaw_out <- flagLicense(data = beesRaw,                         strings_to_restrict = \"all\",                         # DON'T flag if in the following data# source(s)                         excludeDataSource = NULL) #> \\.unLicensed: #>  Flagged 0 records that may NOT be used. #>  One column was added to the database."},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads, appends, and saves occurrence flag data — flagRecorder","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"function used save flag data occurrence data run BeeBDC script. read append existing files, asked . flags also saved occurrence file automatically.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"","code":"flagRecorder(   data = NULL,   outPath = NULL,   fileName = NULL,   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   append = NULL,   printSummary = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"data data frame tibble. Occurrence records input. outPath character path. file saved. fileName Character. name file saved idColumns character vector. names columns kept along flag columns. columns useful identifying unique records flags. Default = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"). append Logical. TRUE, find append existing file generated function. printSummary Logical. TRUE, print summary() filter columns - .e. tidyselect::starts_with(\".\")","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"Saves file id flag columns returns object.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagRecorder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loads, appends, and saves occurrence flag data — flagRecorder","text":"","code":"# Load the example data data(\"beesFlagged\")    # Run the function   OutPath_Report <- tempdir() flagFile <- flagRecorder(   data = beesFlagged,   outPath = paste(OutPath_Report, sep =\"\"),   fileName = paste0(\"flagsRecorded_\", Sys.Date(), \".csv\"),   # These are the columns that will be kept along with the flags   idColumns = c(\"database_id\", \"id\", \"catalogNumber\", \"occurrenceID\", \"dataSource\"),   # TRUE if you want to find a file from a previous part of the script to append to   append = FALSE) #>  - .summary column detected. This will be over-written. #>  - Data saved to /tmp/RtmptRJtSi/flagsRecorded_2025-06-19.csv #>  - Selected 34 columns. These include: #> database_id, id, catalogNumber, occurrenceID, dataSource, .scientificName_empty, .coordinates_empty, .coordinates_outOfRange, .basisOfRecords_notStandard, .coordinates_country_inconsistent, .occurrenceAbsent, .unLicensed, .GBIFflags, .uncer_terms, .invalidName, .rou, .val, .equ, .zer, .cap, .cen, .gbf, .inst, .sequential, .lonFlag, .latFlag, .gridSummary, .uncertaintyThreshold, .countryOutlier, .sea, .summary, .eventDate_empty, .year_outOfRange, and .duplicates"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Build a per-species summary for each and all flags — flagSummaryTable","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"Takes flagged dataset returns total number fails (FALSE) per flag (columns starting \".\") per species. ignore .scientificName_empty .invalidName columns species assigned. Users may define column group summary . intended work scientificName column, users may select grouping column (e.g., country).","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"","code":"flagSummaryTable(   data = NULL,   column = \"scientificName\",   outPath = OutPath_Report,   fileName = \"flagTable.csv\",   percentImpacted = TRUE,   percentThreshold = 0 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"data data frame tibble. flagged dataset. column Character. name column group summarise failed occurrences. Default = \"scientificName\". outPath character path. path directory figure saved. Default = OutPath_Report. NULL file saved disk. fileName Character. name file saved, ending \".csv\". Default = \"flagTable.csv\". percentImpacted Logical. TRUE (default), program write percentage species impacted percentThreshold flagging column. percentThreshold Numeric. number 0 100 indicate percent individuals (>; within species) impacted flag, included percentImpacted. Default = 0.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"tibble column flag column (starting \".\") showing number failed (FALSE) occurrences per group. Also shows () total number records, (ii) total number failed records, (iii) percentage failed records.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/flagSummaryTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build a per-species summary for each and all flags — flagSummaryTable","text":"","code":"# Load the toy flagged bee data data(\"beesFlagged\")    # Run the function and build the flag table flagTibble <- flagSummaryTable(data = beesFlagged,                               column = \"scientificName\",                               outPath = paste0(tempdir()),                               fileName = \"flagTable.csv\") #>  - We will flag all columns starting with '.' #>  - summaryFun: #> Flagged 77  #>   The .summary column was added to the database. #> The percentages of species impacted by each flag in your analysis are as follows:  #>   .coordinates_empty = 23.46% #>   .coordinates_outOfRange = 0% #>   .basisOfRecords_notStandard = 1.23% #>   .coordinates_country_inconsistent = 1.23% #>   .occurrenceAbsent = 8.64% #>   .unLicensed = 0% #>   .GBIFflags = 0% #>   .uncer_terms = 0% #>   .rou = 29.63% #>   .val = 0% #>   .equ = 0% #>   .zer = 0% #>   .cap = 0% #>   .cen = 0% #>   .gbf = 0% #>   .inst = 0% #>   .sequential = 0% #>   .lonFlag = 0% #>   .latFlag = 2.47% #>   .gridSummary = 0% #>   .uncertaintyThreshold = 12.35% #>   .countryOutlier = 0% #>   .sea = 1.23% #>   .eventDate_empty = 13.58% #>   .year_outOfRange = 13.58% #>   .duplicates = 56.79%"},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine the formatted USGS data with the main dataset — formattedCombiner","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"Merges Darwin Core version USGS dataset created using USGS_formatter() main dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"","code":"formattedCombiner(path, strings, existingOccurrences, existingEMLs)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"path directory character. directory look formatted USGS data. strings regex string. string find -recent formatted USGS dataset. existingOccurrences data frame. existing occurrence dataset. existingEMLs EML file. existing EML data file appended.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"list combined occurrence dataset updated EML file.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/formattedCombiner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine the formatted USGS data with the main dataset — formattedCombiner","text":"","code":"if (FALSE) { # \\dontrun{ DataPath <- tempdir() strings = c(\"USGS_DRO_flat_27-Apr-2022\")     # Combine the USGS data and the existing big dataset Complete_data <- formattedCombiner(path = DataPath,                                      strings = strings,                                      # This should be the list-format with eml attached                                     existingOccurrences = DataImp$Data_WebDL,                                     existingEMLs = DataImp$eml_files)                                      } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ggRichnessWrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","title":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","text":"BeeBDC::ggRichnessWrapper() takes data output BeeBDC::iNEXTwrapper() BeeBDC::ChaoWrapper() produce plots multiple groups one go. plots can multiple per page across multiple pages.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ggRichnessWrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","text":"","code":"ggRichnessWrapper(   iNEXT_in = country_iNEXT,   iChao_in = NULL,   filterOut = NULL,   type = 1,   se = TRUE,   facet.var = \"None\",   color.var = \"Order.q\",   grey = FALSE,   legendPerPlot = FALSE,   show_iNEXT = TRUE,   showPercent = TRUE,   ChaoColour = \"#55AD9B\",   iNEXTcolour = \"#FD9B63\",   Chao_estimate = \"iChao1 (Chiu et al. 2014)\",   nrow = 3,   ncol = 4,   labels = NULL,   fileName = \"richnessPlots\",   outPath = tempdir(),   base_width = 8.3,   base_height = 11.7,   dpi = 300,   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/ggRichnessWrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","text":"iNEXT_in list iNEXT objects computed BeeBDC::iNEXTwrapper(). iChao_in list R data created BeeBDC::ChaoWrapper(). filterOut Character. list sites/countries exclude plotting; example, sample size inadequate. Default = NULL. type three types plots: sample-size-based rarefaction/extrapolation curve (type = 1); sample completeness curve (type = 2); coverage-based rarefaction/extrapolation curve (type = 3). iNEXT::ggiNEXT() se logical variable display confidence interval around estimated sampling curve. iNEXT::ggiNEXT() facet.var create separate plot value specified variable: separation  (facet.var=\"None\"); separate plot diversity order (facet.var=\"Order.q\"); separate plot assemblage (facet.var=\"Assemblage\"); separate plot combination order x assemblage (facet.var=\"\"). iNEXT::ggiNEXT() color.var create curves different colors values specified variable: curves color (color.var=\"None\"); use different colors diversity orders (color.var=\"Order.q\"); use different colors sites (color.var=\"Assemblage\"); use different colors combinations order x assemblage (color.var=\"\"). iNEXT::ggiNEXT() grey logical variable display grey white ggplot2 theme. iNEXT::ggiNEXT() legendPerPlot Logical. TRUE, remove legend plot. Default = FALSE show_iNEXT Logical. TRUE, show estimate 95% CIs specified iNEXT. Default = TRUE. showPercent Logical. TRUE, show prrcentage increases. Default = TRUE. ChaoColour Character. used graph Chao estimates (95% confidence intervals shown reduced opacity). Default = \"#55AD9B\". iNEXTcolour Character. used graph iNEXT estimates (95% confidence intervals shown reduced opacity). Default = \"#FD9B63\". Chao_estimate Character. name Chao estimate use calculated SpadeR::ChaoSpecies(). options \"Homogeneous Model\",\"Homogeneous (MLE)\", \"Chao1 (Chao, 1984)\",\"Chao1-bc\",\"iChao1 (Chiu et al. 2014)\",\"ACE (Chao & Lee, 1992)\", \"ACE-1 (Chao & Lee, 1992)\",\"1st order jackknife\",\"2nd order jackknife\". Default = \"iChao1 (Chiu et al. 2014)\". nrow Numeric. number rows per figure. Figures (fit nrow*ncol grid) saved additional files. Default = 3. ncol Numeric. number columns per figure. Figures (fit nrow*ncol grid) saved additional files. Default = 4. labels Character. labels sub-plot (, b, c, ...). default NULL, provide labels -z required. fileName Character. Prefix output files. Default = \"richnessPlots\". outPath Character. fodler save plots. Default = tempdir() base_width Numeric. width, inches, save plot. Default = 8.3. base_height Numeric. height, inches, save plot. Default = 11.7. dpi Numeric. Plot resolution. Also accepts string input: \"retina\" (320), \"print\" (300), \"screen\" (72). Applies raster output types. Default = 300. ... arguments passed methods. currently used. iNEXT::ggiNEXT()","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ggRichnessWrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","text":"Saves pdf objects returns summary table levels","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/ggRichnessWrapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ggplot2 extension for a Chao- and iNEXT-wrapper outputs — ggRichnessWrapper","text":"","code":"if (FALSE) { # \\dontrun{  data(beesCountrySubset)     # Transform data for iNEXT  data_nextWrapper <- beesCountrySubset %>%    dplyr::group_by(scientificName, country_suggested) %>%    dplyr::count()       # Calculate iNEXT with the wrapper function  output_iNEXTwrapper <- BeeBDC::iNEXTwrapper(data = data_nextWrapper,                                              variableColumn = \"country_suggested\",                                              valueColumn = \"n\",                                              mc.cores = 1)   # Transform data for iChao data_iChao <- beesCountrySubset %>%   dplyr::group_by(scientificName, country_suggested) %>%   dplyr::count() %>%   dplyr::select(scientificName, country_suggested, n) %>%   tidyr::pivot_wider(names_from = country_suggested,                      values_from = n,                      values_fill = 0) %>%   ## Create the rownames   tibble::column_to_rownames(\"scientificName\") %>%   dplyr::tibble()      # Run the wrapper function output_iChaowrapper <- BeeBDC::ChaoWrapper(data = data_iChao,                                              datatype = \"abundance\",                                              k = 10,                                              conf = 0.95,                                              mc.cores = 1)                                                  # Make the plots!  plot_summary <- BeeBDC::ggRichnessWrapper( iNEXT_in = output_iNEXTwrapper, iChao_in = output_iChaowrapper, nrow = 2, ncol = 2, labels = NULL, fileName = \"speciesRichnessPlots\", outPath = tempdir(), base_width = 8.3, base_height = 11.7,  dpi = 300)        } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/iNEXTwrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","title":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","text":"wrapper iNEXT::iNEXT() interpolate extrapolate Hill numbers order q (rarify species richness). wrapper ability estimate species richness multiple sites (countries) using multiple cores.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/iNEXTwrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","text":"","code":"iNEXTwrapper(   data = NULL,   variableColumn = \"groupVariable\",   valueColumn = \"n\",   q = 0,   datatype = \"abundance\",   conf = 0.95,   se = TRUE,   nboot = 50,   size = NULL,   endpoint = NULL,   knots = 40,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/iNEXTwrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","text":"data data frame tibble. data frame containing \"abundance\"-type data per variable (population, country, species...) columns. variableColumn Character. column used group data. Probably \"country\" \"site\". Default =  \"groupVariable\". valueColumn Character. column containing count data. Defualt =  \"n\". q number vector specifying richness order(s) Hill numbers. datatype data type input data: individual-based abundance data (datatype = \"abundance\"), sampling-unit-based incidence frequencies data (datatype = \"incidence_freq\") species sampling-units incidence matrix (datatype = \"incidence_raw\"). conf positive number < 1 specifying level confidence interval; default 0.95. se logical variable calculate bootstrap standard error conf confidence interval. nboot integer specifying number replications; default 50. size integer vector sample sizes (number individuals sampling units) richness estimates computed. NULL, richness estimates computed sample sizes determined specified/default endpoint knots. endpoint integer specifying sample size endpoint rarefaction/extrapolation. NULL, endpoint = double reference sample size. knots integer specifying number equally-spaced knots (say K, default 40) size 1 endpoint; knot represents particular sample size richness estimate calculated. endpoint smaller reference sample size, iNEXT() computes rarefaction esimates approximately K evenly spaced knots. endpoint larger reference sample size, iNEXT() computes rarefaction estimates approximately K/2 evenly spaced knots sample size 1 reference sample size, computes extrapolation estimates approximately K/2 evenly spaced knots reference sample size endpoint. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/iNEXTwrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","text":"Returns list containing two tibbles. first tibble concatenates outputs basic data rare species information columns per input variable (column). second tibble concatenates various species richness estimates, input variables chunks rows. Additionally console output list variables (columns) lacked sufficient data analysed.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/iNEXTwrapper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel estimation of species richness in a community using iNEXT — iNEXTwrapper","text":"","code":"if (FALSE) { # \\dontrun{   # Read in some example data and use [BeeBDC::richnessPrepR()] to create the example input data  #' data(beesCountrySubset)  estimateDataExample <- BeeBDC::richnessPrepR(   data = beesCountrySubset,   # Download the taxonomy   taxonomyFile = BeeBDC::beesTaxonomy(),   # Download the checklist   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\",   limitGlobal = NULL,   outPath = tempdir() )    # In this function we can directly feed in estimateDataExample$site_speciesCounts   iNextOut <- iNEXTwrapper(data = estimateDataExample$site_speciesCounts,                           variableColumn = \"country_suggested\",                           valueColumn = \"n\",                           q = 0,                           datatype = \"abundance\",                           conf = 0.95,                           se = TRUE,                           nboot = 50,                           size = NULL,                           endpoint = NULL,                           knots = 40,                           mc.cores = 1) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":null,"dir":"Reference","previous_headings":"","what":"Attempt to match database_ids from a prior run — idMatchR","title":"Attempt to match database_ids from a prior run — idMatchR","text":"function attempts match database_ids prior bdc BeeBDC run order keep column somewhat consistent iterations. However, records contain sufficient information work flawlessly.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attempt to match database_ids from a prior run — idMatchR","text":"","code":"idMatchR(   currentData = NULL,   priorData = NULL,   matchBy = NULL,   completeness_cols = NULL,   excludeDataset = NULL )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attempt to match database_ids from a prior run — idMatchR","text":"currentData data frame tibble. NEW occurrence records input. priorData data frame tibble. PRIOR occurrence records input. matchBy list character vectors contain columns iteratively compare. completeness_cols character vector. columns check completeness, arrange, assign relevant prior database_id. excludeDataset character vector. dataSources excluded data matching. static dataSources minor providers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attempt to match database_ids from a prior run — idMatchR","text":"input data frame returned updated database_id column shows database_ids priorData matched. Additionally, columnd called idContinuity returned TRUE indicates match prior database_id FALSE indicates new database_id assigned.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/idMatchR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Attempt to match database_ids from a prior run — idMatchR","text":"","code":"# Get the example data data(\"beesRaw\", package = \"BeeBDC\") # Which datasets are static and should be excluded from matching? excludeDataset <- c(\"BMin\", \"BMont\", \"CAES\", \"EaCO\", \"Ecd\", \"EcoS\",                     \"Gai\", \"KP\", \"EPEL\", \"USGS\", \"FSCA\", \"SMC\", \"Bal\", \"Lic\", \"Arm\", \"BBD\",                      \"MEPB\")   # Match the data to itself just as an example of running the code. beesRaw_out <- idMatchR(   currentData = beesRaw,   priorData = beesRaw,   # First matches will be given preference over later ones   matchBy = dplyr::lst(c(\"gbifID\"),                         c(\"catalogNumber\", \"institutionCode\", \"dataSource\"),                         c(\"occurrenceID\", \"dataSource\"),                         c(\"recordId\", \"dataSource\"),                         c(\"id\"),                         c(\"catalogNumber\", \"institutionCode\")),   # You can exclude datasets from prior by matching their prefixs - before first underscore:   excludeDataset = excludeDataset) #> Warning message:  #>  - No completeness_cols provided. Using default of: c('decimalLatitude',  'decimalLongitude', 'scientificName', and 'eventDate') #>  - Generating a basic completeness summary from the decimalLatitude, decimalLongitude, scientificName, eventDate columns. #> This summary is simply the sum of complete.cases in each column. It ranges from zero to the N of columns. This will be used to sort duplicate rows and select the most-complete rows. #>  - Starting core loop... #>  - we matched 47 records using gbifID. #> This leaves 51 unmatched data in the priorData file #>  - we matched 45 records using catalogNumber, institutionCode, dataSource. #> This leaves 6 unmatched data in the priorData file #>  - we matched 4 records using occurrenceID, dataSource. #> This leaves 2 unmatched data in the priorData file #>  - we matched 0 records using recordId, dataSource. #> This leaves 2 unmatched data in the priorData file #>  - we matched 1 records using id. #> This leaves 1 unmatched data in the priorData file #>  - we matched 0 records using catalogNumber, institutionCode. #> This leaves 1 unmatched data in the priorData file #>  - Combining ids and assigning new ones where needed... #>  - We matched a total of 97 database_id numbers. We then assigned new database_id numbers to 1 unmatched occurrences."},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":null,"dir":"Reference","previous_headings":"","what":"Imports the most-recent repoMerge data — importOccurrences","title":"Imports the most-recent repoMerge data — importOccurrences","text":"Looks imports -recent version occurrence data created repoMerge() function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imports the most-recent repoMerge data — importOccurrences","text":"","code":"importOccurrences(path = path, fileName = \"^BeeData_\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imports the most-recent repoMerge data — importOccurrences","text":"path directory character. directory recursively look data. fileName Character. String text look -recent dataset. Default = \"^BeeData_\". Find faults modifying fileFinder() logic-checking file found.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Imports the most-recent repoMerge data — importOccurrences","text":"list data frame merged occurrence records, \"Data_WebDL\", list EML files contained \"eml_files\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/importOccurrences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imports the most-recent repoMerge data — importOccurrences","text":"","code":"if (FALSE) { # \\dontrun{ DataImp <- importOccurrences(path = DataPath) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates interactive html maps for species — interactiveMapR","title":"Creates interactive html maps for species — interactiveMapR","text":"Uses occurrence data (preferably uncleaned) outputs interactive .html maps can opened browser specific directory. maps can highlight occurrence passed filtering (.summary == TRUE) failed least one filter (.summary == FALSE). can modified first running summaryFun() set columns want highlighted. can also highlight occurrences flagged expert-identified country outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates interactive html maps for species — interactiveMapR","text":"","code":"interactiveMapR(   data = NULL,   outPath = NULL,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   speciesColumn = \"scientificName\",   speciesList = NULL,   countryList = NULL,   jitterValue = NULL,   onlySummary = TRUE,   overWrite = TRUE,   TrueAlwaysTop = FALSE,   excludeApis_mellifera = TRUE,   pointColours = c(\"blue\", \"darkred\", \"#ff7f00\", \"black\"),   returnPlot = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates interactive html maps for species — interactiveMapR","text":"data data frame tibble. Occurrence records use input. outPath directory character. Directory save output maps. lon Character. name longitude column. Default = \"decimalLongitude\". lat Character. name latitude column. Default = \"decimalLatitude\". speciesColumn Character. name column containing species names (another factor) build individual maps . Default = \"scientificName\". speciesList character vector. contain species names appear speciesColumn make maps . User can also specify \"\" order make maps species present data. Hence, user may first filter data use \"\". countryList character vector. Country names map, NULL map countries. jitterValue Numeric. amount, decimal degrees, jitter map points - important separating stacked points coordinates. onlySummary Logical. TRUE, function look plot country expert-identified outliers different colours. overWrite Logical. TRUE, function overwrite existing files provided directory name. Default = TRUE. TrueAlwaysTop TRUE, quality (TRUE) points always displayed top points. FALSE, whichever layer turned -recently displayed top. excludeApis_mellifera Logical. TRUE, map records Apis mellifera. Note: cases . mellifera many points, resulting map take long time make difficult open. Default = TRUE. pointColours character vector colours. order provide colour TRUE, FALSE, countryOutlier, customOutlier. Default = c(\"blue\", \"darkred\",\"#ff7f00\", \"black\"). returnPlot Logical. TRUE, return plot environment. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates interactive html maps for species — interactiveMapR","text":"Exports .html interactive maps bee occurrences specified directory.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/interactiveMapR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates interactive html maps for species — interactiveMapR","text":"","code":"OutPath_Figures <- tempdir()  interactiveMapR( # occurrence data - start with entire dataset, filter down to these species data = BeeBDC::bees3sp, # %>%   # Select only those species in the 100 randomly chosen   # dplyr::filter(scientificName %in% beeData_interactive$scientificName),   # Select only one species to map   # dplyr::filter(scientificName %in% \"Agapostemon sericeus (Forster, 1771)\"), # Directory where to save files outPath = paste0(OutPath_Figures, \"/interactiveMaps_TEST\"), # lat long columns lon = \"decimalLongitude\", lat = \"decimalLatitude\", # Occurrence dataset column with species names speciesColumn = \"scientificName\", # Which species to map - a character vector of names or \"ALL\" # Note: \"ALL\" is defined AFTER filtering for country speciesList = \"ALL\", # studyArea countryList = NULL,  # Point jitter to see stacked points - jitters an amount in decimal degrees jitterValue = 0.01, # If TRUE, it will only map the .summary column. Otherwise, it will map .summary # which will be over-written by countryOutliers and manualOutliers onlySummary = TRUE, excludeApis_mellifera = TRUE, overWrite = TRUE,   # Colours for points which are flagged as TRUE, FALSE, countryOutlier, and customOutlier pointColours = c(\"blue\", \"darkred\",\"#ff7f00\", \"black\") ) #> Loading required namespace: leaflet #> The column .expertOutlier was not found. One will be created with all values = TRUE."},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":null,"dir":"Reference","previous_headings":"","what":"Get country names from coordinates — jbd_CfC_chunker","title":"Get country names from coordinates — jbd_CfC_chunker","text":"bdc::bdc_country_from_coordinates() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_country_from_coordinates().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get country names from coordinates — jbd_CfC_chunker","text":"","code":"jbd_CfC_chunker(   data = NULL,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   stepSize = 1e+06,   chunkStart = 1,   scale = \"medium\",   path = tempdir(),   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get country names from coordinates — jbd_CfC_chunker","text":"data data frame tibble. Occurrence records use input. lat Character. name column use latitude. Default = \"decimalLatitude\". lon Character. name column use longitude. Default = \"decimalLongitude\". country Character. name column containing country names. Default = \"country. stepSize Numeric. number occurrences process chunk. Default = 1000000. chunkStart Numeric. chunk number start . can > 1 need restart function certain chunk. example, can used R failed unexpectedly. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". path Character. directory path folder save running countrylist csv file. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get country names from coordinates — jbd_CfC_chunker","text":"data frame containing database_ids country column needs re-merged data input.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_CfC_chunker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get country names from coordinates — jbd_CfC_chunker","text":"","code":"library(\"dplyr\") data(beesFlagged) HomePath = tempdir() # Tibble of common issues in country names and their replacements commonProblems <- dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES', 'United States','U.S.A','MX','CA','Bras.','Braz.','Brasil','CNMI','USA TERRITORY: PUERTO RICO'),                                  fix = c('United States of America','United States of America',                                  'United States of America','United States of America',                                  'United States of America','United States of America',                                  'United States of America','Mexico','Canada','Brazil','Brazil',                                  'Brazil','Northern Mariana Islands','Puerto Rico'))                                   beesFlagged <- beesFlagged %>%       # Replace a name to test    dplyr::mutate(country = stringr::str_replace_all(country, \"Brazil\", \"Brasil\"))  beesFlagged_out <- countryNameCleanR(   data = beesFlagged,   commonProblems = commonProblems) #>  - Using default country names and codes from https:en.wikipedia.org/wiki/ISO_3166-1_alpha-2 - static version from July 2022.  suppressWarnings(   countryOutput <- jbd_CfC_chunker(data = beesFlagged_out,                                    lat = \"decimalLatitude\",                                    lon = \"decimalLongitude\",                                    country = \"country\",                                    # How many rows to process at a time                                    stepSize = 1000000,                                    # Start row                                    chunkStart = 1,                                    path = HomePath,                                    scale = \"medium\"),   classes = \"warning\") #>  - Running chunker with: #> stepSize = 1,000,000 #> chunkStart = 1 #> chunkEnd = 1,000,000 #>  - Starting parallel operation. Unlike the serial operation (mc.cores = 1) , a parallel operation will not provide running feedback. Please be patient  as this function may take some time to complete. Each chunk will be run on  a seperate thread so also be aware of RAM usage. #> Loading required package: rnaturalearth #>  - Completed in 0.29 secs #>  - We have updated the country names of 5 occurrences that previously had no country name assigned.   # Left join these datasets beesFlagged_out <- left_join(beesFlagged_out, countryOutput, by = \"database_id\")  %>%    # merge the two country name columns into the \"country\" column   dplyr::mutate(country = dplyr::coalesce(country.x, country.y)) %>%   # remove the now redundant country columns    dplyr::select(!c(country.x, country.y)) %>%   # put the column back    dplyr::relocate(country) %>%    # Remove duplicates if they arose!   dplyr::distinct()  # Remove illegal characters beesFlagged_out$country <- beesFlagged_out$country %>%   stringr::str_replace(., pattern = paste(\"\\\\[\", \"\\\\]\", \"\\\\?\",                                           sep=  \"|\"), replacement = \"\")"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":null,"dir":"Reference","previous_headings":"","what":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","title":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","text":"jbd_coordinates_transposed() function RAM-intensive, wrapper allows user specify chunk-sizes analyse small portion occurrence data time. prefix jbd_ used highlight difference function original bdc::bdc_coordinates_transposed(). function preferably use countryCode column generated bdc::bdc_country_standardized().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","text":"","code":"jbd_Ctrans_chunker(   data = NULL,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   idcol = \"databse_id\",   country = \"country_suggested\",   countryCode = \"countryCode\",   sci_names = \"scientificName\",   border_buffer = 0.2,   save_outputs = TRUE,   stepSize = 1e+06,   chunkStart = 1,   progressiveSave = TRUE,   path = tempdir(),   append = TRUE,   scale = \"large\",   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","text":"data data frame tibble. Occurrence records input. lat Character. column latitude decimal degrees. Default = \"decimalLatitude\". lon Character. column longitude decimal degrees. Default = \"decimalLongitude\". idcol Character. column name unique record identifier. Default = \"database_id\". country Character. name column containing country names. Default = \"country\". countryCode Character. Identifies column containing ISO-2 country codes Default = \"countryCode\". sci_names Character. column containing scientific names. Default = \"scientificName\". border_buffer Numeric. buffer, decimal degrees, around points help match countries. Default = 0.2 (~22 km equator). save_outputs Logical. TRUE, transposed occurrences saved file. stepSize Numeric. number occurrences process chunk. Default = 1000000. chunkStart Numeric. chunk number start . can > 1 need restart function certain chunk; example R failed unexpectedly. progressiveSave Logical. TRUE country output list saved iteration append can used function stopped part way . path Character. path file save 01_coordinates_transposed_ output. append Logical. TRUE, function look append existing file. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". mc.cores Numeric. > 1, jbd_correct_coordinates function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.#'","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","text":"Returns input data frame new column, coordinates_transposed, FALSE = columns coordinates transposed.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_Ctrans_chunker.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wraps jbd_coordinates_transposed to identify and fix transposed occurrences — jbd_Ctrans_chunker","text":"","code":"library(dplyr)   # Import and prepare the data data(beesFlagged) beesFlagged <- beesFlagged %>% dplyr::select(!c(.val, .sea)) %>%   # Cut down the dataset to un example quicker dplyr::filter(dplyr::row_number() %in% 1:20)   # Run the function beesFlagged_out <- jbd_Ctrans_chunker( # bdc_coordinates_transposed inputs data = beesFlagged, idcol = \"database_id\", lat = \"decimalLatitude\", lon = \"decimalLongitude\", country = \"country_suggested\", countryCode = \"countryCode\", # in decimal degrees (~22 km at the equator) border_buffer = 1,  save_outputs = FALSE, sci_names = \"scientificName\", # chunker inputs # How many rows to process at a time stepSize = 1000000,   # Start row chunkStart = 1,   # Progressively save the output between each iteration? progressiveSave = FALSE, path = tempdir(), # If FALSE it may overwrite existing dataset append = FALSE,   # Users should select scale = \"large\" as it is more thoroughly tested scale = \"medium\", mc.cores = 1 )  #>  - Running chunker with: #> stepSize = 1,000,000 #> chunkStart = 1 #> chunkEnd = 1,000,000 #> append = FALSE #>  - Starting chunk 1... #> From 1 to 1,000,000 #> Loading required package: readr #> Spherical geometry (s2) switched on #> Correcting latitude and longitude transposed #> 0 occurrences will be tested #> No latitude and longitude were transposed #>  - Finished chunk 1 of 1. Total records examined: 20 #>  - Completed in 3.86 secs table(beesFlagged_out$coordinates_transposed, useNA = \"always\") #>  #> TRUE <NA>  #>   20    0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"Compares stated country name occurrence record record’s coordinates using rnaturalearth data. prefix, jbd_ meant distinguish function original bdc::bdc_coordinates_country_inconsistent(). functions preferably use countryCode country_suggested columns generated bdc::bdc_country_standardized(); please run dataset prior running function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"","code":"jbd_coordCountryInconsistent(   data = NULL,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   scale = 50,   pointBuffer = 0.01,   stepSize = 1e+06,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"data data frame tibble. Occurrence records input. lon Character. name column use longitude. Default = \"decimalLongitude\". lat Character. name column use latitude. Default = \"decimalLatitude\". scale Numeric character. passed rnaturalearth::ne_countries()'s scale. Scale map return, one 110, 50, 10 “small”, “medium”, “large”. Smaller values return higher-resolution maps. pointBuffer Numeric. Amount buffer points, decimal degrees. point outside country, within point buffer, flagged. Default = 0.01. stepSize Numeric. number occurrences process chunk. Default = 1000000. mc.cores Numeric. > 1, st_intersects function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"input occurrence data new column, .coordinates_country_inconsistent","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordCountryInconsistent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags coordinates that are inconsistent with the stated country name — jbd_coordCountryInconsistent","text":"","code":"beesRaw_out <- jbd_coordCountryInconsistent(   data = BeeBDC::beesRaw,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",   scale = 50,   pointBuffer = 0.01) #> No '.coordinates_outOfRange' column found, running bdc_coordinates_outOfRange... #>  #> bdc_coordinates_outOfRange: #> Flagged 0 records. #> One column was added to the database. #> No '.coordinates_empty' column found, running bdc_coordinates_empty #>  #> bdc_coordinates_empty: #> Flagged 23 records. #> One column was added to the database. #> No 'country_suggested' column found, adding an empty (NA) placeholder. This column can be added by running bdc::bdc_country_standardized() on the input data. #> No 'countryCode' column found, adding an empty (NA) placeholder. This column can be added by running bdc::bdc_country_standardized() on the input data. #>  - Downloading naturalearth map... #> Spherical geometry (s2) switched off #>  - Extracting initial country names without buffer... #>  - Buffering naturalearth map by pointBuffer... #> dist is assumed to be in decimal degrees (arc_degrees). #>  - Extracting FAILED country names WITH buffer... #>  #> jbd_coordinates_country_inconsistent: #> Flagged 2 records. #> The column, '.coordinates_country_inconsistent', was added to the database. #>  - Completed in 0.85 secs"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Flags coordinates for imprecision — jbd_coordinates_precision","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"function flags occurrences latitude longitude values rounded. contrasts original function, bdc::bdc_coordinates_precision() flag occurrences one latitude longitude rounded. BeeBDC approach saves occurrences may terminal zeros rounded one coordinate column.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"","code":"jbd_coordinates_precision(   data,   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   ndec = NULL,   quieter = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"data data frame tibble. Occurrence records input. lat Character. name column use latitude. Default = \"decimalLatitude\". lon Character. name column use longitude. Default = \"decimalLongitude\". ndec Numeric. number decimal places flag decimal degrees. example, argument value 2 flag occurrences nothing hundredths place (0.0x). quieter Logical. TRUE, functino run little quieter. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"Returns input data frame new column, .rou, FALSE indicates occurrences failed test.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_precision.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flags coordinates for imprecision — jbd_coordinates_precision","text":"","code":"beesRaw_out <- jbd_coordinates_precision(   data = BeeBDC::beesRaw,   lon = \"decimalLongitude\",   lat = \"decimalLatitude\",     # number of decimals to be tested   ndec = 2 ) #> jbd_coordinates_precision: #> Flagged 30 records #> The '.rou' column was added to the database. table(beesRaw_out$.rou, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    30    70     0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify transposed geographic coordinates — jbd_coordinates_transposed","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"function flags corrects records latitude longitude appear transposed. function preferably use countryCode column generated bdc::bdc_country_standardized().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"","code":"jbd_coordinates_transposed(   data,   idcol = \"database_id\",   sci_names = \"scientificName\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country\",   countryCode = \"countryCode\",   border_buffer = 0.2,   save_outputs = FALSE,   fileName = NULL,   scale = \"large\",   path = NULL,   mc.cores = 1 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"data data frame tibble. Containing unique identifier record, geographical coordinates, country names. Coordinates must expressed decimal degrees WGS84. idcol character string. column name unique record identifier. Default = \"database_id\". sci_names character string. column name species' scientific names. Default = \"scientificName\". lat character string. column name latitudes. Coordinates must expressed decimal degrees WGS84. Default = \"decimalLatitude\". lon character string. column name longitudes. Coordinates must expressed decimal degrees WGS84. Default = \"decimalLongitude\". country character string. column name country assignment occurrence record. Default = \"country\". countryCode character string. column name containing ISO-2 country code record. border_buffer Numeric. Must value greater equal 0. distance decimal degrees used created buffer around country. Records within given country specified distance border corrected. Default = 0.2 (~22 km equator). save_outputs Logical. Indicates table containing transposed coordinates saved inspection. Default = FALSE. fileName character string. file's name. scale Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = \"large\". path character string. path character vector create directories save figures. path provided (default), directories created using ::(). mc.cores Numeric. > 1, jbd_correct_coordinates function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1.#'","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"tibble containing column \"coordinates_transposed\" indicates verbatim coordinates transposed (TRUE). Otherwise records flagged (FALSE) , case, verbatim coordinates replaced corrected coordinates.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"test identifies transposed coordinates based mismatches country provided record record’s latitude longitude coordinates. Transposed coordinates often fall outside indicated country (.e., countries sea). Different coordinate transformations performed correct country/coordinates mismatches. Importantly, verbatim coordinates replaced corrected ones returned database. database containing verbatim corrected coordinates created \"Output/Check/01_coordinates_transposed.csv\" save_outputs == TRUE. columns \"country\" \"countryCode\" can retrieved using function bdc::bdc_country_standardized.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_coordinates_transposed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify transposed geographic coordinates — jbd_coordinates_transposed","text":"","code":"# \\donttest{ database_id <- c(1, 2, 3, 4) scientificName <- c(   \"Rhinella major\", \"Scinax ruber\",   \"Siparuna guianensis\", \"Psychotria vellosiana\" ) decimalLatitude <- c(63.43333, -14.43333, -41.90000, -46.69778) decimalLongitude <- c(-17.90000, -67.91667, -13.25000, -13.82444) country <- c(\"BOLIVIA\", \"bolivia\", \"Brasil\", \"Brazil\")  x <- data.frame(   database_id, scientificName, decimalLatitude,   decimalLongitude, country )  # Get country codes x <- bdc::bdc_country_standardized(data = x, country = \"country\") #> Loading auxiliary data: country names #> Standardizing country names #> country found: Bolivia #> country found: Brazil #>  #> bdc_country_standardized: #> The country names of 3 records were standardized. #> Two columns ('country_suggested' and 'countryCode') were added to the database.  jbd_coordinates_transposed(   data = x,   idcol = \"database_id\",   sci_names = \"scientificName\",   lat = \"decimalLatitude\",   lon = \"decimalLongitude\",   country = \"country_suggested\",   countryCode = \"countryCode\",   border_buffer = 0.2,   save_outputs = FALSE,   scale = \"medium\" )  #> Spherical geometry (s2) switched on #> Correcting latitude and longitude transposed #> 3 occurrences will be tested #>  #> jbd_coordinates_transposed: #> Corrected 3 records. #> One columns were added to the database. #> # A tibble: 4 × 8 #>   database_id scientificName        decimalLatitude decimalLongitude country #>         <dbl> <chr>                           <dbl>            <dbl> <chr>   #> 1           1 Rhinella major                  -17.9            -63.4 BOLIVIA #> 2           2 Scinax ruber                    -14.4            -67.9 bolivia #> 3           3 Siparuna guianensis             -13.2            -41.9 Brasil  #> 4           4 Psychotria vellosiana           -13.8            -46.7 Brazil  #> # ℹ 3 more variables: country_suggested <chr>, countryCode <chr>, #> #   coordinates_transposed <lgl> # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":null,"dir":"Reference","previous_headings":"","what":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"Creates figures (.e., bar plots, maps, histograms) reporting results data quality tests implemented bdc BeeBDC packages. Works like bdc::bdc_create_figures(), allows user specify save path.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"","code":"jbd_create_figures(   data,   path = OutPath_Figures,   database_id = \"database_id\",   workflow_step = NULL,   save_figures = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"data data frame tibble. Needs contain results data quality tests; , columns starting \".\". path character directory. path directory save figures. Default = OutPath_Figures. database_id character string. column name unique record identifier. Default = \"database_id\". workflow_step character string. Name workflow step. Options available \"prefilter\", \"space\", \"time\". save_figures Logical. Indicates figures saved inspection use. Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"List containing figures showing results data quality tests implemented one module bdc/BeeBDC. save_figures = TRUE, figures also saved locally .png format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"function creates figures based results data quality tests. pre-defined list test names used creating figures depending name workflow step informed. Figures saved \"Output/Figures\" save_figures = TRUE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/jbd_create_figures.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create figures reporting the results of the bdc/BeeBDC packages — jbd_create_figures","text":"","code":"# \\donttest{ database_id <- c(\"GBIF_01\", \"GBIF_02\", \"GBIF_03\", \"FISH_04\", \"FISH_05\") lat <- c(-19.93580, -13.01667, -22.34161, -6.75000, -15.15806) lon <- c(-40.60030, -39.60000, -49.61017, -35.63330, -39.52861) .scientificName_emptys <- c(TRUE, TRUE, TRUE, FALSE, FALSE) .coordinates_empty <- c(TRUE, TRUE, TRUE, TRUE, TRUE) .invalid_basis_of_records <- c(TRUE, FALSE, TRUE, FALSE, TRUE) .summary <- c(TRUE, FALSE, TRUE, FALSE, FALSE)  x <- data.frame(   database_id,   lat,   lon,   .scientificName_emptys,   .coordinates_empty,   .invalid_basis_of_records,   .summary )  figures <-  jbd_create_figures(   data = x,    database_id = \"database_id\",   workflow_step = \"prefilter\",   save_figures = FALSE ) #> Warning: Please provide a path! #> Loading required package: cowplot #> Loading required package: ggspatial # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"Uses expert-identified outliers source spreadsheets may edited users. function also use duplicates file made using dupeSummary() identify duplicates expert-identified outliers flag well. function add flagging column called .expertOutlier records FALSE expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"","code":"manualOutlierFindeR(   data = NULL,   DataPath = NULL,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"All_outliers_ANB.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   duplicates = NULL,   NearTRUE = NULL,   NearTRUE_threshold = 5 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"data data frame tibble. Occurrence records input. DataPath character path directory contains outlier spreadsheets. PaigeOutliersName character patch. lead outlier spreadsheet Paige Chesshire (csv file). newOutliersName character path. lead appropriate outlier spreadsheet (xlsx file). ColombiaOutliers_all character path. lead spreadsheet bee outliers Colombia (csv file). duplicates data frame tibble. duplicate file produced dupeSummary(). NearTRUE Optional. character file name csv file. want remove expert outliers close TRUE points, use name NearTRUE.csv. Note: implementation basic now unless greater need future. NearTRUE_threshold Numeric. threshold (km) distance TRUE points keep expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"Returns data new column, .expertOutlier records FALSE expert outliers.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/manualOutlierFindeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds outliers, and their duplicates, as determined by experts — manualOutlierFindeR","text":"","code":"if (FALSE) { # \\dontrun{   # Read example data   data(beesFlagged) # Read in the most-recent duplicates file as well if(!exists(\"duplicates\")){   duplicates <- fileFinder(path = DataPath,                             fileName = \"duplicateRun_\") %>%     readr::read_csv()} # identify the outliers and get a list of their database_ids beesFlagged_out <- manualOutlierFindeR(   data = beesFlagged,   DataPath = DataPath,   PaigeOutliersName = \"removedBecauseDeterminedOutlier.csv\",   newOutliersName = \"^All_outliers_ANB_14March.xlsx\",   ColombiaOutliers_all = \"All_Colombian_OutlierIDs.csv\",   duplicates = duplicates) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a plot summarising flagged data — plotFlagSummary","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"Creates compound bar plot shows proportion records pass fail flag (rows) data source (columns). function can also optionally return point map user-specified species plotMap = TRUE. function requires dataset run filtering functions - can display logical columns starting \".\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"","code":"plotFlagSummary(   data = NULL,   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = NULL,   outPath = OutPath_Figures,   width = 15,   height = 9,   units = \"in\",   dpi = 300,   bg = \"white\",   device = \"pdf\",   speciesName = NULL,   saveFiltered = FALSE,   filterColumn = \".summary\",   nameColumn = NULL,   plotMap = FALSE,   mapAlpha = 0.5,   xbuffer = c(0, 0),   ybuffer = c(0, 0),   ptSize = 1,   saveTable = FALSE,   jitterValue = NULL,   returnPlot = FALSE,   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"data data frame tibble. Occurrence records input. flagColours character vector. Colours order pass (TRUE), fail (FALSE), NA. Default = c(\"#127852\", \"#A7002D\", \"#BDBABB\"). fileName Character. name file saved, ending \".pdf\". saving different file type, change file type suffix - See device. outPath character path. path directory figure saved. Default = OutPath_Figures. width Numeric. width output figure user-defined units Default = 15. height Numeric. height output figure user-defined units Default = 9. units Character. units figure width height passed ggplot2::ggsave() (\"\", \"cm\", \"mm\", \"px\"). Default = \"\". dpi Numeric. Passed ggplot2::ggsave(). Plot resolution. Also accepts string input: \"retina\" (320), \"print\" (300), \"screen\" (72). Applies raster output types. Default = 300. bg Character. Passed ggplot2::ggsave(). Background colour. NULL, uses plot.background fill value plot theme. Default = \"white.\" device Character. Passed ggplot2::ggsave(). Device use. Can either device function (e.g. png), one \"eps\", \"ps\", \"tex\" (pictex), \"pdf\", \"jpeg\", \"tiff\", \"png\", \"bmp\", \"svg\" \"wmf\" (windows ). Default = \"pdf\". using default, change file name suffix fileName argument. speciesName Optional. Character. species name, occurs user-input nameColumn. provided, data filtered species plot. saveFiltered Optional. Logical. TRUE, filtered data saved computer .csv file. filterColumn Optional. flag column display map. Default = .summary. nameColumn Optional. Character. speciesName NULL, enter column look species . User might realise , combined speciesName, figures can made variety factors. plotMap Logical. TRUE, function produce point map. Tested use one species time; .e., speciesName NULL. mapAlpha Optional. Numeric. opacity points map. xbuffer Optional. Numeric vector. buffer degrees amount increase min max bounds along x-axis. may require experimentation, keeping mind negative positive directionality hemispheres. Default = c(0,0). ybuffer Optional. Numeric vector. buffer degrees amount increase min max bounds along y-axis. may require experimentation, keeping mind negative positive directionality hemispheres. Default = c(0,0). ptSize Optional. Numeric. size points passed ggplot2. Default = 1. saveTable Optional. Logical. TRUE, function save data used produce compound bar plot. jitterValue Optional. Numeric. value jitter points map decimal degrees. returnPlot Logical. TRUE, return plot environment. Default = FALSE. ... Optional. Extra variables fed forcats::fct_recode() change names plot. example... 'B. Mont.' = \"BMont\", 'B. Minkley' = \"BMin\", Ecd = \"Ecd\", Gaiarsa = \"Gai\"","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"Exports compound bar plot summarises flag columns. Optionally can also return point map particular species tandem summary plot.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/plotFlagSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a plot summarising flagged data — plotFlagSummary","text":"","code":"# import data data(beesFlagged) OutPath_Figures <- tempdir()  # Visualise all flags for each dataSource (simplified to the text before the first underscore) plotFlagSummary(   data = beesFlagged,   # Colours in order of pass (TRUE), fail (FALSE), and NA   flagColours = c(\"#127852\", \"#A7002D\", \"#BDBABB\"),   fileName = paste0(\"FlagsPlot_TEST_\", Sys.Date(),\".pdf\"),   outPath = OutPath_Figures,   width = 15, height = 9,   # OPTIONAL:   #\\   #  # Filter to species   #\\   speciesName = \"Holcopasites heliopsis\",   #\\   # column to look in   #\\   nameColumn = \"species\",   #\\   # Save the filtered data   #\\   saveFiltered = TRUE,   #\\   # Filter column to display on map   #\\   filterColumn = \".summary\",   #\\   plotMap = TRUE,   #\\   # amount to jitter points if desired, e.g. 0.25 or NULL   #\\   jitterValue = NULL,   #\\   # Map opacity value for points between 0 and 1   #\\   mapAlpha = 1,   # Extra variables can be fed into forcats::fct_recode() to change names on plot   GBIF = \"GBIF\", SCAN = \"SCAN\", iDigBio = \"iDigBio\", USGS = \"USGS\", ALA = \"ALA\",    ASP = \"ASP\", CAES = \"CAES\", 'B. Mont.' = \"BMont\", 'B. Minkley' = \"BMin\", Ecd = \"Ecd\",   Gaiarsa = \"Gai\", EPEL = \"EPEL\" ) #>  - Preparing data to plot... #>  - Building plot..."},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper for all of the data readr_functions — readr_BeeBDC","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"Read variety data files specific certain smaller data providers. internal readr function dataset one functions called readr_BeeBDC. functions internal, displayed documentation readr_BeeBDC clarity.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"","code":"readr_BeeBDC(   dataset = NULL,   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = NULL )  readr_EPEL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_ASP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_BMin(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_BMont(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Ecd(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Gai(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_CAES(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Sheet1\" )  readr_KP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_EcoS(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_GeoL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_EaCO(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MABC(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Hoja1\" )  readr_Col(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = sheet )  readr_FSCA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_SMC(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Bal(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"animal_data\" )  readr_Lic(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_Arm(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Sheet1\" )  readr_Dor(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MEPB(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = NULL )  readr_BBD(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_MPUJ(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = sheet )  readr_STRI(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_PALA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)  readr_JoLa(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = c(\"pre-1950\", \"post-1950\") )  readr_VicWam(   path = NULL,   inFile = NULL,   outFile = NULL,   dataLicense = NULL,   sheet = \"Combined\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"dataset Character. name dataset read . example readr_CAES can called using \"readr_CAES\" \"CAES\". caps sensitive. path character path. path directory containing data. inFile Character character path. name file (can also remainder path including file name). outFile Character character path. name Darwin Core format file saved. dataLicense Character. license accompany record Darwin Core 'license' column. sheet character String. datasets read .xlsx format, provide sheet name. NOTE: ignored .csv readr_ functions required .xlsx readr_ functions.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"data frame Darwin Core format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"function wraps several internal readr functions. Users may call readr_BeeBDC select dataset name import certain dataset. datasets include: Excel (.xlsx) formatted datasets: CAES, MABC, Col, Bal, MEPB, MUPJ, Arm, JoLa, VicWam. CSV (.csv) formatted datasets: EPEL, ASP, BMin, BMont, Ecd, Gai, KP, EcoS, GeoL, EaCo, FSCA, SMC, Lic, Dor, BBD, STRI, PALA See Dorey et al. 2023 BeeBDC... details.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"readr_EPEL(): Reads specific data files Darwin Core format readr_ASP(): Reads specific data files Darwin Core format readr_BMin(): Reads specific data files Darwin Core format readr_BMont(): Reads specific data files Darwin Core format readr_Ecd(): Reads specific data files Darwin Core format readr_Gai(): Reads specific data files Darwin Core format readr_CAES(): Reads specific data files Darwin Core format readr_KP(): Reads specific data files Darwin Core format readr_EcoS(): Reads specific data files Darwin Core format readr_GeoL(): Reads specific data files Darwin Core format readr_EaCO(): Reads specific data files Darwin Core format readr_MABC(): Reads specific data files Darwin Core format readr_Col(): Reads specific data files Darwin Core format readr_FSCA(): Reads specific data files Darwin Core format readr_SMC(): Reads specific data files Darwin Core format readr_Bal(): Reads specific data files Darwin Core format readr_Lic(): Reads specific data files Darwin Core format readr_Arm(): Reads specific data files Darwin Core format readr_Dor(): Reads specific data files Darwin Core format readr_MEPB(): Reads specific data files Darwin Core format readr_BBD(): Reads specific data files Darwin Core format readr_MPUJ(): Reads specific data files Darwin Core format readr_STRI(): Reads specific data files Darwin Core format readr_PALA(): Reads specific data files Darwin Core format readr_JoLa(): Reads specific data files Darwin Core format readr_VicWam(): Reads specific data files Darwin Core format","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/readr_BeeBDC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A wrapper for all of the data readr_functions — readr_BeeBDC","text":"","code":"if (FALSE) { # \\dontrun{ # An example using a .xlsx file Arm_Data <- readr_BeeBDC(     dataset = \"Arm\",     path = paste0(tempdir(), \"/Additional_Datasets\"),     inFile = \"/InputDatasets/Bee database Armando_Final.xlsx\",     outFile = \"jbd_Arm_Data.csv\",     sheet = \"Sheet1\",     dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\")               # An example using a .csv file EPEL_Data <- readr_BeeBDC(   dataset = \"readr_EPEL\",   path = paste0(tempdir(), \"/Additional_Datasets\"),   inFile = \"/InputDatasets/bee_data_canada.csv\",   outFile = \"jbd_EPEL_data.csv\",   dataLicense = \"https://creativecommons.org/licenses/by-nc-sa/4.0/\") } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":null,"dir":"Reference","previous_headings":"","what":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"Find GBIF, ALA, iDigBio, SCAN files directory","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"","code":"repoFinder(path)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"path directory character. path within recursively look GBIF, ALA, iDigBio, SCAN files.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"Returns list directories data downloads","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoFinder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find GBIF, ALA, iDigBio, and SCAN files in a directory — repoFinder","text":"","code":"if (FALSE) { # \\dontrun{ # Where DataPath is made by [BeeBDC::dirMaker()] BeeBDC::repoFinder(path = DataPath) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":null,"dir":"Reference","previous_headings":"","what":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"Locates data GBIF, ALA, iDigBio, SCAN within directory reads along eml metadata. Please keep original download folder names architecture unchanged. NOTE: function uses family-level data identify taxon downloads. , something new, becomes issue, please contact James Dorey (developer) likely exceptions files downloaded. current versions 1.0.4.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"","code":"repoMerge(path, save_type, occ_paths)"},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"path directory character. directory recursively look data. save_type Character. data type save resulting file . Options : csv_files\" \"R_file\". occ_paths list directories. Preferably produced using repoFinder() function asks list paths relevant input datasets. can fault-find errors function checking output repoFinder().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"list data frame merged occurrence records, \"Data_WebDL\", list eml files contained \"eml_files\". Also saves files requested format.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/repoMerge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads — repoMerge","text":"","code":"if (FALSE) { # \\dontrun{ DataImp <- repoMerge(path = DataPath,  # Find data - Many problems can be solved by running [BeeBDC::repoFinder(path = DataPath)] # And looking for problems occ_paths = BeeBDC::repoFinder(path = DataPath), save_type = \"R_file\") } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessEstimateR.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate country, continental, and global species richnesses — richnessEstimateR","title":"Estimate country, continental, and global species richnesses — richnessEstimateR","text":"Takes output dataset richnessPrepR() estimate species richness using iChao iNEXT (hill numbers) countries, continents, /entire globe.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessEstimateR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate country, continental, and global species richnesses — richnessEstimateR","text":"","code":"richnessEstimateR(   data = NULL,   sampleSize = 10000,   countrySamples = 1,   continentSamples = 1,   globalSamples = 1,   countriesToExclude = NULL,   mc.cores = 1,   k = 10,   filterToRecordedCountries = TRUE,   outPath = tempdir(),   fileName = \"continentSampled.pdf\" )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessEstimateR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate country, continental, and global species richnesses — richnessEstimateR","text":"data RData file created using richnessPrepR() function. sampleSize Numeric. size sample randomly drawn provided curve. See curveFunction. Default = 10000. countrySamples Numeric. number times sample country species richness iChao iNEXT. equal zero (0), analysed. Default = 5. continentSamples Numeric. number times sample continent species richness iChao iNEXT. equal zero (0), analysed. Default = 5. globalSamples Numeric. number times sample global species richness iChao iNEXT. equal zero (0), analysed. Default = 5. countriesToExclude Character vector. may decide excluse countries problematic sample sizes small. Default = NULL. mc.cores Numeric. > 1, function run parallel using mclapply using number cores specified. = 1 run using serial loop. NOTE: Windows machines must use value 1 (see ?parallel::mclapply). Additionally, aware thread can use large chunks memory. Default = 1. k Numeric. iChao; cut-point (default = 10), separates species \"abundant\" \"rare\" groups abundance data estimator ACE; separates species \"frequent\" \"infrequent\" groups incidence data estimator ICE. Default = 10. filterToRecordedCountries Logical. TRUE, checklist filtered countries occurrence records found. Default = TRUE. Change peril. outPath directory character. Directory save output figure. Default = tempdir(). fileName character vector file name output figure, ending '.pdf'. Default = \"continentSampled.pdf\".","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessEstimateR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate country, continental, and global species richnesses — richnessEstimateR","text":"Outputs R file four tables (\"Summary\", \"SiteOutput\", \"ContinentOutput\", \"GlobalOutput\"; depending number required). summary table shows Median overall estimates, remaining three shows outputs iteration (useful plotting, see relevant vignette). figures may also saved selected outPath.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessEstimateR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate country, continental, and global species richnesses — richnessEstimateR","text":"","code":"if (FALSE) { # \\dontrun{    # Use the example data  data(beesCountrySubset)    # First,  estimateDataExample <- BeeBDC::richnessPrepR(   data = beesCountrySubset,   # Download the taxonomy   taxonomyFile = BeeBDC::beesTaxonomy(),   # Download the checklist   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\",   limitGlobal = NULL,   outPath = tempdir() )   exampleEstimate <- richnessEstimateR(    data = estimateDataExample,    sampleSize = 10000,    countrySamples = 1,    continentSamples = 1,    globalSamples = 1,    filterToRecordedCountries = TRUE,    mc.cores = 1,    # Directory where to save files    outPath = tempdir(),    fileName = \"Sampled.pdf\"  )   } # } # END dontrun"},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessPrepR.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","title":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","text":"Takes occurrence dataset along taxonomy checklist order produce file ready passed richnessEstimateR() function order estimate species richness using iChao iNEXT (hill numbers) countries, continents, entire globe.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessPrepR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","text":"","code":"richnessPrepR(   data = NULL,   taxonomyFile = BeeBDC::beesTaxonomy(),   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\",   limitGlobal = NULL,   outPath = tempdir() )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessPrepR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","text":"data data frame tibble. Occurrence records input. Needs include scientificName column \"country\" column (see countryColumn) taxonomyFile data frame tibble. taxonomy file use. Default = beesTaxonomy() see taxadbToBeeBDC() taxa. checklistFile data frame tibble. taxonomy use. Default = beesChecklist(); use template convert taxa checklists. curveFunction function. mathematical function describes curve used randomly sample order fill empty sample sizes species present checklist present occurrence dataset. Default function(x) (228.7531 * x * x^-log(12.1593)), taken paper \"many bee species ? quantitative global estimate\" Dorey et al. Models can fit using mosaic::fitModel(). sampleSize Numeric. size sample randomly drawn provided curve. See curveFunction. Default = 10000. countryColumn Character. column country names sought. limitGlobal Character vector. character vector countries filter data order limit extent global-level analysis. Defualt = NULL. outPath Character. output path curve plot (curvePlot.pdf) output Rdata (richnessInputs.Rda) file saved. Default = tempdir().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessPrepR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","text":"Saves Rdata file data needed feed richnessEstimateR() function. richnessEstimateR() function use iChao /iNEXT estimate species richness countries, continents, globe. Also returns RData file environment.","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/richnessPrepR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare occurrence, taxonomy, and checklist data for richness estimation — richnessPrepR","text":"","code":"if (FALSE) { # \\dontrun{ data(beesCountrySubset)  estimateDataExample <- richnessPrepR(   data = beesCountrySubset,   # Download the taxonomy   taxonomyFile = BeeBDC::beesTaxonomy(),   # Download the checklist   checklistFile = BeeBDC::beesChecklist(),   curveFunction = function(x) (228.7531 * x * x^-log(12.1593)),   sampleSize = 10000,   countryColumn = \"country_suggested\",   limitGlobal = NULL,   outPath = tempdir() ) } # }"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or update the .summary flag column — summaryFun","title":"Create or update the .summary flag column — summaryFun","text":"Using flag columns (column names starting \".\"), function either creates updates .summary flag column FALSE flag columns FALSE. Columns can excluded removed creating .summary column. Additionally, occurrence dataset can filtered .summary = TRUE end function.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or update the .summary flag column — summaryFun","text":"","code":"summaryFun(   data = NULL,   dontFilterThese = NULL,   removeFilterColumns = FALSE,   filterClean = FALSE )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or update the .summary flag column — summaryFun","text":"data data frame tibble. Occurrence records use input. dontFilterThese character vector flag columns ignored creation updating .summary column. removeFilterColumns Logical. TRUE columns starting \".\" removed output data. makes sense use filterClean = TRUE. Default = FALSE. filterClean Logical. TRUE, data filtered occurrence .summary = TRUE (.e., completely clean according used flag columns). Default = FALSE.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or update the .summary flag column — summaryFun","text":"Returns data frame tibble input data modified based parameters.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryFun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create or update the .summary flag column — summaryFun","text":"","code":"# Read in example data data(beesFlagged)  # To only update the .summary column beesFlagged_out <- summaryFun(     data = beesFlagged,     dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\", \".unLicensed\"),     removeFilterColumns = FALSE,     filterClean = FALSE) #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .unLicensed #>  - summaryFun: #> Flagged 81  #>   The .summary column was added to the database.   # View output table(beesFlagged_out$.summary, useNA = \"always\") #>  #> FALSE  TRUE  <NA>  #>    81    19     0   # Now filter to only the clean data and remove the flag columns beesFlagged_out <- summaryFun(   data = BeeBDC::beesFlagged,   dontFilterThese = c(\".gridSummary\", \".lonFlag\", \".latFlag\", \".uncer_terms\", \".unLicensed\"),   removeFilterColumns = TRUE,   filterClean = TRUE) #>  - We will NOT flag the following columns. However, they will remain in the data file. #> .gridSummary, .lonFlag, .latFlag, .uncer_terms, .unLicensed #>  - summaryFun: #> Flagged 81  #>   The .summary column was added to the database. #>  - REMOVED all occurrences that were FALSE for the 'summary' column. # View output table(beesFlagged_out$.summary, useNA = \"always\") #> Warning: Unknown or uninitialised column: `.summary`. #>  #> <NA>  #>    0"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Create country-level summary maps of species and occurrence numbers — summaryMaps","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"Builds output figure shows number species number occurrences per country. Breaks data classes visualisation. Users may filter data taxa interest produce figures interest.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"","code":"summaryMaps(   data = NULL,   class_n = 15,   class_Style = \"fisher\",   outPath = NULL,   fileName = NULL,   width = 10,   height = 5,   dpi = 300,   returnPlot = FALSE,   scale = 110,   pointBuffer = 0.01 )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"data data frame tibble. Occurrence records input. class_n Numeric. number categories break data . class_Style Character. class style passed classInt::classIntervals(). Options chosen style: one \"fixed\", \"sd\", \"equal\", \"pretty\", \"quantile\", \"kmeans\", \"hclust\", \"bclust\", \"fisher\", \"jenks\", \"dpih\", \"headtails\", \"maximum\". Default = \"fisher\" outPath character vector path save location output figure. fileName character vector file name output figure, ending '.pdf'. width Numeric. width, inches, resulting figure. Default = 10. height Numeric. height, inches, resulting figure. Default = 5. dpi Numeric. resolution resulting plot. Default = 300. returnPlot Logical. TRUE, return plot environment. Default = FALSE. scale Numeric character. Passed rnaturalearth's ne_countries(). Scale map return, one 110, 50, 10 'small', 'medium', 'large'. Default = 110. pointBuffer Numeric. Amount buffer points, decimal degrees. point outside country, within point buffer, count towards country. good idea keep value consistent prior flags applied. Default = 0.01.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"Saves figure user-specified outpath name global map bee occurrence species count data input dataset.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/summaryMaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create country-level summary maps of species and occurrence numbers — summaryMaps","text":"","code":"# Read in data data(beesFlagged) OutPath_Figures <- tempdir() # This simple example using the test data has very few classes due to the small amount of input  # data. summaryMaps( data = beesFlagged, width = 10, height = 10, class_n = 4, class_Style = \"fisher\", outPath = OutPath_Figures, fileName = paste0(\"CountryMaps_fisher_TEST.pdf\"), ) #> Spherical geometry (s2) switched off #>  - Extracting country data from points... #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #> Extraction complete. #>  - Buffering naturalearth map by pointBuffer... #> dist is assumed to be in decimal degrees (arc_degrees). #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar #> although coordinates are longitude/latitude, st_intersects assumes that they #> are planar"},{"path":"https://jbdorey.github.io/BeeBDC/reference/taxadbToBeeBDC.html","id":null,"dir":"Reference","previous_headings":"","what":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","title":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","text":"Uses taxadb R package download requested taxonomy transforms input BeeBDC format. means taxonomy databases can used BeeBDC. can also save output computer R environment immediate use. See details list providers see taxadb::td_create().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/taxadbToBeeBDC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","text":"","code":"taxadbToBeeBDC(   name = NULL,   rank = NULL,   provider = \"gbif\",   version = \"22.12\",   collect = TRUE,   ignore_case = TRUE,   db = NULL,   removeEmptyNames = TRUE,   outPath = getwd(),   fileName = NULL,   ... )"},{"path":"https://jbdorey.github.io/BeeBDC/reference/taxadbToBeeBDC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","text":"name Character. Taxonomic scientific name (e.g. \"Aves\"). defined  taxadb::filter_rank(). rank Character. Taxonomic rank name. (e.g. \"class\"). defined taxadb::filter_rank(). provider Character. provider hierarchy returned? Default 'gbif', can also configured using options(default_taxadb_provide = ...\"). See taxadb::td_create() list recognized providers. NOTE: gbif seems -complete columns, especially terms scientificNameAuthorship, important matching ambiguous names. defined taxadb::filter_rank(). version Character. version taxadb provider database use? defaults latest. See tl_import details. Default = 22.12. defined taxadb::filter_rank(). collect Logical. return -memory data.frame (default, usually convenient), reference lazy-eval table disk (useful large tables may first perform subsequent filtering operations.). Default = TRUE. defined taxadb::filter_rank(). ignore_case Logical. ignore case (capitalization) matching names? Can significantly slower run. Default = TRUE. defined taxadb::filter_rank(). db connection taxadb database. See details taxadb::filter_rank(). Default = Null work. defined taxadb::filter_rank(). removeEmptyNames Logical. True (default), remove entries without entry specificEpithet. outPath Character. path directory (folder) output saved. fileName Character. name output file, ending '.csv'. ... Arguments passed taxadb::td_create().","code":""},{"path":"https://jbdorey.github.io/BeeBDC/reference/taxadbToBeeBDC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","text":"Returns taxonomy file (R environment disk, fileName provided) tibble can used BeeBDC::harmoniseR().","code":""},{"path":[]},{"path":"https://jbdorey.github.io/BeeBDC/reference/taxadbToBeeBDC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import and convert taxadb taxonomies to BeeBDC format — taxadbToBeeBDC","text":"","code":"if (FALSE) { # \\dontrun{   # Run the function using the bee genus Apis as an example... ApisTaxonomy <- BeeBDC::taxadbToBeeBDC(   name = \"Apis\",   rank = \"Genus\",   provider = \"gbif\",   version = \"22.12\",   removeEmptyNames = TRUE,   outPath = getwd(),   fileName = NULL,   ...   )   } # }"},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-version-130","dir":"Changelog","previous_headings":"","what":"Changes in version 1.3.0","title":"Changes in version 1.3.0","text":"Updates BeeBDC::flagAbsent() also check individualCount count flag individualCount == 0. updated BeeBDC::ColTypeR() include bee-specific Darwin Core data standard using new argument standardFormat = “bee”. Updated BeeBDC::atlasDownloader() use newer galah syntax. Updated BeeBDC::interactiveMapR() allow present plot returned R environment viewer. Added new functions estimate species richness across multiple sites parallel added speed. BeeBDC::richnessPrepR() takes input occurrence data, taxonomy, checklists produce R data file following functions. BeeBDC::iNEXTwrapper() wrapper iNEXT::iNEXT() interpolate extrapolate Hill numbers order q (rarify species richness). BeeBDC::ChaoWrapper() wrapper SpadeR::ChaoSpecies() non-parametrically estimate species richness. BeeBDC::richnessEstimateR() Takes output dataset [BeeBDC::richnessPrepR()] estimate species richness using iChao (non-parametric species richness; BeeBDC::ChaoWrapper()) iNEXT (hill numbers; BeeBDC::iNEXTwrapper()) countries, continents, /entire globe. BeeBDC::ggRichnessWrapper() Takes outputs BeeBDC::iNEXTwrapper() BeeBDC::ChaoWrapper() create summary table output figure. BeeBDC::countryHarmoniseR added helper function harmonise country names often inconsistent otherwise problematic. going internal function made available exported. Added new test dataset, beesCountrySubsets test new species richness functions. Added (Vignette)[https://jbdorey.github.io/BeeBDC/articles/speciesRichness_example.html] implementing functions Fixed issue upcoming ggplot2 version causing test failures Depends “R (>= 4.1.0)” usage |> pipe operator","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-version-121","dir":"Changelog","previous_headings":"","what":"Changes in version 1.2.1","title":"Changes in version 1.2.1","text":"CRAN release: 2024-11-04 BeeBDC::taxadbToBeeBDC() now prompts users install taxadb ’s already installed. Minor updates fix breaks external updates. NOTE: major update planned next year users requests problems, feel free get touch ’ll see ’s possible given available time.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-120","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.2.0","title":"Changes in BeeBDC version 1.2.0","text":"CRAN release: 2024-06-21 Release new function, BeeBDC::continentOutlieRs(), conceptually BeeBDC::countryOutlieRs() except continental level. function recognises sometimes knowledge (including data) insufficient country-level analyses. continent-level function might actually see greater use taxa beyond bees country-level checklists may exist continent-level checklist created. also provide updates BeeBDC::beesTaxonomy() BeeBDC::beesChecklist() allow new function used properly. also include new tests added sections vignette. also added warning use function older versions beesChecklist added compatibility BeeBDC::plotFlagSummary(). added option BeeBDC::summaryFun() allow users specify “onlyFilterThese” instead “dontFilterThese”.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-111","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.1.1","title":"Changes in BeeBDC version 1.1.1","text":"CRAN release: 2024-04-03 Trying close unused connections formattedCombiner tests throw errors CRAN’s arm tests (reproducible M1 M3 mac test ). Removed extra UTF-8 characters causing note CRAN’s Linux tests. Updating citations .","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-110","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.1.0","title":"Changes in BeeBDC version 1.1.0","text":"CRAN release: 2024-03-20 new function added, BeeBDC::taxadbToBeeBDC(), can use taxadb package download taxonomic data taxa. function transform taxadb format BeeBDC format can put directly BeeBDC::harmoniseR(). Users may choose data source (e.g., “gbif” “itis”), formats may better others. Comments issues welcome regards well function works, , taxon. minor fix legend colours BeeBDC::interactiveMapR() function inverted . Thanks Neil Cobb pointing . Minor fixes BeeBDC::dateFindR() identify dates exceptions advice Elsa Youngsteadt. Minor update BeeBDC::dupeSummary() update igraph::clusters igraph::components(); simple renaming.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-105","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.0.5","title":"Changes in BeeBDC version 1.0.5","text":"Minor alteration plotFlagSummary allow removal columns level one factors, “Initial”,“Time”,“Summary”,“Taxonomy”,“Space”, longer present. Basically, minor upgrade make function resilient different input data. Fixed issue caused stability fix leaflet #884 tonerLite base map work stop points showing map.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-104","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.0.4","title":"Changes in BeeBDC version 1.0.4","text":"CRAN release: 2024-02-14 Suggestions Elsa Youngsteadt (North Carolina State University) allow functionality harmoniseR search name matches verbatimScientificName column. functionality optionally added checkVerbatim argument (default = FALSE) whereby TRUE function make checks normal name columns , rows failed, check verbatimScientificName column matches. Exception found Elsa Youngsteadt repoMerge attr_builder fail complete multiple families included single GBIF, iDigBio, SCAN download. updated whereby functions can now work together order identify multi-family download label dataSource column accordingly. also reflected metadata EML data show different sources, maintaining metadata download (doi, link, …). Minor exception found Elsa Youngsteadt synonyms fail matched due double brackets (e.g., “Lasioglossum (leucocomum) (Lovell)”). fixed letting harmoniseR stringr::str_replace instead stringr::str_replace_all finding matches without subgenus. Additionally, harmoniseR now ignores “non-ambiguous…” flags notes actual issues. Update rnaturalearthdata 1.0.0 breaks BeeBDC::countryOutliers(). function now uses column “iso_a3_eh” instead “iso_a3”. Thanks @PMassicotte identifying issue solution.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-103","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.0.3","title":"Changes in BeeBDC version 1.0.3","text":"CRAN release: 2023-12-20 Minor update jbd_correct_coordinates maintain functionality sf version 1.0-15.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-102","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.0.2","title":"Changes in BeeBDC version 1.0.2","text":"CRAN release: 2023-11-30 Minor update plotFlagSummary allow individual species maps get updated. Update atlasDownloader mjwestgate work galah version 2.0.0 Minor update bee taxonomy file (29th November 2023), especially regards species getting associated genus-identifications. particular, users downloaded version 1 dataset careful following species: Coelioxys texanus, Lasioglossum albipenne, Megachile brevis, Xylocopa virginica. Likely verbatimScientificName column filtered remove issues something like: beeData %>% dplyr::filter(verbatimScientificName %% c(“Coelioxys”, “Lasioglossum”, “Megachile”, “Xylocopa”)). Thanks Angela Nava-Bolaños identifying issue.","code":""},{"path":"https://jbdorey.github.io/BeeBDC/news/index.html","id":"changes-in-beebdc-version-101","dir":"Changelog","previous_headings":"","what":"Changes in BeeBDC version 1.0.1","title":"Changes in BeeBDC version 1.0.1","text":"CRAN release: 2023-10-09 ComplexHeatmap moved imports suggests chordDiagramR now ask user want install BiocManager ComplexHeatmap (already installed) completing function. simplify installation process greatly. new readr function added (readr_VicWam), reads data combined Victorian Western Australian Museums Australia. typo potential pitfall fixed countryOutliers sometimes .sea records flagged NA record counts .countryOutlier stated text output. users access taxonomy checklist files slightly modified include better warnings help troubleshooting well specific file-path operations Windows machines. jbd_coordCountryInconsistent updated better capture mismatched countries using columns match. Tests workflows updated accordingly.","code":""}]
